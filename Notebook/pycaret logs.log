2023-09-28 16:13:02,811:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-28 16:13:02,811:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-28 16:13:02,811:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-28 16:13:02,811:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-28 16:13:03,113:INFO:PyCaret RegressionExperiment
2023-09-28 16:13:03,113:INFO:Logging name: reg-default-name
2023-09-28 16:13:03,113:INFO:ML Usecase: MLUsecase.REGRESSION
2023-09-28 16:13:03,113:INFO:version 3.1.0
2023-09-28 16:13:03,113:INFO:Initializing setup()
2023-09-28 16:13:03,113:INFO:self.USI: af8b
2023-09-28 16:13:03,113:INFO:self._variable_keys: {'gpu_param', 'fold_shuffle_param', 'exp_id', 'idx', 'exp_name_log', 'target_param', 'X_train', 'X_test', '_available_plots', 'n_jobs_param', 'y', 'fold_generator', '_ml_usecase', 'data', 'html_param', 'y_test', 'y_train', 'logging_param', 'transform_target_param', 'seed', 'fold_groups_param', 'gpu_n_jobs_param', 'X', 'pipeline', 'USI', 'log_plots_param', 'memory'}
2023-09-28 16:13:03,113:INFO:Checking environment
2023-09-28 16:13:03,113:INFO:python_version: 3.10.11
2023-09-28 16:13:03,113:INFO:python_build: ('main', 'May 16 2023 00:55:32')
2023-09-28 16:13:03,113:INFO:machine: AMD64
2023-09-28 16:13:03,113:INFO:platform: Windows-10-10.0.19045-SP0
2023-09-28 16:13:03,129:INFO:Memory: svmem(total=16931770368, available=8104214528, percent=52.1, used=8827555840, free=8104214528)
2023-09-28 16:13:03,129:INFO:Physical Core: 4
2023-09-28 16:13:03,129:INFO:Logical Core: 8
2023-09-28 16:13:03,129:INFO:Checking libraries
2023-09-28 16:13:03,129:INFO:System:
2023-09-28 16:13:03,129:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, May 16 2023, 00:55:32) [MSC v.1916 64 bit (AMD64)]
2023-09-28 16:13:03,129:INFO:executable: p:\Anaconda\envs\jupy\python.exe
2023-09-28 16:13:03,129:INFO:   machine: Windows-10-10.0.19045-SP0
2023-09-28 16:13:03,129:INFO:PyCaret required dependencies:
2023-09-28 16:13:03,178:INFO:                 pip: 23.2.1
2023-09-28 16:13:03,178:INFO:          setuptools: 68.0.0
2023-09-28 16:13:03,178:INFO:             pycaret: 3.1.0
2023-09-28 16:13:03,178:INFO:             IPython: 8.14.0
2023-09-28 16:13:03,178:INFO:          ipywidgets: 8.1.1
2023-09-28 16:13:03,178:INFO:                tqdm: 4.66.1
2023-09-28 16:13:03,178:INFO:               numpy: 1.23.5
2023-09-28 16:13:03,178:INFO:              pandas: 1.5.3
2023-09-28 16:13:03,178:INFO:              jinja2: 3.1.2
2023-09-28 16:13:03,178:INFO:               scipy: 1.11.1
2023-09-28 16:13:03,178:INFO:              joblib: 1.2.0
2023-09-28 16:13:03,178:INFO:             sklearn: 1.3.0
2023-09-28 16:13:03,178:INFO:                pyod: 1.1.0
2023-09-28 16:13:03,178:INFO:            imblearn: 0.11.0
2023-09-28 16:13:03,178:INFO:   category_encoders: 2.6.2
2023-09-28 16:13:03,178:INFO:            lightgbm: 4.1.0
2023-09-28 16:13:03,178:INFO:               numba: 0.57.1
2023-09-28 16:13:03,178:INFO:            requests: 2.31.0
2023-09-28 16:13:03,178:INFO:          matplotlib: 3.7.3
2023-09-28 16:13:03,178:INFO:          scikitplot: 0.3.7
2023-09-28 16:13:03,178:INFO:         yellowbrick: 1.5
2023-09-28 16:13:03,178:INFO:              plotly: 5.17.0
2023-09-28 16:13:03,178:INFO:    plotly-resampler: Not installed
2023-09-28 16:13:03,178:INFO:             kaleido: 0.2.1
2023-09-28 16:13:03,178:INFO:           schemdraw: 0.15
2023-09-28 16:13:03,178:INFO:         statsmodels: 0.14.0
2023-09-28 16:13:03,178:INFO:              sktime: 0.21.1
2023-09-28 16:13:03,178:INFO:               tbats: 1.1.3
2023-09-28 16:13:03,178:INFO:            pmdarima: 2.0.3
2023-09-28 16:13:03,178:INFO:              psutil: 5.9.5
2023-09-28 16:13:03,178:INFO:          markupsafe: 2.1.3
2023-09-28 16:13:03,178:INFO:             pickle5: Not installed
2023-09-28 16:13:03,178:INFO:         cloudpickle: 2.2.1
2023-09-28 16:13:03,178:INFO:         deprecation: 2.1.0
2023-09-28 16:13:03,178:INFO:              xxhash: 3.3.0
2023-09-28 16:13:03,178:INFO:           wurlitzer: Not installed
2023-09-28 16:13:03,178:INFO:PyCaret optional dependencies:
2023-09-28 16:13:04,076:INFO:                shap: 0.42.1
2023-09-28 16:13:04,076:INFO:           interpret: Not installed
2023-09-28 16:13:04,076:INFO:                umap: Not installed
2023-09-28 16:13:04,076:INFO:     ydata_profiling: Not installed
2023-09-28 16:13:04,076:INFO:  explainerdashboard: Not installed
2023-09-28 16:13:04,076:INFO:             autoviz: Not installed
2023-09-28 16:13:04,076:INFO:           fairlearn: Not installed
2023-09-28 16:13:04,076:INFO:          deepchecks: Not installed
2023-09-28 16:13:04,076:INFO:             xgboost: 2.0.0
2023-09-28 16:13:04,076:INFO:            catboost: Not installed
2023-09-28 16:13:04,076:INFO:              kmodes: Not installed
2023-09-28 16:13:04,076:INFO:             mlxtend: Not installed
2023-09-28 16:13:04,076:INFO:       statsforecast: Not installed
2023-09-28 16:13:04,076:INFO:        tune_sklearn: Not installed
2023-09-28 16:13:04,076:INFO:                 ray: Not installed
2023-09-28 16:13:04,076:INFO:            hyperopt: Not installed
2023-09-28 16:13:04,076:INFO:              optuna: 3.3.0
2023-09-28 16:13:04,076:INFO:               skopt: Not installed
2023-09-28 16:13:04,076:INFO:              mlflow: Not installed
2023-09-28 16:13:04,076:INFO:              gradio: Not installed
2023-09-28 16:13:04,076:INFO:             fastapi: 0.103.1
2023-09-28 16:13:04,076:INFO:             uvicorn: 0.23.2
2023-09-28 16:13:04,076:INFO:              m2cgen: Not installed
2023-09-28 16:13:04,076:INFO:           evidently: 0.4.5
2023-09-28 16:13:04,076:INFO:               fugue: Not installed
2023-09-28 16:13:04,076:INFO:           streamlit: 1.26.0
2023-09-28 16:13:04,076:INFO:             prophet: Not installed
2023-09-28 16:13:04,076:INFO:None
2023-09-28 16:13:04,076:INFO:Set up data.
2023-09-28 16:13:04,076:INFO:Set up folding strategy.
2023-09-28 16:13:04,076:INFO:Set up train/test split.
2023-09-28 16:13:04,092:INFO:Set up index.
2023-09-28 16:13:04,092:INFO:Assigning column types.
2023-09-28 16:13:04,092:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-09-28 16:13:04,092:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-09-28 16:13:04,092:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-28 16:13:04,107:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-28 16:13:04,194:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-28 16:13:04,277:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-28 16:13:04,278:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:13:04,284:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:13:04,284:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-09-28 16:13:04,289:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-28 16:13:04,295:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-28 16:13:04,400:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-28 16:13:04,462:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-28 16:13:04,462:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:13:04,478:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:13:04,478:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-09-28 16:13:04,478:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-28 16:13:04,478:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-28 16:13:04,565:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-28 16:13:04,627:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-28 16:13:04,627:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:13:04,627:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:13:04,627:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-28 16:13:04,643:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-28 16:13:04,728:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-28 16:13:04,794:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-28 16:13:04,794:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:13:04,794:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:13:04,794:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-09-28 16:13:04,811:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-28 16:13:04,883:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-28 16:13:04,930:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-28 16:13:04,930:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:13:04,930:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:13:04,930:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-28 16:13:04,997:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-28 16:13:05,060:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-28 16:13:05,060:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:13:05,060:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:13:05,060:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-09-28 16:13:05,128:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-28 16:13:05,178:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-28 16:13:05,178:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:13:05,178:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:13:05,278:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-28 16:13:05,328:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-28 16:13:05,328:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:13:05,328:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:13:05,328:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-09-28 16:13:05,431:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-28 16:13:05,485:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:13:05,485:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:13:05,593:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-28 16:13:05,644:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:13:05,660:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:13:05,660:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-09-28 16:13:05,762:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:13:05,778:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:13:05,894:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:13:05,894:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:13:05,894:INFO:Preparing preprocessing pipeline...
2023-09-28 16:13:05,894:INFO:Set up simple imputation.
2023-09-28 16:13:05,911:INFO:Finished creating preprocessing pipeline.
2023-09-28 16:13:05,927:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\maxxk\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['clonesize', 'honeybee', 'bumbles',
                                             'andrena', 'osmia',
                                             'MaxOfUpperTRange',
                                             'MinOfUpperTRange',
                                             'AverageOfUpperTRange',
                                             'MaxOfLowerTRange',
                                             'MinOfLowerTRange',
                                             'AverageOfLowerTRange',
                                             'RainingDays',
                                             'AverageRainingDays'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-09-28 16:13:05,927:INFO:Creating final display dataframe.
2023-09-28 16:13:05,978:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target             yield
2                   Target type        Regression
3           Original data shape         (777, 14)
4        Transformed data shape         (777, 14)
5   Transformed train set shape         (543, 14)
6    Transformed test set shape         (234, 14)
7              Numeric features                13
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              af8b
2023-09-28 16:13:06,132:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:13:06,132:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:13:06,281:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:13:06,296:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:13:06,296:INFO:setup() successfully completed in 3.18s...............
2023-09-28 16:14:19,390:INFO:Initializing compare_models()
2023-09-28 16:14:19,391:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023448F92230>, include=None, fold=None, round=4, cross_validation=True, sort=RMSE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000023448F92230>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'RMSE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-09-28 16:14:19,391:INFO:Checking exceptions
2023-09-28 16:14:19,395:INFO:Preparing display monitor
2023-09-28 16:14:19,459:INFO:Initializing Linear Regression
2023-09-28 16:14:19,459:INFO:Total runtime is 1.6617774963378907e-05 minutes
2023-09-28 16:14:19,471:INFO:SubProcess create_model() called ==================================
2023-09-28 16:14:19,471:INFO:Initializing create_model()
2023-09-28 16:14:19,472:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023448F92230>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000234271B60B0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:14:19,472:INFO:Checking exceptions
2023-09-28 16:14:19,472:INFO:Importing libraries
2023-09-28 16:14:19,472:INFO:Copying training dataset
2023-09-28 16:14:19,482:INFO:Defining folds
2023-09-28 16:14:19,482:INFO:Declaring metric variables
2023-09-28 16:14:19,492:INFO:Importing untrained model
2023-09-28 16:14:19,500:INFO:Linear Regression Imported successfully
2023-09-28 16:14:19,513:INFO:Starting cross validation
2023-09-28 16:14:19,523:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:14:28,561:INFO:Calculating mean and std
2023-09-28 16:14:28,563:INFO:Creating metrics dataframe
2023-09-28 16:14:28,566:INFO:Uploading results into container
2023-09-28 16:14:28,566:INFO:Uploading model into container now
2023-09-28 16:14:28,566:INFO:_master_model_container: 1
2023-09-28 16:14:28,566:INFO:_display_container: 2
2023-09-28 16:14:28,566:INFO:LinearRegression(n_jobs=-1)
2023-09-28 16:14:28,566:INFO:create_model() successfully completed......................................
2023-09-28 16:14:28,628:INFO:SubProcess create_model() end ==================================
2023-09-28 16:14:28,628:INFO:Creating metrics dataframe
2023-09-28 16:14:28,646:INFO:Initializing Lasso Regression
2023-09-28 16:14:28,646:INFO:Total runtime is 0.1531223734219869 minutes
2023-09-28 16:14:28,646:INFO:SubProcess create_model() called ==================================
2023-09-28 16:14:28,646:INFO:Initializing create_model()
2023-09-28 16:14:28,646:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023448F92230>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000234271B60B0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:14:28,646:INFO:Checking exceptions
2023-09-28 16:14:28,646:INFO:Importing libraries
2023-09-28 16:14:28,646:INFO:Copying training dataset
2023-09-28 16:14:28,665:INFO:Defining folds
2023-09-28 16:14:28,665:INFO:Declaring metric variables
2023-09-28 16:14:28,665:INFO:Importing untrained model
2023-09-28 16:14:28,677:INFO:Lasso Regression Imported successfully
2023-09-28 16:14:28,686:INFO:Starting cross validation
2023-09-28 16:14:28,686:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:14:28,729:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.455e+07, tolerance: 8.787e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:14:28,730:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.717e+07, tolerance: 8.750e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:14:28,745:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.482e+07, tolerance: 8.741e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:14:28,746:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.406e+07, tolerance: 8.527e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:14:28,754:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.686e+07, tolerance: 8.176e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:14:28,754:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.041e+07, tolerance: 8.833e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:14:28,770:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.775e+07, tolerance: 8.728e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:14:28,770:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.859e+07, tolerance: 8.783e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:14:28,786:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.710e+07, tolerance: 8.812e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:14:28,786:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.878e+07, tolerance: 8.614e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:14:28,818:INFO:Calculating mean and std
2023-09-28 16:14:28,818:INFO:Creating metrics dataframe
2023-09-28 16:14:28,818:INFO:Uploading results into container
2023-09-28 16:14:28,818:INFO:Uploading model into container now
2023-09-28 16:14:28,818:INFO:_master_model_container: 2
2023-09-28 16:14:28,818:INFO:_display_container: 2
2023-09-28 16:14:28,818:INFO:Lasso(random_state=42)
2023-09-28 16:14:28,818:INFO:create_model() successfully completed......................................
2023-09-28 16:14:28,894:INFO:SubProcess create_model() end ==================================
2023-09-28 16:14:28,894:INFO:Creating metrics dataframe
2023-09-28 16:14:28,911:INFO:Initializing Ridge Regression
2023-09-28 16:14:28,911:INFO:Total runtime is 0.1575448195139567 minutes
2023-09-28 16:14:28,911:INFO:SubProcess create_model() called ==================================
2023-09-28 16:14:28,911:INFO:Initializing create_model()
2023-09-28 16:14:28,911:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023448F92230>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000234271B60B0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:14:28,911:INFO:Checking exceptions
2023-09-28 16:14:28,911:INFO:Importing libraries
2023-09-28 16:14:28,911:INFO:Copying training dataset
2023-09-28 16:14:28,911:INFO:Defining folds
2023-09-28 16:14:28,911:INFO:Declaring metric variables
2023-09-28 16:14:28,911:INFO:Importing untrained model
2023-09-28 16:14:28,911:INFO:Ridge Regression Imported successfully
2023-09-28 16:14:28,932:INFO:Starting cross validation
2023-09-28 16:14:28,932:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:14:29,077:INFO:Calculating mean and std
2023-09-28 16:14:29,078:INFO:Creating metrics dataframe
2023-09-28 16:14:29,078:INFO:Uploading results into container
2023-09-28 16:14:29,078:INFO:Uploading model into container now
2023-09-28 16:14:29,078:INFO:_master_model_container: 3
2023-09-28 16:14:29,078:INFO:_display_container: 2
2023-09-28 16:14:29,078:INFO:Ridge(random_state=42)
2023-09-28 16:14:29,078:INFO:create_model() successfully completed......................................
2023-09-28 16:14:29,161:INFO:SubProcess create_model() end ==================================
2023-09-28 16:14:29,161:INFO:Creating metrics dataframe
2023-09-28 16:14:29,179:INFO:Initializing Elastic Net
2023-09-28 16:14:29,179:INFO:Total runtime is 0.16200244824091595 minutes
2023-09-28 16:14:29,195:INFO:SubProcess create_model() called ==================================
2023-09-28 16:14:29,195:INFO:Initializing create_model()
2023-09-28 16:14:29,195:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023448F92230>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000234271B60B0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:14:29,195:INFO:Checking exceptions
2023-09-28 16:14:29,195:INFO:Importing libraries
2023-09-28 16:14:29,195:INFO:Copying training dataset
2023-09-28 16:14:29,195:INFO:Defining folds
2023-09-28 16:14:29,195:INFO:Declaring metric variables
2023-09-28 16:14:29,195:INFO:Importing untrained model
2023-09-28 16:14:29,216:INFO:Elastic Net Imported successfully
2023-09-28 16:14:29,230:INFO:Starting cross validation
2023-09-28 16:14:29,232:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:14:29,381:INFO:Calculating mean and std
2023-09-28 16:14:29,381:INFO:Creating metrics dataframe
2023-09-28 16:14:29,381:INFO:Uploading results into container
2023-09-28 16:14:29,381:INFO:Uploading model into container now
2023-09-28 16:14:29,381:INFO:_master_model_container: 4
2023-09-28 16:14:29,381:INFO:_display_container: 2
2023-09-28 16:14:29,381:INFO:ElasticNet(random_state=42)
2023-09-28 16:14:29,381:INFO:create_model() successfully completed......................................
2023-09-28 16:14:29,460:INFO:SubProcess create_model() end ==================================
2023-09-28 16:14:29,460:INFO:Creating metrics dataframe
2023-09-28 16:14:29,479:INFO:Initializing Least Angle Regression
2023-09-28 16:14:29,479:INFO:Total runtime is 0.16701083978017173 minutes
2023-09-28 16:14:29,479:INFO:SubProcess create_model() called ==================================
2023-09-28 16:14:29,479:INFO:Initializing create_model()
2023-09-28 16:14:29,479:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023448F92230>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000234271B60B0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:14:29,479:INFO:Checking exceptions
2023-09-28 16:14:29,479:INFO:Importing libraries
2023-09-28 16:14:29,479:INFO:Copying training dataset
2023-09-28 16:14:29,479:INFO:Defining folds
2023-09-28 16:14:29,479:INFO:Declaring metric variables
2023-09-28 16:14:29,479:INFO:Importing untrained model
2023-09-28 16:14:29,497:INFO:Least Angle Regression Imported successfully
2023-09-28 16:14:29,505:INFO:Starting cross validation
2023-09-28 16:14:29,510:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:14:29,645:INFO:Calculating mean and std
2023-09-28 16:14:29,645:INFO:Creating metrics dataframe
2023-09-28 16:14:29,645:INFO:Uploading results into container
2023-09-28 16:14:29,645:INFO:Uploading model into container now
2023-09-28 16:14:29,645:INFO:_master_model_container: 5
2023-09-28 16:14:29,645:INFO:_display_container: 2
2023-09-28 16:14:29,645:INFO:Lars(random_state=42)
2023-09-28 16:14:29,645:INFO:create_model() successfully completed......................................
2023-09-28 16:14:29,711:INFO:SubProcess create_model() end ==================================
2023-09-28 16:14:29,711:INFO:Creating metrics dataframe
2023-09-28 16:14:29,727:INFO:Initializing Lasso Least Angle Regression
2023-09-28 16:14:29,727:INFO:Total runtime is 0.17114917437235516 minutes
2023-09-28 16:14:29,727:INFO:SubProcess create_model() called ==================================
2023-09-28 16:14:29,727:INFO:Initializing create_model()
2023-09-28 16:14:29,727:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023448F92230>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000234271B60B0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:14:29,727:INFO:Checking exceptions
2023-09-28 16:14:29,727:INFO:Importing libraries
2023-09-28 16:14:29,727:INFO:Copying training dataset
2023-09-28 16:14:29,746:INFO:Defining folds
2023-09-28 16:14:29,746:INFO:Declaring metric variables
2023-09-28 16:14:29,746:INFO:Importing untrained model
2023-09-28 16:14:29,746:INFO:Lasso Least Angle Regression Imported successfully
2023-09-28 16:14:29,765:INFO:Starting cross validation
2023-09-28 16:14:29,767:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:14:29,884:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 11 iterations, alpha=3.334e+00, previous alpha=3.244e+00, with an active set of 10 regressors.
  warnings.warn(

2023-09-28 16:14:29,913:INFO:Calculating mean and std
2023-09-28 16:14:29,913:INFO:Creating metrics dataframe
2023-09-28 16:14:29,913:INFO:Uploading results into container
2023-09-28 16:14:29,913:INFO:Uploading model into container now
2023-09-28 16:14:29,913:INFO:_master_model_container: 6
2023-09-28 16:14:29,913:INFO:_display_container: 2
2023-09-28 16:14:29,913:INFO:LassoLars(random_state=42)
2023-09-28 16:14:29,913:INFO:create_model() successfully completed......................................
2023-09-28 16:14:29,994:INFO:SubProcess create_model() end ==================================
2023-09-28 16:14:29,994:INFO:Creating metrics dataframe
2023-09-28 16:14:29,994:INFO:Initializing Orthogonal Matching Pursuit
2023-09-28 16:14:29,994:INFO:Total runtime is 0.17559745311737063 minutes
2023-09-28 16:14:30,012:INFO:SubProcess create_model() called ==================================
2023-09-28 16:14:30,012:INFO:Initializing create_model()
2023-09-28 16:14:30,012:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023448F92230>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000234271B60B0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:14:30,012:INFO:Checking exceptions
2023-09-28 16:14:30,012:INFO:Importing libraries
2023-09-28 16:14:30,012:INFO:Copying training dataset
2023-09-28 16:14:30,012:INFO:Defining folds
2023-09-28 16:14:30,012:INFO:Declaring metric variables
2023-09-28 16:14:30,012:INFO:Importing untrained model
2023-09-28 16:14:30,032:INFO:Orthogonal Matching Pursuit Imported successfully
2023-09-28 16:14:30,048:INFO:Starting cross validation
2023-09-28 16:14:30,049:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:14:30,219:INFO:Calculating mean and std
2023-09-28 16:14:30,221:INFO:Creating metrics dataframe
2023-09-28 16:14:30,228:INFO:Uploading results into container
2023-09-28 16:14:30,230:INFO:Uploading model into container now
2023-09-28 16:14:30,231:INFO:_master_model_container: 7
2023-09-28 16:14:30,231:INFO:_display_container: 2
2023-09-28 16:14:30,233:INFO:OrthogonalMatchingPursuit()
2023-09-28 16:14:30,233:INFO:create_model() successfully completed......................................
2023-09-28 16:14:30,318:INFO:SubProcess create_model() end ==================================
2023-09-28 16:14:30,318:INFO:Creating metrics dataframe
2023-09-28 16:14:30,332:INFO:Initializing Bayesian Ridge
2023-09-28 16:14:30,333:INFO:Total runtime is 0.1812365531921387 minutes
2023-09-28 16:14:30,337:INFO:SubProcess create_model() called ==================================
2023-09-28 16:14:30,338:INFO:Initializing create_model()
2023-09-28 16:14:30,338:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023448F92230>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000234271B60B0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:14:30,338:INFO:Checking exceptions
2023-09-28 16:14:30,338:INFO:Importing libraries
2023-09-28 16:14:30,339:INFO:Copying training dataset
2023-09-28 16:14:30,343:INFO:Defining folds
2023-09-28 16:14:30,343:INFO:Declaring metric variables
2023-09-28 16:14:30,349:INFO:Importing untrained model
2023-09-28 16:14:30,353:INFO:Bayesian Ridge Imported successfully
2023-09-28 16:14:30,370:INFO:Starting cross validation
2023-09-28 16:14:30,371:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:14:30,610:INFO:Calculating mean and std
2023-09-28 16:14:30,611:INFO:Creating metrics dataframe
2023-09-28 16:14:30,611:INFO:Uploading results into container
2023-09-28 16:14:30,611:INFO:Uploading model into container now
2023-09-28 16:14:30,611:INFO:_master_model_container: 8
2023-09-28 16:14:30,611:INFO:_display_container: 2
2023-09-28 16:14:30,611:INFO:BayesianRidge()
2023-09-28 16:14:30,611:INFO:create_model() successfully completed......................................
2023-09-28 16:14:30,661:INFO:SubProcess create_model() end ==================================
2023-09-28 16:14:30,661:INFO:Creating metrics dataframe
2023-09-28 16:14:30,677:INFO:Initializing Passive Aggressive Regressor
2023-09-28 16:14:30,677:INFO:Total runtime is 0.18698298136393232 minutes
2023-09-28 16:14:30,677:INFO:SubProcess create_model() called ==================================
2023-09-28 16:14:30,677:INFO:Initializing create_model()
2023-09-28 16:14:30,677:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023448F92230>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000234271B60B0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:14:30,677:INFO:Checking exceptions
2023-09-28 16:14:30,677:INFO:Importing libraries
2023-09-28 16:14:30,677:INFO:Copying training dataset
2023-09-28 16:14:30,693:INFO:Defining folds
2023-09-28 16:14:30,693:INFO:Declaring metric variables
2023-09-28 16:14:30,696:INFO:Importing untrained model
2023-09-28 16:14:30,696:INFO:Passive Aggressive Regressor Imported successfully
2023-09-28 16:14:30,709:INFO:Starting cross validation
2023-09-28 16:14:30,711:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:14:30,827:INFO:Calculating mean and std
2023-09-28 16:14:30,827:INFO:Creating metrics dataframe
2023-09-28 16:14:30,827:INFO:Uploading results into container
2023-09-28 16:14:30,827:INFO:Uploading model into container now
2023-09-28 16:14:30,827:INFO:_master_model_container: 9
2023-09-28 16:14:30,827:INFO:_display_container: 2
2023-09-28 16:14:30,827:INFO:PassiveAggressiveRegressor(random_state=42)
2023-09-28 16:14:30,827:INFO:create_model() successfully completed......................................
2023-09-28 16:14:30,896:INFO:SubProcess create_model() end ==================================
2023-09-28 16:14:30,896:INFO:Creating metrics dataframe
2023-09-28 16:14:30,911:INFO:Initializing Huber Regressor
2023-09-28 16:14:30,911:INFO:Total runtime is 0.1908720135688782 minutes
2023-09-28 16:14:30,911:INFO:SubProcess create_model() called ==================================
2023-09-28 16:14:30,911:INFO:Initializing create_model()
2023-09-28 16:14:30,911:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023448F92230>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000234271B60B0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:14:30,911:INFO:Checking exceptions
2023-09-28 16:14:30,911:INFO:Importing libraries
2023-09-28 16:14:30,911:INFO:Copying training dataset
2023-09-28 16:14:30,911:INFO:Defining folds
2023-09-28 16:14:30,911:INFO:Declaring metric variables
2023-09-28 16:14:30,911:INFO:Importing untrained model
2023-09-28 16:14:30,927:INFO:Huber Regressor Imported successfully
2023-09-28 16:14:30,940:INFO:Starting cross validation
2023-09-28 16:14:30,940:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:14:31,100:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-28 16:14:31,114:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-28 16:14:31,114:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-28 16:14:31,116:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-28 16:14:31,162:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-28 16:14:31,179:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-28 16:14:31,179:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-28 16:14:31,179:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-28 16:14:31,261:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-28 16:14:31,279:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-28 16:14:31,295:INFO:Calculating mean and std
2023-09-28 16:14:31,295:INFO:Creating metrics dataframe
2023-09-28 16:14:31,295:INFO:Uploading results into container
2023-09-28 16:14:31,295:INFO:Uploading model into container now
2023-09-28 16:14:31,295:INFO:_master_model_container: 10
2023-09-28 16:14:31,295:INFO:_display_container: 2
2023-09-28 16:14:31,295:INFO:HuberRegressor()
2023-09-28 16:14:31,295:INFO:create_model() successfully completed......................................
2023-09-28 16:14:31,361:INFO:SubProcess create_model() end ==================================
2023-09-28 16:14:31,361:INFO:Creating metrics dataframe
2023-09-28 16:14:31,377:INFO:Initializing K Neighbors Regressor
2023-09-28 16:14:31,377:INFO:Total runtime is 0.19864807128906253 minutes
2023-09-28 16:14:31,377:INFO:SubProcess create_model() called ==================================
2023-09-28 16:14:31,377:INFO:Initializing create_model()
2023-09-28 16:14:31,377:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023448F92230>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000234271B60B0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:14:31,377:INFO:Checking exceptions
2023-09-28 16:14:31,377:INFO:Importing libraries
2023-09-28 16:14:31,377:INFO:Copying training dataset
2023-09-28 16:14:31,394:INFO:Defining folds
2023-09-28 16:14:31,394:INFO:Declaring metric variables
2023-09-28 16:14:31,394:INFO:Importing untrained model
2023-09-28 16:14:31,403:INFO:K Neighbors Regressor Imported successfully
2023-09-28 16:14:31,413:INFO:Starting cross validation
2023-09-28 16:14:31,415:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:14:31,593:INFO:Calculating mean and std
2023-09-28 16:14:31,595:INFO:Creating metrics dataframe
2023-09-28 16:14:31,595:INFO:Uploading results into container
2023-09-28 16:14:31,595:INFO:Uploading model into container now
2023-09-28 16:14:31,595:INFO:_master_model_container: 11
2023-09-28 16:14:31,595:INFO:_display_container: 2
2023-09-28 16:14:31,595:INFO:KNeighborsRegressor(n_jobs=-1)
2023-09-28 16:14:31,595:INFO:create_model() successfully completed......................................
2023-09-28 16:14:31,660:INFO:SubProcess create_model() end ==================================
2023-09-28 16:14:31,676:INFO:Creating metrics dataframe
2023-09-28 16:14:31,677:INFO:Initializing Decision Tree Regressor
2023-09-28 16:14:31,677:INFO:Total runtime is 0.20364623467127485 minutes
2023-09-28 16:14:31,677:INFO:SubProcess create_model() called ==================================
2023-09-28 16:14:31,677:INFO:Initializing create_model()
2023-09-28 16:14:31,677:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023448F92230>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000234271B60B0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:14:31,677:INFO:Checking exceptions
2023-09-28 16:14:31,677:INFO:Importing libraries
2023-09-28 16:14:31,677:INFO:Copying training dataset
2023-09-28 16:14:31,694:INFO:Defining folds
2023-09-28 16:14:31,694:INFO:Declaring metric variables
2023-09-28 16:14:31,694:INFO:Importing untrained model
2023-09-28 16:14:31,694:INFO:Decision Tree Regressor Imported successfully
2023-09-28 16:14:31,708:INFO:Starting cross validation
2023-09-28 16:14:31,710:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:14:31,827:INFO:Calculating mean and std
2023-09-28 16:14:31,827:INFO:Creating metrics dataframe
2023-09-28 16:14:31,835:INFO:Uploading results into container
2023-09-28 16:14:31,835:INFO:Uploading model into container now
2023-09-28 16:14:31,835:INFO:_master_model_container: 12
2023-09-28 16:14:31,835:INFO:_display_container: 2
2023-09-28 16:14:31,835:INFO:DecisionTreeRegressor(random_state=42)
2023-09-28 16:14:31,835:INFO:create_model() successfully completed......................................
2023-09-28 16:14:31,894:INFO:SubProcess create_model() end ==================================
2023-09-28 16:14:31,894:INFO:Creating metrics dataframe
2023-09-28 16:14:31,910:INFO:Initializing Random Forest Regressor
2023-09-28 16:14:31,910:INFO:Total runtime is 0.20751761595408125 minutes
2023-09-28 16:14:31,910:INFO:SubProcess create_model() called ==================================
2023-09-28 16:14:31,910:INFO:Initializing create_model()
2023-09-28 16:14:31,910:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023448F92230>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000234271B60B0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:14:31,910:INFO:Checking exceptions
2023-09-28 16:14:31,910:INFO:Importing libraries
2023-09-28 16:14:31,910:INFO:Copying training dataset
2023-09-28 16:14:31,910:INFO:Defining folds
2023-09-28 16:14:31,910:INFO:Declaring metric variables
2023-09-28 16:14:31,910:INFO:Importing untrained model
2023-09-28 16:14:31,910:INFO:Random Forest Regressor Imported successfully
2023-09-28 16:14:31,932:INFO:Starting cross validation
2023-09-28 16:14:31,933:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:14:33,360:INFO:Calculating mean and std
2023-09-28 16:14:33,361:INFO:Creating metrics dataframe
2023-09-28 16:14:33,367:INFO:Uploading results into container
2023-09-28 16:14:33,367:INFO:Uploading model into container now
2023-09-28 16:14:33,368:INFO:_master_model_container: 13
2023-09-28 16:14:33,368:INFO:_display_container: 2
2023-09-28 16:14:33,368:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-09-28 16:14:33,368:INFO:create_model() successfully completed......................................
2023-09-28 16:14:33,429:INFO:SubProcess create_model() end ==================================
2023-09-28 16:14:33,429:INFO:Creating metrics dataframe
2023-09-28 16:14:33,429:INFO:Initializing Extra Trees Regressor
2023-09-28 16:14:33,443:INFO:Total runtime is 0.23307996590932212 minutes
2023-09-28 16:14:33,447:INFO:SubProcess create_model() called ==================================
2023-09-28 16:14:33,448:INFO:Initializing create_model()
2023-09-28 16:14:33,448:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023448F92230>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000234271B60B0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:14:33,448:INFO:Checking exceptions
2023-09-28 16:14:33,448:INFO:Importing libraries
2023-09-28 16:14:33,448:INFO:Copying training dataset
2023-09-28 16:14:33,451:INFO:Defining folds
2023-09-28 16:14:33,451:INFO:Declaring metric variables
2023-09-28 16:14:33,454:INFO:Importing untrained model
2023-09-28 16:14:33,457:INFO:Extra Trees Regressor Imported successfully
2023-09-28 16:14:33,464:INFO:Starting cross validation
2023-09-28 16:14:33,466:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:14:34,543:INFO:Calculating mean and std
2023-09-28 16:14:34,545:INFO:Creating metrics dataframe
2023-09-28 16:14:34,549:INFO:Uploading results into container
2023-09-28 16:14:34,550:INFO:Uploading model into container now
2023-09-28 16:14:34,550:INFO:_master_model_container: 14
2023-09-28 16:14:34,551:INFO:_display_container: 2
2023-09-28 16:14:34,551:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2023-09-28 16:14:34,551:INFO:create_model() successfully completed......................................
2023-09-28 16:14:34,661:INFO:SubProcess create_model() end ==================================
2023-09-28 16:14:34,661:INFO:Creating metrics dataframe
2023-09-28 16:14:34,677:INFO:Initializing AdaBoost Regressor
2023-09-28 16:14:34,677:INFO:Total runtime is 0.2536498069763184 minutes
2023-09-28 16:14:34,677:INFO:SubProcess create_model() called ==================================
2023-09-28 16:14:34,677:INFO:Initializing create_model()
2023-09-28 16:14:34,677:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023448F92230>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000234271B60B0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:14:34,677:INFO:Checking exceptions
2023-09-28 16:14:34,677:INFO:Importing libraries
2023-09-28 16:14:34,677:INFO:Copying training dataset
2023-09-28 16:14:34,694:INFO:Defining folds
2023-09-28 16:14:34,694:INFO:Declaring metric variables
2023-09-28 16:14:34,705:INFO:Importing untrained model
2023-09-28 16:14:34,716:INFO:AdaBoost Regressor Imported successfully
2023-09-28 16:14:34,738:INFO:Starting cross validation
2023-09-28 16:14:34,741:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:14:35,243:INFO:Calculating mean and std
2023-09-28 16:14:35,245:INFO:Creating metrics dataframe
2023-09-28 16:14:35,247:INFO:Uploading results into container
2023-09-28 16:14:35,247:INFO:Uploading model into container now
2023-09-28 16:14:35,247:INFO:_master_model_container: 15
2023-09-28 16:14:35,247:INFO:_display_container: 2
2023-09-28 16:14:35,254:INFO:AdaBoostRegressor(random_state=42)
2023-09-28 16:14:35,254:INFO:create_model() successfully completed......................................
2023-09-28 16:14:35,311:INFO:SubProcess create_model() end ==================================
2023-09-28 16:14:35,311:INFO:Creating metrics dataframe
2023-09-28 16:14:35,327:INFO:Initializing Gradient Boosting Regressor
2023-09-28 16:14:35,327:INFO:Total runtime is 0.2644837538401286 minutes
2023-09-28 16:14:35,327:INFO:SubProcess create_model() called ==================================
2023-09-28 16:14:35,327:INFO:Initializing create_model()
2023-09-28 16:14:35,327:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023448F92230>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000234271B60B0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:14:35,327:INFO:Checking exceptions
2023-09-28 16:14:35,327:INFO:Importing libraries
2023-09-28 16:14:35,327:INFO:Copying training dataset
2023-09-28 16:14:35,346:INFO:Defining folds
2023-09-28 16:14:35,346:INFO:Declaring metric variables
2023-09-28 16:14:35,352:INFO:Importing untrained model
2023-09-28 16:14:35,352:INFO:Gradient Boosting Regressor Imported successfully
2023-09-28 16:14:35,366:INFO:Starting cross validation
2023-09-28 16:14:35,366:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:14:35,793:INFO:Calculating mean and std
2023-09-28 16:14:35,795:INFO:Creating metrics dataframe
2023-09-28 16:14:35,795:INFO:Uploading results into container
2023-09-28 16:14:35,795:INFO:Uploading model into container now
2023-09-28 16:14:35,795:INFO:_master_model_container: 16
2023-09-28 16:14:35,795:INFO:_display_container: 2
2023-09-28 16:14:35,795:INFO:GradientBoostingRegressor(random_state=42)
2023-09-28 16:14:35,795:INFO:create_model() successfully completed......................................
2023-09-28 16:14:35,861:INFO:SubProcess create_model() end ==================================
2023-09-28 16:14:35,861:INFO:Creating metrics dataframe
2023-09-28 16:14:35,893:INFO:Initializing Extreme Gradient Boosting
2023-09-28 16:14:35,893:INFO:Total runtime is 0.2739140033721924 minutes
2023-09-28 16:14:35,897:INFO:SubProcess create_model() called ==================================
2023-09-28 16:14:35,897:INFO:Initializing create_model()
2023-09-28 16:14:35,897:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023448F92230>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000234271B60B0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:14:35,897:INFO:Checking exceptions
2023-09-28 16:14:35,897:INFO:Importing libraries
2023-09-28 16:14:35,897:INFO:Copying training dataset
2023-09-28 16:14:35,897:INFO:Defining folds
2023-09-28 16:14:35,897:INFO:Declaring metric variables
2023-09-28 16:14:35,910:INFO:Importing untrained model
2023-09-28 16:14:35,915:INFO:Extreme Gradient Boosting Imported successfully
2023-09-28 16:14:35,922:INFO:Starting cross validation
2023-09-28 16:14:35,922:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:14:37,461:INFO:Calculating mean and std
2023-09-28 16:14:37,461:INFO:Creating metrics dataframe
2023-09-28 16:14:37,461:INFO:Uploading results into container
2023-09-28 16:14:37,461:INFO:Uploading model into container now
2023-09-28 16:14:37,461:INFO:_master_model_container: 17
2023-09-28 16:14:37,461:INFO:_display_container: 2
2023-09-28 16:14:37,461:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=42, ...)
2023-09-28 16:14:37,461:INFO:create_model() successfully completed......................................
2023-09-28 16:14:37,530:INFO:SubProcess create_model() end ==================================
2023-09-28 16:14:37,530:INFO:Creating metrics dataframe
2023-09-28 16:14:37,553:INFO:Initializing Light Gradient Boosting Machine
2023-09-28 16:14:37,553:INFO:Total runtime is 0.30157934427261357 minutes
2023-09-28 16:14:37,557:INFO:SubProcess create_model() called ==================================
2023-09-28 16:14:37,560:INFO:Initializing create_model()
2023-09-28 16:14:37,560:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023448F92230>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000234271B60B0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:14:37,560:INFO:Checking exceptions
2023-09-28 16:14:37,560:INFO:Importing libraries
2023-09-28 16:14:37,561:INFO:Copying training dataset
2023-09-28 16:14:37,563:INFO:Defining folds
2023-09-28 16:14:37,563:INFO:Declaring metric variables
2023-09-28 16:14:37,563:INFO:Importing untrained model
2023-09-28 16:14:37,563:INFO:Light Gradient Boosting Machine Imported successfully
2023-09-28 16:14:37,582:INFO:Starting cross validation
2023-09-28 16:14:37,584:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:14:38,371:INFO:Calculating mean and std
2023-09-28 16:14:38,373:INFO:Creating metrics dataframe
2023-09-28 16:14:38,383:INFO:Uploading results into container
2023-09-28 16:14:38,384:INFO:Uploading model into container now
2023-09-28 16:14:38,385:INFO:_master_model_container: 18
2023-09-28 16:14:38,385:INFO:_display_container: 2
2023-09-28 16:14:38,387:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2023-09-28 16:14:38,387:INFO:create_model() successfully completed......................................
2023-09-28 16:14:38,478:INFO:SubProcess create_model() end ==================================
2023-09-28 16:14:38,478:INFO:Creating metrics dataframe
2023-09-28 16:14:38,497:INFO:Initializing Dummy Regressor
2023-09-28 16:14:38,497:INFO:Total runtime is 0.317310380935669 minutes
2023-09-28 16:14:38,497:INFO:SubProcess create_model() called ==================================
2023-09-28 16:14:38,497:INFO:Initializing create_model()
2023-09-28 16:14:38,497:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023448F92230>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000234271B60B0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:14:38,497:INFO:Checking exceptions
2023-09-28 16:14:38,497:INFO:Importing libraries
2023-09-28 16:14:38,497:INFO:Copying training dataset
2023-09-28 16:14:38,513:INFO:Defining folds
2023-09-28 16:14:38,513:INFO:Declaring metric variables
2023-09-28 16:14:38,521:INFO:Importing untrained model
2023-09-28 16:14:38,527:INFO:Dummy Regressor Imported successfully
2023-09-28 16:14:38,537:INFO:Starting cross validation
2023-09-28 16:14:38,537:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:14:38,643:INFO:Calculating mean and std
2023-09-28 16:14:38,643:INFO:Creating metrics dataframe
2023-09-28 16:14:38,643:INFO:Uploading results into container
2023-09-28 16:14:38,643:INFO:Uploading model into container now
2023-09-28 16:14:38,643:INFO:_master_model_container: 19
2023-09-28 16:14:38,643:INFO:_display_container: 2
2023-09-28 16:14:38,643:INFO:DummyRegressor()
2023-09-28 16:14:38,643:INFO:create_model() successfully completed......................................
2023-09-28 16:14:38,711:INFO:SubProcess create_model() end ==================================
2023-09-28 16:14:38,711:INFO:Creating metrics dataframe
2023-09-28 16:14:38,726:INFO:Initializing create_model()
2023-09-28 16:14:38,726:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023448F92230>, estimator=GradientBoostingRegressor(random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:14:38,726:INFO:Checking exceptions
2023-09-28 16:14:38,726:INFO:Importing libraries
2023-09-28 16:14:38,726:INFO:Copying training dataset
2023-09-28 16:14:38,742:INFO:Defining folds
2023-09-28 16:14:38,742:INFO:Declaring metric variables
2023-09-28 16:14:38,742:INFO:Importing untrained model
2023-09-28 16:14:38,742:INFO:Declaring custom model
2023-09-28 16:14:38,742:INFO:Gradient Boosting Regressor Imported successfully
2023-09-28 16:14:38,742:INFO:Cross validation set to False
2023-09-28 16:14:38,742:INFO:Fitting Model
2023-09-28 16:14:38,834:INFO:GradientBoostingRegressor(random_state=42)
2023-09-28 16:14:38,834:INFO:create_model() successfully completed......................................
2023-09-28 16:14:38,936:INFO:_master_model_container: 19
2023-09-28 16:14:38,936:INFO:_display_container: 2
2023-09-28 16:14:38,936:INFO:GradientBoostingRegressor(random_state=42)
2023-09-28 16:14:38,936:INFO:compare_models() successfully completed......................................
2023-09-28 16:16:35,944:INFO:Initializing predict_model()
2023-09-28 16:16:35,944:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023448F92230>, estimator=GradientBoostingRegressor(random_state=42), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002342716B6D0>)
2023-09-28 16:16:35,944:INFO:Checking exceptions
2023-09-28 16:16:35,945:INFO:Preloading libraries
2023-09-28 16:16:52,271:INFO:Initializing predict_model()
2023-09-28 16:16:52,275:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023448F92230>, estimator=GradientBoostingRegressor(random_state=42), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002344BA79900>)
2023-09-28 16:16:52,275:INFO:Checking exceptions
2023-09-28 16:16:52,275:INFO:Preloading libraries
2023-09-28 16:16:54,438:INFO:Initializing predict_model()
2023-09-28 16:16:54,438:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023448F92230>, estimator=GradientBoostingRegressor(random_state=42), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002344B6C7AC0>)
2023-09-28 16:16:54,438:INFO:Checking exceptions
2023-09-28 16:16:54,443:INFO:Preloading libraries
2023-09-28 16:17:41,251:INFO:Initializing tune_model()
2023-09-28 16:17:41,252:INFO:tune_model(estimator=GradientBoostingRegressor(random_state=42), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023448F92230>)
2023-09-28 16:17:41,252:INFO:Checking exceptions
2023-09-28 16:17:41,277:INFO:Copying training dataset
2023-09-28 16:17:41,281:INFO:Checking base model
2023-09-28 16:17:41,282:INFO:Base model : Gradient Boosting Regressor
2023-09-28 16:17:41,288:INFO:Declaring metric variables
2023-09-28 16:17:41,294:INFO:Defining Hyperparameters
2023-09-28 16:17:41,394:INFO:Tuning with n_jobs=-1
2023-09-28 16:17:41,394:INFO:Initializing RandomizedSearchCV
2023-09-28 16:17:46,761:INFO:best_params: {'actual_estimator__subsample': 0.8, 'actual_estimator__n_estimators': 110, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 4, 'actual_estimator__learning_rate': 0.4}
2023-09-28 16:17:46,761:INFO:Hyperparameter search completed
2023-09-28 16:17:46,761:INFO:SubProcess create_model() called ==================================
2023-09-28 16:17:46,761:INFO:Initializing create_model()
2023-09-28 16:17:46,761:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023448F92230>, estimator=GradientBoostingRegressor(random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002344A8A6110>, model_only=True, return_train_score=False, kwargs={'subsample': 0.8, 'n_estimators': 110, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0, 'max_features': 'log2', 'max_depth': 4, 'learning_rate': 0.4})
2023-09-28 16:17:46,761:INFO:Checking exceptions
2023-09-28 16:17:46,761:INFO:Importing libraries
2023-09-28 16:17:46,761:INFO:Copying training dataset
2023-09-28 16:17:46,770:INFO:Defining folds
2023-09-28 16:17:46,770:INFO:Declaring metric variables
2023-09-28 16:17:46,777:INFO:Importing untrained model
2023-09-28 16:17:46,777:INFO:Declaring custom model
2023-09-28 16:17:46,782:INFO:Gradient Boosting Regressor Imported successfully
2023-09-28 16:17:46,807:INFO:Starting cross validation
2023-09-28 16:17:46,810:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:17:47,325:INFO:Calculating mean and std
2023-09-28 16:17:47,327:INFO:Creating metrics dataframe
2023-09-28 16:17:47,335:INFO:Finalizing model
2023-09-28 16:17:47,528:INFO:Uploading results into container
2023-09-28 16:17:47,530:INFO:Uploading model into container now
2023-09-28 16:17:47,532:INFO:_master_model_container: 20
2023-09-28 16:17:47,532:INFO:_display_container: 6
2023-09-28 16:17:47,534:INFO:GradientBoostingRegressor(learning_rate=0.4, max_depth=4, max_features='log2',
                          min_impurity_decrease=0, min_samples_leaf=2,
                          min_samples_split=5, n_estimators=110,
                          random_state=42, subsample=0.8)
2023-09-28 16:17:47,534:INFO:create_model() successfully completed......................................
2023-09-28 16:17:47,634:INFO:SubProcess create_model() end ==================================
2023-09-28 16:17:47,634:INFO:choose_better activated
2023-09-28 16:17:47,634:INFO:SubProcess create_model() called ==================================
2023-09-28 16:17:47,634:INFO:Initializing create_model()
2023-09-28 16:17:47,634:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023448F92230>, estimator=GradientBoostingRegressor(random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:17:47,634:INFO:Checking exceptions
2023-09-28 16:17:47,647:INFO:Importing libraries
2023-09-28 16:17:47,647:INFO:Copying training dataset
2023-09-28 16:17:47,650:INFO:Defining folds
2023-09-28 16:17:47,650:INFO:Declaring metric variables
2023-09-28 16:17:47,650:INFO:Importing untrained model
2023-09-28 16:17:47,650:INFO:Declaring custom model
2023-09-28 16:17:47,651:INFO:Gradient Boosting Regressor Imported successfully
2023-09-28 16:17:47,651:INFO:Starting cross validation
2023-09-28 16:17:47,652:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:17:48,095:INFO:Calculating mean and std
2023-09-28 16:17:48,095:INFO:Creating metrics dataframe
2023-09-28 16:17:48,095:INFO:Finalizing model
2023-09-28 16:17:48,197:INFO:Uploading results into container
2023-09-28 16:17:48,197:INFO:Uploading model into container now
2023-09-28 16:17:48,197:INFO:_master_model_container: 21
2023-09-28 16:17:48,197:INFO:_display_container: 7
2023-09-28 16:17:48,197:INFO:GradientBoostingRegressor(random_state=42)
2023-09-28 16:17:48,197:INFO:create_model() successfully completed......................................
2023-09-28 16:17:48,291:INFO:SubProcess create_model() end ==================================
2023-09-28 16:17:48,292:INFO:GradientBoostingRegressor(random_state=42) result for R2 is 0.9527
2023-09-28 16:17:48,294:INFO:GradientBoostingRegressor(learning_rate=0.4, max_depth=4, max_features='log2',
                          min_impurity_decrease=0, min_samples_leaf=2,
                          min_samples_split=5, n_estimators=110,
                          random_state=42, subsample=0.8) result for R2 is 0.9589
2023-09-28 16:17:48,295:INFO:GradientBoostingRegressor(learning_rate=0.4, max_depth=4, max_features='log2',
                          min_impurity_decrease=0, min_samples_leaf=2,
                          min_samples_split=5, n_estimators=110,
                          random_state=42, subsample=0.8) is best model
2023-09-28 16:17:48,295:INFO:choose_better completed
2023-09-28 16:17:48,295:INFO:_master_model_container: 21
2023-09-28 16:17:48,311:INFO:_display_container: 6
2023-09-28 16:17:48,311:INFO:GradientBoostingRegressor(learning_rate=0.4, max_depth=4, max_features='log2',
                          min_impurity_decrease=0, min_samples_leaf=2,
                          min_samples_split=5, n_estimators=110,
                          random_state=42, subsample=0.8)
2023-09-28 16:17:48,311:INFO:tune_model() successfully completed......................................
2023-09-28 16:17:48,398:INFO:Initializing predict_model()
2023-09-28 16:17:48,398:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023448F92230>, estimator=GradientBoostingRegressor(learning_rate=0.4, max_depth=4, max_features='log2',
                          min_impurity_decrease=0, min_samples_leaf=2,
                          min_samples_split=5, n_estimators=110,
                          random_state=42, subsample=0.8), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000023435364430>)
2023-09-28 16:17:48,398:INFO:Checking exceptions
2023-09-28 16:17:48,398:INFO:Preloading libraries
2023-09-28 16:19:56,950:INFO:Initializing finalize_model()
2023-09-28 16:19:56,950:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023448F92230>, estimator=GradientBoostingRegressor(learning_rate=0.4, max_depth=4, max_features='log2',
                          min_impurity_decrease=0, min_samples_leaf=2,
                          min_samples_split=5, n_estimators=110,
                          random_state=42, subsample=0.8), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-09-28 16:19:56,950:INFO:Finalizing GradientBoostingRegressor(learning_rate=0.4, max_depth=4, max_features='log2',
                          min_impurity_decrease=0, min_samples_leaf=2,
                          min_samples_split=5, n_estimators=110,
                          random_state=42, subsample=0.8)
2023-09-28 16:19:56,950:INFO:Initializing create_model()
2023-09-28 16:19:56,960:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023448F92230>, estimator=GradientBoostingRegressor(learning_rate=0.4, max_depth=4, max_features='log2',
                          min_impurity_decrease=0, min_samples_leaf=2,
                          min_samples_split=5, n_estimators=110,
                          random_state=42, subsample=0.8), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-09-28 16:19:56,960:INFO:Checking exceptions
2023-09-28 16:19:56,964:INFO:Importing libraries
2023-09-28 16:19:56,965:INFO:Copying training dataset
2023-09-28 16:19:56,965:INFO:Defining folds
2023-09-28 16:19:56,965:INFO:Declaring metric variables
2023-09-28 16:19:56,966:INFO:Importing untrained model
2023-09-28 16:19:56,966:INFO:Declaring custom model
2023-09-28 16:19:56,968:INFO:Gradient Boosting Regressor Imported successfully
2023-09-28 16:19:56,969:INFO:Cross validation set to False
2023-09-28 16:19:56,969:INFO:Fitting Model
2023-09-28 16:19:57,172:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['clonesize', 'honeybee', 'bumbles',
                                             'andrena', 'osmia',
                                             'MaxOfUpperTRange',
                                             'MinOfUpperTRange',
                                             'AverageOfUpperTRange',
                                             'MaxOfLowerTRange',
                                             'MinOfLowerTRange',
                                             'AverageOfLowerTRange',
                                             'RainingDays',
                                             'AverageRainingDays'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 GradientBoostingRegressor(learning_rate=0.4, max_depth=4,
                                           max_features='log2',
                                           min_impurity_decrease=0,
                                           min_samples_leaf=2,
                                           min_samples_split=5,
                                           n_estimators=110, random_state=42,
                                           subsample=0.8))])
2023-09-28 16:19:57,172:INFO:create_model() successfully completed......................................
2023-09-28 16:19:57,261:INFO:_master_model_container: 21
2023-09-28 16:19:57,261:INFO:_display_container: 7
2023-09-28 16:19:57,261:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['clonesize', 'honeybee', 'bumbles',
                                             'andrena', 'osmia',
                                             'MaxOfUpperTRange',
                                             'MinOfUpperTRange',
                                             'AverageOfUpperTRange',
                                             'MaxOfLowerTRange',
                                             'MinOfLowerTRange',
                                             'AverageOfLowerTRange',
                                             'RainingDays',
                                             'AverageRainingDays'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 GradientBoostingRegressor(learning_rate=0.4, max_depth=4,
                                           max_features='log2',
                                           min_impurity_decrease=0,
                                           min_samples_leaf=2,
                                           min_samples_split=5,
                                           n_estimators=110, random_state=42,
                                           subsample=0.8))])
2023-09-28 16:19:57,276:INFO:finalize_model() successfully completed......................................
2023-09-28 16:19:57,344:INFO:Initializing save_model()
2023-09-28 16:19:57,344:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['clonesize', 'honeybee', 'bumbles',
                                             'andrena', 'osmia',
                                             'MaxOfUpperTRange',
                                             'MinOfUpperTRange',
                                             'AverageOfUpperTRange',
                                             'MaxOfLowerTRange',
                                             'MinOfLowerTRange',
                                             'AverageOfLowerTRange',
                                             'RainingDays',
                                             'AverageRainingDays'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 GradientBoostingRegressor(learning_rate=0.4, max_depth=4,
                                           max_features='log2',
                                           min_impurity_decrease=0,
                                           min_samples_leaf=2,
                                           min_samples_split=5,
                                           n_estimators=110, random_state=42,
                                           subsample=0.8))]), model_name=pycaret_automl_blueberry_yield_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\maxxk\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['clonesize', 'honeybee', 'bumbles',
                                             'andrena', 'osmia',
                                             'MaxOfUpperTRange',
                                             'MinOfUpperTRange',
                                             'AverageOfUpperTRange',
                                             'MaxOfLowerTRange',
                                             'MinOfLowerTRange',
                                             'AverageOfLowerTRange',
                                             'RainingDays',
                                             'AverageRainingDays'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-09-28 16:19:57,344:INFO:Adding model into prep_pipe
2023-09-28 16:19:57,344:WARNING:Only Model saved as it was a pipeline.
2023-09-28 16:19:57,362:INFO:pycaret_automl_blueberry_yield_model.pkl saved in current working directory
2023-09-28 16:19:57,380:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['clonesize', 'honeybee', 'bumbles',
                                             'andrena', 'osmia',
                                             'MaxOfUpperTRange',
                                             'MinOfUpperTRange',
                                             'AverageOfUpperTRange',
                                             'MaxOfLowerTRange',
                                             'MinOfLowerTRange',
                                             'AverageOfLowerTRange',
                                             'RainingDays',
                                             'AverageRainingDays'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 GradientBoostingRegressor(learning_rate=0.4, max_depth=4,
                                           max_features='log2',
                                           min_impurity_decrease=0,
                                           min_samples_leaf=2,
                                           min_samples_split=5,
                                           n_estimators=110, random_state=42,
                                           subsample=0.8))])
2023-09-28 16:19:57,380:INFO:save_model() successfully completed......................................
2023-09-28 16:21:12,677:INFO:Initializing plot_model()
2023-09-28 16:21:12,677:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(learning_rate=0.4, max_depth=4, max_features='log2',
                          min_impurity_decrease=0, min_samples_leaf=2,
                          min_samples_split=5, n_estimators=110,
                          random_state=42, subsample=0.8), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023448F92230>, system=True)
2023-09-28 16:21:12,678:INFO:Checking exceptions
2023-09-28 16:21:12,682:INFO:Preloading libraries
2023-09-28 16:21:12,698:INFO:Copying training dataset
2023-09-28 16:21:12,698:INFO:Plot type: residuals
2023-09-28 16:21:12,832:INFO:Fitting Model
2023-09-28 16:21:12,861:INFO:Scoring test/hold-out set
2023-09-28 16:21:13,694:INFO:Visual Rendered Successfully
2023-09-28 16:21:13,760:INFO:plot_model() successfully completed......................................
2023-09-28 16:22:52,914:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-28 16:22:52,914:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-28 16:22:52,914:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-28 16:22:52,914:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-28 16:22:53,213:INFO:PyCaret RegressionExperiment
2023-09-28 16:22:53,213:INFO:Logging name: reg-default-name
2023-09-28 16:22:53,213:INFO:ML Usecase: MLUsecase.REGRESSION
2023-09-28 16:22:53,213:INFO:version 3.1.0
2023-09-28 16:22:53,213:INFO:Initializing setup()
2023-09-28 16:22:53,213:INFO:self.USI: 68f5
2023-09-28 16:22:53,213:INFO:self._variable_keys: {'gpu_param', 'seed', 'y_test', 'fold_groups_param', 'fold_shuffle_param', 'memory', '_available_plots', 'X', 'fold_generator', 'X_train', 'y_train', 'pipeline', '_ml_usecase', 'logging_param', 'exp_id', 'log_plots_param', 'y', 'exp_name_log', 'transform_target_param', 'html_param', 'idx', 'n_jobs_param', 'X_test', 'USI', 'target_param', 'gpu_n_jobs_param', 'data'}
2023-09-28 16:22:53,213:INFO:Checking environment
2023-09-28 16:22:53,213:INFO:python_version: 3.10.11
2023-09-28 16:22:53,213:INFO:python_build: ('main', 'May 16 2023 00:55:32')
2023-09-28 16:22:53,213:INFO:machine: AMD64
2023-09-28 16:22:53,213:INFO:platform: Windows-10-10.0.19045-SP0
2023-09-28 16:22:53,213:INFO:Memory: svmem(total=16931770368, available=8261623808, percent=51.2, used=8670146560, free=8261623808)
2023-09-28 16:22:53,213:INFO:Physical Core: 4
2023-09-28 16:22:53,213:INFO:Logical Core: 8
2023-09-28 16:22:53,213:INFO:Checking libraries
2023-09-28 16:22:53,213:INFO:System:
2023-09-28 16:22:53,213:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, May 16 2023, 00:55:32) [MSC v.1916 64 bit (AMD64)]
2023-09-28 16:22:53,213:INFO:executable: p:\Anaconda\envs\jupy\python.exe
2023-09-28 16:22:53,213:INFO:   machine: Windows-10-10.0.19045-SP0
2023-09-28 16:22:53,213:INFO:PyCaret required dependencies:
2023-09-28 16:22:53,253:INFO:                 pip: 23.2.1
2023-09-28 16:22:53,253:INFO:          setuptools: 68.0.0
2023-09-28 16:22:53,253:INFO:             pycaret: 3.1.0
2023-09-28 16:22:53,254:INFO:             IPython: 8.14.0
2023-09-28 16:22:53,254:INFO:          ipywidgets: 8.1.1
2023-09-28 16:22:53,254:INFO:                tqdm: 4.66.1
2023-09-28 16:22:53,254:INFO:               numpy: 1.23.5
2023-09-28 16:22:53,254:INFO:              pandas: 1.5.3
2023-09-28 16:22:53,254:INFO:              jinja2: 3.1.2
2023-09-28 16:22:53,254:INFO:               scipy: 1.11.1
2023-09-28 16:22:53,254:INFO:              joblib: 1.2.0
2023-09-28 16:22:53,254:INFO:             sklearn: 1.3.0
2023-09-28 16:22:53,254:INFO:                pyod: 1.1.0
2023-09-28 16:22:53,254:INFO:            imblearn: 0.11.0
2023-09-28 16:22:53,254:INFO:   category_encoders: 2.6.2
2023-09-28 16:22:53,254:INFO:            lightgbm: 4.1.0
2023-09-28 16:22:53,254:INFO:               numba: 0.57.1
2023-09-28 16:22:53,254:INFO:            requests: 2.31.0
2023-09-28 16:22:53,254:INFO:          matplotlib: 3.7.3
2023-09-28 16:22:53,254:INFO:          scikitplot: 0.3.7
2023-09-28 16:22:53,254:INFO:         yellowbrick: 1.5
2023-09-28 16:22:53,254:INFO:              plotly: 5.17.0
2023-09-28 16:22:53,254:INFO:    plotly-resampler: Not installed
2023-09-28 16:22:53,254:INFO:             kaleido: 0.2.1
2023-09-28 16:22:53,254:INFO:           schemdraw: 0.15
2023-09-28 16:22:53,254:INFO:         statsmodels: 0.14.0
2023-09-28 16:22:53,254:INFO:              sktime: 0.21.1
2023-09-28 16:22:53,254:INFO:               tbats: 1.1.3
2023-09-28 16:22:53,255:INFO:            pmdarima: 2.0.3
2023-09-28 16:22:53,255:INFO:              psutil: 5.9.5
2023-09-28 16:22:53,255:INFO:          markupsafe: 2.1.3
2023-09-28 16:22:53,255:INFO:             pickle5: Not installed
2023-09-28 16:22:53,255:INFO:         cloudpickle: 2.2.1
2023-09-28 16:22:53,255:INFO:         deprecation: 2.1.0
2023-09-28 16:22:53,255:INFO:              xxhash: 3.3.0
2023-09-28 16:22:53,255:INFO:           wurlitzer: Not installed
2023-09-28 16:22:53,255:INFO:PyCaret optional dependencies:
2023-09-28 16:22:53,659:INFO:                shap: 0.42.1
2023-09-28 16:22:53,659:INFO:           interpret: Not installed
2023-09-28 16:22:53,659:INFO:                umap: Not installed
2023-09-28 16:22:53,659:INFO:     ydata_profiling: Not installed
2023-09-28 16:22:53,659:INFO:  explainerdashboard: Not installed
2023-09-28 16:22:53,659:INFO:             autoviz: Not installed
2023-09-28 16:22:53,659:INFO:           fairlearn: Not installed
2023-09-28 16:22:53,659:INFO:          deepchecks: Not installed
2023-09-28 16:22:53,659:INFO:             xgboost: 2.0.0
2023-09-28 16:22:53,659:INFO:            catboost: Not installed
2023-09-28 16:22:53,659:INFO:              kmodes: Not installed
2023-09-28 16:22:53,659:INFO:             mlxtend: Not installed
2023-09-28 16:22:53,659:INFO:       statsforecast: Not installed
2023-09-28 16:22:53,659:INFO:        tune_sklearn: Not installed
2023-09-28 16:22:53,659:INFO:                 ray: Not installed
2023-09-28 16:22:53,659:INFO:            hyperopt: Not installed
2023-09-28 16:22:53,659:INFO:              optuna: 3.3.0
2023-09-28 16:22:53,659:INFO:               skopt: Not installed
2023-09-28 16:22:53,659:INFO:              mlflow: Not installed
2023-09-28 16:22:53,659:INFO:              gradio: Not installed
2023-09-28 16:22:53,659:INFO:             fastapi: 0.103.1
2023-09-28 16:22:53,659:INFO:             uvicorn: 0.23.2
2023-09-28 16:22:53,659:INFO:              m2cgen: Not installed
2023-09-28 16:22:53,659:INFO:           evidently: 0.4.5
2023-09-28 16:22:53,659:INFO:               fugue: Not installed
2023-09-28 16:22:53,659:INFO:           streamlit: 1.26.0
2023-09-28 16:22:53,659:INFO:             prophet: Not installed
2023-09-28 16:22:53,659:INFO:None
2023-09-28 16:22:53,659:INFO:Set up data.
2023-09-28 16:22:53,677:INFO:Set up folding strategy.
2023-09-28 16:22:53,677:INFO:Set up train/test split.
2023-09-28 16:22:53,677:INFO:Set up index.
2023-09-28 16:22:53,677:INFO:Assigning column types.
2023-09-28 16:22:53,677:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-09-28 16:22:53,677:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-09-28 16:22:53,677:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-28 16:22:53,692:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-28 16:22:53,747:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-28 16:22:53,794:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-28 16:22:53,794:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:22:53,810:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:22:53,810:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-09-28 16:22:53,810:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-28 16:22:53,810:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-28 16:22:53,894:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-28 16:22:53,948:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-28 16:22:53,948:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:22:53,948:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:22:53,948:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-09-28 16:22:53,965:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-28 16:22:53,965:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-28 16:22:54,061:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-28 16:22:54,127:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-28 16:22:54,127:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:22:54,127:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:22:54,143:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-28 16:22:54,143:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-28 16:22:54,212:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-28 16:22:54,258:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-28 16:22:54,258:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:22:54,258:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:22:54,258:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-09-28 16:22:54,274:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-28 16:22:54,327:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-28 16:22:54,376:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-28 16:22:54,392:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:22:54,396:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:22:54,400:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-28 16:22:54,477:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-28 16:22:54,529:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-28 16:22:54,529:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:22:54,529:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:22:54,529:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-09-28 16:22:54,627:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-28 16:22:54,677:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-28 16:22:54,677:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:22:54,677:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:22:54,745:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-28 16:22:54,792:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-28 16:22:54,792:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:22:54,792:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:22:54,792:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-09-28 16:22:54,878:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-28 16:22:54,926:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:22:54,944:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:22:55,027:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-28 16:22:55,079:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:22:55,093:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:22:55,093:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-09-28 16:22:55,225:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:22:55,240:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:22:55,363:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:22:55,363:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:22:55,363:INFO:Preparing preprocessing pipeline...
2023-09-28 16:22:55,363:INFO:Set up simple imputation.
2023-09-28 16:22:55,395:INFO:Finished creating preprocessing pipeline.
2023-09-28 16:22:55,395:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\maxxk\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['clonesize', 'honeybee', 'bumbles',
                                             'andrena', 'osmia',
                                             'MaxOfUpperTRange',
                                             'MinOfUpperTRange',
                                             'AverageOfUpperTRange',
                                             'MaxOfLowerTRange',
                                             'MinOfLowerTRange',
                                             'AverageOfLowerTRange',
                                             'RainingDays',
                                             'AverageRainingDays'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-09-28 16:22:55,395:INFO:Creating final display dataframe.
2023-09-28 16:22:55,480:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target             yield
2                   Target type        Regression
3           Original data shape         (777, 14)
4        Transformed data shape         (777, 14)
5   Transformed train set shape         (543, 14)
6    Transformed test set shape         (234, 14)
7              Numeric features                13
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              68f5
2023-09-28 16:22:55,664:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:22:55,668:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:22:55,794:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:22:55,794:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:22:55,794:INFO:setup() successfully completed in 2.58s...............
2023-09-28 16:23:11,381:INFO:Initializing compare_models()
2023-09-28 16:23:11,381:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269A469E170>, include=None, fold=None, round=4, cross_validation=True, sort=RMSE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000269A469E170>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'RMSE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-09-28 16:23:11,381:INFO:Checking exceptions
2023-09-28 16:23:11,383:INFO:Preparing display monitor
2023-09-28 16:23:11,424:INFO:Initializing Linear Regression
2023-09-28 16:23:11,424:INFO:Total runtime is 0.0 minutes
2023-09-28 16:23:11,431:INFO:SubProcess create_model() called ==================================
2023-09-28 16:23:11,431:INFO:Initializing create_model()
2023-09-28 16:23:11,432:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269A469E170>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026994C0A7D0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:23:11,432:INFO:Checking exceptions
2023-09-28 16:23:11,432:INFO:Importing libraries
2023-09-28 16:23:11,432:INFO:Copying training dataset
2023-09-28 16:23:11,440:INFO:Defining folds
2023-09-28 16:23:11,441:INFO:Declaring metric variables
2023-09-28 16:23:11,447:INFO:Importing untrained model
2023-09-28 16:23:11,453:INFO:Linear Regression Imported successfully
2023-09-28 16:23:11,469:INFO:Starting cross validation
2023-09-28 16:23:11,480:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:23:19,766:INFO:Calculating mean and std
2023-09-28 16:23:19,766:INFO:Creating metrics dataframe
2023-09-28 16:23:19,773:INFO:Uploading results into container
2023-09-28 16:23:19,775:INFO:Uploading model into container now
2023-09-28 16:23:19,776:INFO:_master_model_container: 1
2023-09-28 16:23:19,777:INFO:_display_container: 2
2023-09-28 16:23:19,777:INFO:LinearRegression(n_jobs=-1)
2023-09-28 16:23:19,777:INFO:create_model() successfully completed......................................
2023-09-28 16:23:19,859:INFO:SubProcess create_model() end ==================================
2023-09-28 16:23:19,867:INFO:Creating metrics dataframe
2023-09-28 16:23:19,879:INFO:Initializing Lasso Regression
2023-09-28 16:23:19,879:INFO:Total runtime is 0.14091354211171467 minutes
2023-09-28 16:23:19,884:INFO:SubProcess create_model() called ==================================
2023-09-28 16:23:19,885:INFO:Initializing create_model()
2023-09-28 16:23:19,885:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269A469E170>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026994C0A7D0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:23:19,885:INFO:Checking exceptions
2023-09-28 16:23:19,885:INFO:Importing libraries
2023-09-28 16:23:19,885:INFO:Copying training dataset
2023-09-28 16:23:19,891:INFO:Defining folds
2023-09-28 16:23:19,891:INFO:Declaring metric variables
2023-09-28 16:23:19,894:INFO:Importing untrained model
2023-09-28 16:23:19,894:INFO:Lasso Regression Imported successfully
2023-09-28 16:23:19,915:INFO:Starting cross validation
2023-09-28 16:23:19,916:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:23:19,952:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.455e+07, tolerance: 8.787e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:23:19,955:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.717e+07, tolerance: 8.750e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:23:19,965:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.406e+07, tolerance: 8.527e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:23:19,969:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.482e+07, tolerance: 8.741e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:23:19,977:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.686e+07, tolerance: 8.176e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:23:19,977:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.041e+07, tolerance: 8.833e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:23:19,993:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.775e+07, tolerance: 8.728e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:23:20,014:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.859e+07, tolerance: 8.783e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:23:20,015:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.710e+07, tolerance: 8.812e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:23:20,015:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.878e+07, tolerance: 8.614e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:23:20,030:INFO:Calculating mean and std
2023-09-28 16:23:20,030:INFO:Creating metrics dataframe
2023-09-28 16:23:20,030:INFO:Uploading results into container
2023-09-28 16:23:20,030:INFO:Uploading model into container now
2023-09-28 16:23:20,030:INFO:_master_model_container: 2
2023-09-28 16:23:20,030:INFO:_display_container: 2
2023-09-28 16:23:20,030:INFO:Lasso(random_state=42)
2023-09-28 16:23:20,030:INFO:create_model() successfully completed......................................
2023-09-28 16:23:20,094:INFO:SubProcess create_model() end ==================================
2023-09-28 16:23:20,094:INFO:Creating metrics dataframe
2023-09-28 16:23:20,111:INFO:Initializing Ridge Regression
2023-09-28 16:23:20,111:INFO:Total runtime is 0.14478143056233722 minutes
2023-09-28 16:23:20,111:INFO:SubProcess create_model() called ==================================
2023-09-28 16:23:20,111:INFO:Initializing create_model()
2023-09-28 16:23:20,111:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269A469E170>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026994C0A7D0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:23:20,111:INFO:Checking exceptions
2023-09-28 16:23:20,111:INFO:Importing libraries
2023-09-28 16:23:20,111:INFO:Copying training dataset
2023-09-28 16:23:20,111:INFO:Defining folds
2023-09-28 16:23:20,111:INFO:Declaring metric variables
2023-09-28 16:23:20,111:INFO:Importing untrained model
2023-09-28 16:23:20,130:INFO:Ridge Regression Imported successfully
2023-09-28 16:23:20,138:INFO:Starting cross validation
2023-09-28 16:23:20,138:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:23:20,259:INFO:Calculating mean and std
2023-09-28 16:23:20,259:INFO:Creating metrics dataframe
2023-09-28 16:23:20,259:INFO:Uploading results into container
2023-09-28 16:23:20,259:INFO:Uploading model into container now
2023-09-28 16:23:20,259:INFO:_master_model_container: 3
2023-09-28 16:23:20,259:INFO:_display_container: 2
2023-09-28 16:23:20,259:INFO:Ridge(random_state=42)
2023-09-28 16:23:20,259:INFO:create_model() successfully completed......................................
2023-09-28 16:23:20,327:INFO:SubProcess create_model() end ==================================
2023-09-28 16:23:20,327:INFO:Creating metrics dataframe
2023-09-28 16:23:20,346:INFO:Initializing Elastic Net
2023-09-28 16:23:20,346:INFO:Total runtime is 0.14869141181310017 minutes
2023-09-28 16:23:20,346:INFO:SubProcess create_model() called ==================================
2023-09-28 16:23:20,346:INFO:Initializing create_model()
2023-09-28 16:23:20,346:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269A469E170>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026994C0A7D0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:23:20,346:INFO:Checking exceptions
2023-09-28 16:23:20,346:INFO:Importing libraries
2023-09-28 16:23:20,346:INFO:Copying training dataset
2023-09-28 16:23:20,346:INFO:Defining folds
2023-09-28 16:23:20,346:INFO:Declaring metric variables
2023-09-28 16:23:20,361:INFO:Importing untrained model
2023-09-28 16:23:20,368:INFO:Elastic Net Imported successfully
2023-09-28 16:23:20,382:INFO:Starting cross validation
2023-09-28 16:23:20,385:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:23:20,527:INFO:Calculating mean and std
2023-09-28 16:23:20,528:INFO:Creating metrics dataframe
2023-09-28 16:23:20,528:INFO:Uploading results into container
2023-09-28 16:23:20,528:INFO:Uploading model into container now
2023-09-28 16:23:20,538:INFO:_master_model_container: 4
2023-09-28 16:23:20,538:INFO:_display_container: 2
2023-09-28 16:23:20,538:INFO:ElasticNet(random_state=42)
2023-09-28 16:23:20,539:INFO:create_model() successfully completed......................................
2023-09-28 16:23:20,611:INFO:SubProcess create_model() end ==================================
2023-09-28 16:23:20,611:INFO:Creating metrics dataframe
2023-09-28 16:23:20,627:INFO:Initializing Least Angle Regression
2023-09-28 16:23:20,627:INFO:Total runtime is 0.15337937275568642 minutes
2023-09-28 16:23:20,627:INFO:SubProcess create_model() called ==================================
2023-09-28 16:23:20,627:INFO:Initializing create_model()
2023-09-28 16:23:20,627:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269A469E170>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026994C0A7D0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:23:20,627:INFO:Checking exceptions
2023-09-28 16:23:20,627:INFO:Importing libraries
2023-09-28 16:23:20,627:INFO:Copying training dataset
2023-09-28 16:23:20,627:INFO:Defining folds
2023-09-28 16:23:20,627:INFO:Declaring metric variables
2023-09-28 16:23:20,627:INFO:Importing untrained model
2023-09-28 16:23:20,646:INFO:Least Angle Regression Imported successfully
2023-09-28 16:23:20,652:INFO:Starting cross validation
2023-09-28 16:23:20,652:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:23:20,763:INFO:Calculating mean and std
2023-09-28 16:23:20,763:INFO:Creating metrics dataframe
2023-09-28 16:23:20,763:INFO:Uploading results into container
2023-09-28 16:23:20,763:INFO:Uploading model into container now
2023-09-28 16:23:20,763:INFO:_master_model_container: 5
2023-09-28 16:23:20,763:INFO:_display_container: 2
2023-09-28 16:23:20,763:INFO:Lars(random_state=42)
2023-09-28 16:23:20,763:INFO:create_model() successfully completed......................................
2023-09-28 16:23:20,827:INFO:SubProcess create_model() end ==================================
2023-09-28 16:23:20,827:INFO:Creating metrics dataframe
2023-09-28 16:23:20,843:INFO:Initializing Lasso Least Angle Regression
2023-09-28 16:23:20,843:INFO:Total runtime is 0.15698097546895343 minutes
2023-09-28 16:23:20,843:INFO:SubProcess create_model() called ==================================
2023-09-28 16:23:20,843:INFO:Initializing create_model()
2023-09-28 16:23:20,843:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269A469E170>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026994C0A7D0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:23:20,843:INFO:Checking exceptions
2023-09-28 16:23:20,843:INFO:Importing libraries
2023-09-28 16:23:20,843:INFO:Copying training dataset
2023-09-28 16:23:20,843:INFO:Defining folds
2023-09-28 16:23:20,843:INFO:Declaring metric variables
2023-09-28 16:23:20,862:INFO:Importing untrained model
2023-09-28 16:23:20,866:INFO:Lasso Least Angle Regression Imported successfully
2023-09-28 16:23:20,880:INFO:Starting cross validation
2023-09-28 16:23:20,882:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:23:20,980:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 11 iterations, alpha=3.334e+00, previous alpha=3.244e+00, with an active set of 10 regressors.
  warnings.warn(

2023-09-28 16:23:20,996:INFO:Calculating mean and std
2023-09-28 16:23:20,996:INFO:Creating metrics dataframe
2023-09-28 16:23:20,996:INFO:Uploading results into container
2023-09-28 16:23:20,996:INFO:Uploading model into container now
2023-09-28 16:23:20,996:INFO:_master_model_container: 6
2023-09-28 16:23:20,996:INFO:_display_container: 2
2023-09-28 16:23:20,996:INFO:LassoLars(random_state=42)
2023-09-28 16:23:20,996:INFO:create_model() successfully completed......................................
2023-09-28 16:23:21,061:INFO:SubProcess create_model() end ==================================
2023-09-28 16:23:21,061:INFO:Creating metrics dataframe
2023-09-28 16:23:21,077:INFO:Initializing Orthogonal Matching Pursuit
2023-09-28 16:23:21,077:INFO:Total runtime is 0.160875924428304 minutes
2023-09-28 16:23:21,077:INFO:SubProcess create_model() called ==================================
2023-09-28 16:23:21,077:INFO:Initializing create_model()
2023-09-28 16:23:21,077:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269A469E170>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026994C0A7D0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:23:21,077:INFO:Checking exceptions
2023-09-28 16:23:21,077:INFO:Importing libraries
2023-09-28 16:23:21,077:INFO:Copying training dataset
2023-09-28 16:23:21,077:INFO:Defining folds
2023-09-28 16:23:21,077:INFO:Declaring metric variables
2023-09-28 16:23:21,077:INFO:Importing untrained model
2023-09-28 16:23:21,097:INFO:Orthogonal Matching Pursuit Imported successfully
2023-09-28 16:23:21,103:INFO:Starting cross validation
2023-09-28 16:23:21,103:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:23:21,213:INFO:Calculating mean and std
2023-09-28 16:23:21,213:INFO:Creating metrics dataframe
2023-09-28 16:23:21,213:INFO:Uploading results into container
2023-09-28 16:23:21,213:INFO:Uploading model into container now
2023-09-28 16:23:21,213:INFO:_master_model_container: 7
2023-09-28 16:23:21,213:INFO:_display_container: 2
2023-09-28 16:23:21,213:INFO:OrthogonalMatchingPursuit()
2023-09-28 16:23:21,213:INFO:create_model() successfully completed......................................
2023-09-28 16:23:21,293:INFO:SubProcess create_model() end ==================================
2023-09-28 16:23:21,293:INFO:Creating metrics dataframe
2023-09-28 16:23:21,296:INFO:Initializing Bayesian Ridge
2023-09-28 16:23:21,296:INFO:Total runtime is 0.16452676455179846 minutes
2023-09-28 16:23:21,312:INFO:SubProcess create_model() called ==================================
2023-09-28 16:23:21,312:INFO:Initializing create_model()
2023-09-28 16:23:21,312:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269A469E170>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026994C0A7D0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:23:21,312:INFO:Checking exceptions
2023-09-28 16:23:21,312:INFO:Importing libraries
2023-09-28 16:23:21,312:INFO:Copying training dataset
2023-09-28 16:23:21,315:INFO:Defining folds
2023-09-28 16:23:21,315:INFO:Declaring metric variables
2023-09-28 16:23:21,315:INFO:Importing untrained model
2023-09-28 16:23:21,327:INFO:Bayesian Ridge Imported successfully
2023-09-28 16:23:21,349:INFO:Starting cross validation
2023-09-28 16:23:21,350:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:23:21,594:INFO:Calculating mean and std
2023-09-28 16:23:21,594:INFO:Creating metrics dataframe
2023-09-28 16:23:21,594:INFO:Uploading results into container
2023-09-28 16:23:21,594:INFO:Uploading model into container now
2023-09-28 16:23:21,594:INFO:_master_model_container: 8
2023-09-28 16:23:21,594:INFO:_display_container: 2
2023-09-28 16:23:21,594:INFO:BayesianRidge()
2023-09-28 16:23:21,594:INFO:create_model() successfully completed......................................
2023-09-28 16:23:21,661:INFO:SubProcess create_model() end ==================================
2023-09-28 16:23:21,661:INFO:Creating metrics dataframe
2023-09-28 16:23:21,677:INFO:Initializing Passive Aggressive Regressor
2023-09-28 16:23:21,677:INFO:Total runtime is 0.17087473471959427 minutes
2023-09-28 16:23:21,694:INFO:SubProcess create_model() called ==================================
2023-09-28 16:23:21,695:INFO:Initializing create_model()
2023-09-28 16:23:21,695:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269A469E170>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026994C0A7D0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:23:21,695:INFO:Checking exceptions
2023-09-28 16:23:21,695:INFO:Importing libraries
2023-09-28 16:23:21,695:INFO:Copying training dataset
2023-09-28 16:23:21,695:INFO:Defining folds
2023-09-28 16:23:21,695:INFO:Declaring metric variables
2023-09-28 16:23:21,695:INFO:Importing untrained model
2023-09-28 16:23:21,695:INFO:Passive Aggressive Regressor Imported successfully
2023-09-28 16:23:21,717:INFO:Starting cross validation
2023-09-28 16:23:21,718:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:23:21,863:INFO:Calculating mean and std
2023-09-28 16:23:21,863:INFO:Creating metrics dataframe
2023-09-28 16:23:21,863:INFO:Uploading results into container
2023-09-28 16:23:21,863:INFO:Uploading model into container now
2023-09-28 16:23:21,863:INFO:_master_model_container: 9
2023-09-28 16:23:21,871:INFO:_display_container: 2
2023-09-28 16:23:21,871:INFO:PassiveAggressiveRegressor(random_state=42)
2023-09-28 16:23:21,871:INFO:create_model() successfully completed......................................
2023-09-28 16:23:21,927:INFO:SubProcess create_model() end ==================================
2023-09-28 16:23:21,927:INFO:Creating metrics dataframe
2023-09-28 16:23:21,944:INFO:Initializing Huber Regressor
2023-09-28 16:23:21,944:INFO:Total runtime is 0.17531825701395665 minutes
2023-09-28 16:23:21,944:INFO:SubProcess create_model() called ==================================
2023-09-28 16:23:21,944:INFO:Initializing create_model()
2023-09-28 16:23:21,944:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269A469E170>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026994C0A7D0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:23:21,944:INFO:Checking exceptions
2023-09-28 16:23:21,944:INFO:Importing libraries
2023-09-28 16:23:21,944:INFO:Copying training dataset
2023-09-28 16:23:21,944:INFO:Defining folds
2023-09-28 16:23:21,944:INFO:Declaring metric variables
2023-09-28 16:23:21,944:INFO:Importing untrained model
2023-09-28 16:23:21,962:INFO:Huber Regressor Imported successfully
2023-09-28 16:23:21,973:INFO:Starting cross validation
2023-09-28 16:23:21,973:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:23:22,078:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-28 16:23:22,111:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-28 16:23:22,111:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-28 16:23:22,111:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-28 16:23:22,132:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-28 16:23:22,146:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-28 16:23:22,146:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-28 16:23:22,161:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-28 16:23:22,193:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-28 16:23:22,197:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-28 16:23:22,226:INFO:Calculating mean and std
2023-09-28 16:23:22,226:INFO:Creating metrics dataframe
2023-09-28 16:23:22,230:INFO:Uploading results into container
2023-09-28 16:23:22,231:INFO:Uploading model into container now
2023-09-28 16:23:22,232:INFO:_master_model_container: 10
2023-09-28 16:23:22,232:INFO:_display_container: 2
2023-09-28 16:23:22,233:INFO:HuberRegressor()
2023-09-28 16:23:22,233:INFO:create_model() successfully completed......................................
2023-09-28 16:23:22,303:INFO:SubProcess create_model() end ==================================
2023-09-28 16:23:22,303:INFO:Creating metrics dataframe
2023-09-28 16:23:22,314:INFO:Initializing K Neighbors Regressor
2023-09-28 16:23:22,314:INFO:Total runtime is 0.18148831923802689 minutes
2023-09-28 16:23:22,326:INFO:SubProcess create_model() called ==================================
2023-09-28 16:23:22,326:INFO:Initializing create_model()
2023-09-28 16:23:22,327:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269A469E170>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026994C0A7D0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:23:22,328:INFO:Checking exceptions
2023-09-28 16:23:22,328:INFO:Importing libraries
2023-09-28 16:23:22,328:INFO:Copying training dataset
2023-09-28 16:23:22,332:INFO:Defining folds
2023-09-28 16:23:22,332:INFO:Declaring metric variables
2023-09-28 16:23:22,336:INFO:Importing untrained model
2023-09-28 16:23:22,339:INFO:K Neighbors Regressor Imported successfully
2023-09-28 16:23:22,354:INFO:Starting cross validation
2023-09-28 16:23:22,354:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:23:22,560:INFO:Calculating mean and std
2023-09-28 16:23:22,561:INFO:Creating metrics dataframe
2023-09-28 16:23:22,567:INFO:Uploading results into container
2023-09-28 16:23:22,567:INFO:Uploading model into container now
2023-09-28 16:23:22,567:INFO:_master_model_container: 11
2023-09-28 16:23:22,567:INFO:_display_container: 2
2023-09-28 16:23:22,567:INFO:KNeighborsRegressor(n_jobs=-1)
2023-09-28 16:23:22,567:INFO:create_model() successfully completed......................................
2023-09-28 16:23:22,644:INFO:SubProcess create_model() end ==================================
2023-09-28 16:23:22,644:INFO:Creating metrics dataframe
2023-09-28 16:23:22,660:INFO:Initializing Decision Tree Regressor
2023-09-28 16:23:22,660:INFO:Total runtime is 0.1872654795646667 minutes
2023-09-28 16:23:22,660:INFO:SubProcess create_model() called ==================================
2023-09-28 16:23:22,660:INFO:Initializing create_model()
2023-09-28 16:23:22,660:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269A469E170>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026994C0A7D0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:23:22,660:INFO:Checking exceptions
2023-09-28 16:23:22,669:INFO:Importing libraries
2023-09-28 16:23:22,669:INFO:Copying training dataset
2023-09-28 16:23:22,669:INFO:Defining folds
2023-09-28 16:23:22,669:INFO:Declaring metric variables
2023-09-28 16:23:22,669:INFO:Importing untrained model
2023-09-28 16:23:22,682:INFO:Decision Tree Regressor Imported successfully
2023-09-28 16:23:22,690:INFO:Starting cross validation
2023-09-28 16:23:22,693:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:23:22,809:INFO:Calculating mean and std
2023-09-28 16:23:22,810:INFO:Creating metrics dataframe
2023-09-28 16:23:22,816:INFO:Uploading results into container
2023-09-28 16:23:22,816:INFO:Uploading model into container now
2023-09-28 16:23:22,816:INFO:_master_model_container: 12
2023-09-28 16:23:22,816:INFO:_display_container: 2
2023-09-28 16:23:22,816:INFO:DecisionTreeRegressor(random_state=42)
2023-09-28 16:23:22,816:INFO:create_model() successfully completed......................................
2023-09-28 16:23:22,882:INFO:SubProcess create_model() end ==================================
2023-09-28 16:23:22,882:INFO:Creating metrics dataframe
2023-09-28 16:23:22,897:INFO:Initializing Random Forest Regressor
2023-09-28 16:23:22,897:INFO:Total runtime is 0.19120231866836543 minutes
2023-09-28 16:23:22,900:INFO:SubProcess create_model() called ==================================
2023-09-28 16:23:22,900:INFO:Initializing create_model()
2023-09-28 16:23:22,900:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269A469E170>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026994C0A7D0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:23:22,900:INFO:Checking exceptions
2023-09-28 16:23:22,900:INFO:Importing libraries
2023-09-28 16:23:22,900:INFO:Copying training dataset
2023-09-28 16:23:22,900:INFO:Defining folds
2023-09-28 16:23:22,900:INFO:Declaring metric variables
2023-09-28 16:23:22,914:INFO:Importing untrained model
2023-09-28 16:23:22,919:INFO:Random Forest Regressor Imported successfully
2023-09-28 16:23:22,931:INFO:Starting cross validation
2023-09-28 16:23:22,931:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:23:24,197:INFO:Calculating mean and std
2023-09-28 16:23:24,197:INFO:Creating metrics dataframe
2023-09-28 16:23:24,197:INFO:Uploading results into container
2023-09-28 16:23:24,197:INFO:Uploading model into container now
2023-09-28 16:23:24,197:INFO:_master_model_container: 13
2023-09-28 16:23:24,197:INFO:_display_container: 2
2023-09-28 16:23:24,197:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-09-28 16:23:24,197:INFO:create_model() successfully completed......................................
2023-09-28 16:23:24,260:INFO:SubProcess create_model() end ==================================
2023-09-28 16:23:24,260:INFO:Creating metrics dataframe
2023-09-28 16:23:24,291:INFO:Initializing Extra Trees Regressor
2023-09-28 16:23:24,291:INFO:Total runtime is 0.21444828907648716 minutes
2023-09-28 16:23:24,291:INFO:SubProcess create_model() called ==================================
2023-09-28 16:23:24,291:INFO:Initializing create_model()
2023-09-28 16:23:24,291:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269A469E170>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026994C0A7D0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:23:24,291:INFO:Checking exceptions
2023-09-28 16:23:24,291:INFO:Importing libraries
2023-09-28 16:23:24,291:INFO:Copying training dataset
2023-09-28 16:23:24,291:INFO:Defining folds
2023-09-28 16:23:24,291:INFO:Declaring metric variables
2023-09-28 16:23:24,307:INFO:Importing untrained model
2023-09-28 16:23:24,311:INFO:Extra Trees Regressor Imported successfully
2023-09-28 16:23:24,321:INFO:Starting cross validation
2023-09-28 16:23:24,322:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:23:25,259:INFO:Calculating mean and std
2023-09-28 16:23:25,261:INFO:Creating metrics dataframe
2023-09-28 16:23:25,261:INFO:Uploading results into container
2023-09-28 16:23:25,261:INFO:Uploading model into container now
2023-09-28 16:23:25,261:INFO:_master_model_container: 14
2023-09-28 16:23:25,271:INFO:_display_container: 2
2023-09-28 16:23:25,271:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2023-09-28 16:23:25,272:INFO:create_model() successfully completed......................................
2023-09-28 16:23:25,338:INFO:SubProcess create_model() end ==================================
2023-09-28 16:23:25,338:INFO:Creating metrics dataframe
2023-09-28 16:23:25,344:INFO:Initializing AdaBoost Regressor
2023-09-28 16:23:25,344:INFO:Total runtime is 0.23198540210723873 minutes
2023-09-28 16:23:25,344:INFO:SubProcess create_model() called ==================================
2023-09-28 16:23:25,344:INFO:Initializing create_model()
2023-09-28 16:23:25,344:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269A469E170>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026994C0A7D0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:23:25,344:INFO:Checking exceptions
2023-09-28 16:23:25,344:INFO:Importing libraries
2023-09-28 16:23:25,344:INFO:Copying training dataset
2023-09-28 16:23:25,360:INFO:Defining folds
2023-09-28 16:23:25,360:INFO:Declaring metric variables
2023-09-28 16:23:25,360:INFO:Importing untrained model
2023-09-28 16:23:25,360:INFO:AdaBoost Regressor Imported successfully
2023-09-28 16:23:25,377:INFO:Starting cross validation
2023-09-28 16:23:25,377:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:23:25,942:INFO:Calculating mean and std
2023-09-28 16:23:25,944:INFO:Creating metrics dataframe
2023-09-28 16:23:25,946:INFO:Uploading results into container
2023-09-28 16:23:25,946:INFO:Uploading model into container now
2023-09-28 16:23:25,946:INFO:_master_model_container: 15
2023-09-28 16:23:25,946:INFO:_display_container: 2
2023-09-28 16:23:25,946:INFO:AdaBoostRegressor(random_state=42)
2023-09-28 16:23:25,946:INFO:create_model() successfully completed......................................
2023-09-28 16:23:26,010:INFO:SubProcess create_model() end ==================================
2023-09-28 16:23:26,010:INFO:Creating metrics dataframe
2023-09-28 16:23:26,010:INFO:Initializing Gradient Boosting Regressor
2023-09-28 16:23:26,010:INFO:Total runtime is 0.24309430519739783 minutes
2023-09-28 16:23:26,027:INFO:SubProcess create_model() called ==================================
2023-09-28 16:23:26,028:INFO:Initializing create_model()
2023-09-28 16:23:26,028:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269A469E170>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026994C0A7D0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:23:26,028:INFO:Checking exceptions
2023-09-28 16:23:26,028:INFO:Importing libraries
2023-09-28 16:23:26,028:INFO:Copying training dataset
2023-09-28 16:23:26,031:INFO:Defining folds
2023-09-28 16:23:26,031:INFO:Declaring metric variables
2023-09-28 16:23:26,034:INFO:Importing untrained model
2023-09-28 16:23:26,038:INFO:Gradient Boosting Regressor Imported successfully
2023-09-28 16:23:26,048:INFO:Starting cross validation
2023-09-28 16:23:26,048:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:23:26,426:INFO:Calculating mean and std
2023-09-28 16:23:26,427:INFO:Creating metrics dataframe
2023-09-28 16:23:26,430:INFO:Uploading results into container
2023-09-28 16:23:26,431:INFO:Uploading model into container now
2023-09-28 16:23:26,431:INFO:_master_model_container: 16
2023-09-28 16:23:26,431:INFO:_display_container: 2
2023-09-28 16:23:26,431:INFO:GradientBoostingRegressor(random_state=42)
2023-09-28 16:23:26,432:INFO:create_model() successfully completed......................................
2023-09-28 16:23:26,477:INFO:SubProcess create_model() end ==================================
2023-09-28 16:23:26,477:INFO:Creating metrics dataframe
2023-09-28 16:23:26,495:INFO:Initializing Extreme Gradient Boosting
2023-09-28 16:23:26,495:INFO:Total runtime is 0.2511807521184285 minutes
2023-09-28 16:23:26,495:INFO:SubProcess create_model() called ==================================
2023-09-28 16:23:26,495:INFO:Initializing create_model()
2023-09-28 16:23:26,495:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269A469E170>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026994C0A7D0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:23:26,495:INFO:Checking exceptions
2023-09-28 16:23:26,495:INFO:Importing libraries
2023-09-28 16:23:26,495:INFO:Copying training dataset
2023-09-28 16:23:26,510:INFO:Defining folds
2023-09-28 16:23:26,510:INFO:Declaring metric variables
2023-09-28 16:23:26,510:INFO:Importing untrained model
2023-09-28 16:23:26,510:INFO:Extreme Gradient Boosting Imported successfully
2023-09-28 16:23:26,524:INFO:Starting cross validation
2023-09-28 16:23:26,526:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:23:27,893:INFO:Calculating mean and std
2023-09-28 16:23:27,893:INFO:Creating metrics dataframe
2023-09-28 16:23:27,899:INFO:Uploading results into container
2023-09-28 16:23:27,899:INFO:Uploading model into container now
2023-09-28 16:23:27,899:INFO:_master_model_container: 17
2023-09-28 16:23:27,899:INFO:_display_container: 2
2023-09-28 16:23:27,899:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=42, ...)
2023-09-28 16:23:27,899:INFO:create_model() successfully completed......................................
2023-09-28 16:23:27,960:INFO:SubProcess create_model() end ==================================
2023-09-28 16:23:27,960:INFO:Creating metrics dataframe
2023-09-28 16:23:27,960:INFO:Initializing Light Gradient Boosting Machine
2023-09-28 16:23:27,960:INFO:Total runtime is 0.27559422651926674 minutes
2023-09-28 16:23:27,979:INFO:SubProcess create_model() called ==================================
2023-09-28 16:23:27,980:INFO:Initializing create_model()
2023-09-28 16:23:27,980:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269A469E170>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026994C0A7D0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:23:27,980:INFO:Checking exceptions
2023-09-28 16:23:27,980:INFO:Importing libraries
2023-09-28 16:23:27,980:INFO:Copying training dataset
2023-09-28 16:23:27,980:INFO:Defining folds
2023-09-28 16:23:27,980:INFO:Declaring metric variables
2023-09-28 16:23:27,980:INFO:Importing untrained model
2023-09-28 16:23:27,980:INFO:Light Gradient Boosting Machine Imported successfully
2023-09-28 16:23:28,000:INFO:Starting cross validation
2023-09-28 16:23:28,002:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:23:28,760:INFO:Calculating mean and std
2023-09-28 16:23:28,761:INFO:Creating metrics dataframe
2023-09-28 16:23:28,770:INFO:Uploading results into container
2023-09-28 16:23:28,770:INFO:Uploading model into container now
2023-09-28 16:23:28,770:INFO:_master_model_container: 18
2023-09-28 16:23:28,770:INFO:_display_container: 2
2023-09-28 16:23:28,770:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2023-09-28 16:23:28,770:INFO:create_model() successfully completed......................................
2023-09-28 16:23:28,860:INFO:SubProcess create_model() end ==================================
2023-09-28 16:23:28,860:INFO:Creating metrics dataframe
2023-09-28 16:23:28,877:INFO:Initializing Dummy Regressor
2023-09-28 16:23:28,877:INFO:Total runtime is 0.29088118473688757 minutes
2023-09-28 16:23:28,894:INFO:SubProcess create_model() called ==================================
2023-09-28 16:23:28,894:INFO:Initializing create_model()
2023-09-28 16:23:28,894:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269A469E170>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026994C0A7D0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:23:28,894:INFO:Checking exceptions
2023-09-28 16:23:28,894:INFO:Importing libraries
2023-09-28 16:23:28,894:INFO:Copying training dataset
2023-09-28 16:23:28,894:INFO:Defining folds
2023-09-28 16:23:28,894:INFO:Declaring metric variables
2023-09-28 16:23:28,905:INFO:Importing untrained model
2023-09-28 16:23:28,911:INFO:Dummy Regressor Imported successfully
2023-09-28 16:23:28,918:INFO:Starting cross validation
2023-09-28 16:23:28,918:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:23:29,009:INFO:Calculating mean and std
2023-09-28 16:23:29,010:INFO:Creating metrics dataframe
2023-09-28 16:23:29,010:INFO:Uploading results into container
2023-09-28 16:23:29,010:INFO:Uploading model into container now
2023-09-28 16:23:29,010:INFO:_master_model_container: 19
2023-09-28 16:23:29,010:INFO:_display_container: 2
2023-09-28 16:23:29,010:INFO:DummyRegressor()
2023-09-28 16:23:29,010:INFO:create_model() successfully completed......................................
2023-09-28 16:23:29,076:INFO:SubProcess create_model() end ==================================
2023-09-28 16:23:29,076:INFO:Creating metrics dataframe
2023-09-28 16:23:29,098:INFO:Initializing create_model()
2023-09-28 16:23:29,098:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269A469E170>, estimator=GradientBoostingRegressor(random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:23:29,098:INFO:Checking exceptions
2023-09-28 16:23:29,098:INFO:Importing libraries
2023-09-28 16:23:29,098:INFO:Copying training dataset
2023-09-28 16:23:29,098:INFO:Defining folds
2023-09-28 16:23:29,098:INFO:Declaring metric variables
2023-09-28 16:23:29,098:INFO:Importing untrained model
2023-09-28 16:23:29,098:INFO:Declaring custom model
2023-09-28 16:23:29,098:INFO:Gradient Boosting Regressor Imported successfully
2023-09-28 16:23:29,098:INFO:Cross validation set to False
2023-09-28 16:23:29,098:INFO:Fitting Model
2023-09-28 16:23:29,177:INFO:GradientBoostingRegressor(random_state=42)
2023-09-28 16:23:29,177:INFO:create_model() successfully completed......................................
2023-09-28 16:23:29,283:INFO:_master_model_container: 19
2023-09-28 16:23:29,283:INFO:_display_container: 2
2023-09-28 16:23:29,284:INFO:GradientBoostingRegressor(random_state=42)
2023-09-28 16:23:29,284:INFO:compare_models() successfully completed......................................
2023-09-28 16:23:38,445:INFO:PyCaret RegressionExperiment
2023-09-28 16:23:38,445:INFO:Logging name: reg-default-name
2023-09-28 16:23:38,445:INFO:ML Usecase: MLUsecase.REGRESSION
2023-09-28 16:23:38,445:INFO:version 3.1.0
2023-09-28 16:23:38,445:INFO:Initializing setup()
2023-09-28 16:23:38,445:INFO:self.USI: 87ce
2023-09-28 16:23:38,445:INFO:self._variable_keys: {'gpu_param', 'seed', 'y_test', 'fold_groups_param', 'fold_shuffle_param', 'memory', '_available_plots', 'X', 'fold_generator', 'X_train', 'y_train', 'pipeline', '_ml_usecase', 'logging_param', 'exp_id', 'log_plots_param', 'y', 'exp_name_log', 'transform_target_param', 'html_param', 'idx', 'n_jobs_param', 'X_test', 'USI', 'target_param', 'gpu_n_jobs_param', 'data'}
2023-09-28 16:23:38,445:INFO:Checking environment
2023-09-28 16:23:38,445:INFO:python_version: 3.10.11
2023-09-28 16:23:38,445:INFO:python_build: ('main', 'May 16 2023 00:55:32')
2023-09-28 16:23:38,445:INFO:machine: AMD64
2023-09-28 16:23:38,445:INFO:platform: Windows-10-10.0.19045-SP0
2023-09-28 16:23:38,445:INFO:Memory: svmem(total=16931770368, available=7208951808, percent=57.4, used=9722818560, free=7208951808)
2023-09-28 16:23:38,445:INFO:Physical Core: 4
2023-09-28 16:23:38,445:INFO:Logical Core: 8
2023-09-28 16:23:38,445:INFO:Checking libraries
2023-09-28 16:23:38,445:INFO:System:
2023-09-28 16:23:38,445:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, May 16 2023, 00:55:32) [MSC v.1916 64 bit (AMD64)]
2023-09-28 16:23:38,445:INFO:executable: p:\Anaconda\envs\jupy\python.exe
2023-09-28 16:23:38,445:INFO:   machine: Windows-10-10.0.19045-SP0
2023-09-28 16:23:38,445:INFO:PyCaret required dependencies:
2023-09-28 16:23:38,445:INFO:                 pip: 23.2.1
2023-09-28 16:23:38,445:INFO:          setuptools: 68.0.0
2023-09-28 16:23:38,445:INFO:             pycaret: 3.1.0
2023-09-28 16:23:38,445:INFO:             IPython: 8.14.0
2023-09-28 16:23:38,445:INFO:          ipywidgets: 8.1.1
2023-09-28 16:23:38,445:INFO:                tqdm: 4.66.1
2023-09-28 16:23:38,445:INFO:               numpy: 1.23.5
2023-09-28 16:23:38,445:INFO:              pandas: 1.5.3
2023-09-28 16:23:38,445:INFO:              jinja2: 3.1.2
2023-09-28 16:23:38,445:INFO:               scipy: 1.11.1
2023-09-28 16:23:38,445:INFO:              joblib: 1.2.0
2023-09-28 16:23:38,445:INFO:             sklearn: 1.3.0
2023-09-28 16:23:38,445:INFO:                pyod: 1.1.0
2023-09-28 16:23:38,445:INFO:            imblearn: 0.11.0
2023-09-28 16:23:38,445:INFO:   category_encoders: 2.6.2
2023-09-28 16:23:38,445:INFO:            lightgbm: 4.1.0
2023-09-28 16:23:38,445:INFO:               numba: 0.57.1
2023-09-28 16:23:38,445:INFO:            requests: 2.31.0
2023-09-28 16:23:38,445:INFO:          matplotlib: 3.7.3
2023-09-28 16:23:38,445:INFO:          scikitplot: 0.3.7
2023-09-28 16:23:38,445:INFO:         yellowbrick: 1.5
2023-09-28 16:23:38,445:INFO:              plotly: 5.17.0
2023-09-28 16:23:38,445:INFO:    plotly-resampler: Not installed
2023-09-28 16:23:38,445:INFO:             kaleido: 0.2.1
2023-09-28 16:23:38,445:INFO:           schemdraw: 0.15
2023-09-28 16:23:38,445:INFO:         statsmodels: 0.14.0
2023-09-28 16:23:38,445:INFO:              sktime: 0.21.1
2023-09-28 16:23:38,445:INFO:               tbats: 1.1.3
2023-09-28 16:23:38,445:INFO:            pmdarima: 2.0.3
2023-09-28 16:23:38,445:INFO:              psutil: 5.9.5
2023-09-28 16:23:38,445:INFO:          markupsafe: 2.1.3
2023-09-28 16:23:38,445:INFO:             pickle5: Not installed
2023-09-28 16:23:38,445:INFO:         cloudpickle: 2.2.1
2023-09-28 16:23:38,445:INFO:         deprecation: 2.1.0
2023-09-28 16:23:38,445:INFO:              xxhash: 3.3.0
2023-09-28 16:23:38,445:INFO:           wurlitzer: Not installed
2023-09-28 16:23:38,445:INFO:PyCaret optional dependencies:
2023-09-28 16:23:38,445:INFO:                shap: 0.42.1
2023-09-28 16:23:38,445:INFO:           interpret: Not installed
2023-09-28 16:23:38,445:INFO:                umap: Not installed
2023-09-28 16:23:38,445:INFO:     ydata_profiling: Not installed
2023-09-28 16:23:38,445:INFO:  explainerdashboard: Not installed
2023-09-28 16:23:38,445:INFO:             autoviz: Not installed
2023-09-28 16:23:38,445:INFO:           fairlearn: Not installed
2023-09-28 16:23:38,445:INFO:          deepchecks: Not installed
2023-09-28 16:23:38,445:INFO:             xgboost: 2.0.0
2023-09-28 16:23:38,445:INFO:            catboost: Not installed
2023-09-28 16:23:38,445:INFO:              kmodes: Not installed
2023-09-28 16:23:38,445:INFO:             mlxtend: Not installed
2023-09-28 16:23:38,445:INFO:       statsforecast: Not installed
2023-09-28 16:23:38,445:INFO:        tune_sklearn: Not installed
2023-09-28 16:23:38,445:INFO:                 ray: Not installed
2023-09-28 16:23:38,445:INFO:            hyperopt: Not installed
2023-09-28 16:23:38,445:INFO:              optuna: 3.3.0
2023-09-28 16:23:38,445:INFO:               skopt: Not installed
2023-09-28 16:23:38,445:INFO:              mlflow: Not installed
2023-09-28 16:23:38,445:INFO:              gradio: Not installed
2023-09-28 16:23:38,445:INFO:             fastapi: 0.103.1
2023-09-28 16:23:38,445:INFO:             uvicorn: 0.23.2
2023-09-28 16:23:38,445:INFO:              m2cgen: Not installed
2023-09-28 16:23:38,445:INFO:           evidently: 0.4.5
2023-09-28 16:23:38,445:INFO:               fugue: Not installed
2023-09-28 16:23:38,445:INFO:           streamlit: 1.26.0
2023-09-28 16:23:38,445:INFO:             prophet: Not installed
2023-09-28 16:23:38,445:INFO:None
2023-09-28 16:23:38,445:INFO:Set up data.
2023-09-28 16:23:38,467:INFO:Set up folding strategy.
2023-09-28 16:23:38,467:INFO:Set up train/test split.
2023-09-28 16:23:38,471:INFO:Set up index.
2023-09-28 16:23:38,471:INFO:Assigning column types.
2023-09-28 16:23:38,475:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-09-28 16:23:38,475:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-09-28 16:23:38,483:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-28 16:23:38,490:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-28 16:23:38,583:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-28 16:23:38,646:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-28 16:23:38,646:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:23:38,646:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:23:38,646:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-09-28 16:23:38,662:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-28 16:23:38,664:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-28 16:23:38,747:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-28 16:23:38,812:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-28 16:23:38,812:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:23:38,812:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:23:38,812:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-09-28 16:23:38,829:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-28 16:23:38,838:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-28 16:23:38,925:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-28 16:23:38,959:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-28 16:23:38,959:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:23:38,975:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:23:38,975:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-28 16:23:38,990:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-28 16:23:39,059:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-28 16:23:39,112:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-28 16:23:39,112:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:23:39,112:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:23:39,112:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-09-28 16:23:39,128:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-28 16:23:39,218:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-28 16:23:39,294:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-28 16:23:39,294:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:23:39,294:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:23:39,314:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-28 16:23:39,406:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-28 16:23:39,459:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-28 16:23:39,459:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:23:39,459:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:23:39,459:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-09-28 16:23:39,585:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-28 16:23:39,736:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-28 16:23:39,736:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:23:39,736:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:23:39,845:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-28 16:23:39,894:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-28 16:23:39,894:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:23:39,894:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:23:39,894:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-09-28 16:23:39,980:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-28 16:23:40,026:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:23:40,026:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:23:40,097:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-28 16:23:40,160:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:23:40,160:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:23:40,160:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-09-28 16:23:40,329:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:23:40,329:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:23:40,477:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:23:40,477:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:23:40,492:INFO:Preparing preprocessing pipeline...
2023-09-28 16:23:40,492:INFO:Set up simple imputation.
2023-09-28 16:23:40,515:INFO:Finished creating preprocessing pipeline.
2023-09-28 16:23:40,521:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\maxxk\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['clonesize', 'honeybee', 'bumbles',
                                             'andrena', 'osmia',
                                             'MaxOfUpperTRange',
                                             'MinOfUpperTRange',
                                             'AverageOfUpperTRange',
                                             'MaxOfLowerTRange',
                                             'MinOfLowerTRange',
                                             'AverageOfLowerTRange',
                                             'RainingDays',
                                             'AverageRainingDays'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-09-28 16:23:40,521:INFO:Creating final display dataframe.
2023-09-28 16:23:40,584:INFO:Setup _display_container:                     Description             Value
0                    Session id                 8
1                        Target             yield
2                   Target type        Regression
3           Original data shape         (777, 14)
4        Transformed data shape         (777, 14)
5   Transformed train set shape         (543, 14)
6    Transformed test set shape         (234, 14)
7              Numeric features                13
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              87ce
2023-09-28 16:23:40,746:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:23:40,746:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:23:40,912:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:23:40,929:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:23:40,929:INFO:setup() successfully completed in 2.49s...............
2023-09-28 16:24:21,753:INFO:Initializing compare_models()
2023-09-28 16:24:21,757:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269B93D1810>, include=None, fold=None, round=4, cross_validation=True, sort=RMSE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000269B93D1810>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'RMSE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-09-28 16:24:21,757:INFO:Checking exceptions
2023-09-28 16:24:21,761:INFO:Preparing display monitor
2023-09-28 16:24:21,800:INFO:Initializing Linear Regression
2023-09-28 16:24:21,800:INFO:Total runtime is 0.0 minutes
2023-09-28 16:24:21,806:INFO:SubProcess create_model() called ==================================
2023-09-28 16:24:21,807:INFO:Initializing create_model()
2023-09-28 16:24:21,807:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269B93D1810>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026994C0A890>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:24:21,808:INFO:Checking exceptions
2023-09-28 16:24:21,809:INFO:Importing libraries
2023-09-28 16:24:21,809:INFO:Copying training dataset
2023-09-28 16:24:21,814:INFO:Defining folds
2023-09-28 16:24:21,814:INFO:Declaring metric variables
2023-09-28 16:24:21,820:INFO:Importing untrained model
2023-09-28 16:24:21,828:INFO:Linear Regression Imported successfully
2023-09-28 16:24:21,847:INFO:Starting cross validation
2023-09-28 16:24:21,849:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:24:22,002:INFO:Calculating mean and std
2023-09-28 16:24:22,003:INFO:Creating metrics dataframe
2023-09-28 16:24:22,011:INFO:Uploading results into container
2023-09-28 16:24:22,012:INFO:Uploading model into container now
2023-09-28 16:24:22,014:INFO:_master_model_container: 1
2023-09-28 16:24:22,014:INFO:_display_container: 2
2023-09-28 16:24:22,014:INFO:LinearRegression(n_jobs=-1)
2023-09-28 16:24:22,014:INFO:create_model() successfully completed......................................
2023-09-28 16:24:22,168:INFO:SubProcess create_model() end ==================================
2023-09-28 16:24:22,168:INFO:Creating metrics dataframe
2023-09-28 16:24:22,191:INFO:Initializing Lasso Regression
2023-09-28 16:24:22,191:INFO:Total runtime is 0.0065124193827311196 minutes
2023-09-28 16:24:22,197:INFO:SubProcess create_model() called ==================================
2023-09-28 16:24:22,198:INFO:Initializing create_model()
2023-09-28 16:24:22,198:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269B93D1810>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026994C0A890>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:24:22,199:INFO:Checking exceptions
2023-09-28 16:24:22,199:INFO:Importing libraries
2023-09-28 16:24:22,200:INFO:Copying training dataset
2023-09-28 16:24:22,204:INFO:Defining folds
2023-09-28 16:24:22,204:INFO:Declaring metric variables
2023-09-28 16:24:22,208:INFO:Importing untrained model
2023-09-28 16:24:22,214:INFO:Lasso Regression Imported successfully
2023-09-28 16:24:22,215:INFO:Starting cross validation
2023-09-28 16:24:22,228:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:24:22,275:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.376e+07, tolerance: 8.432e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:24:22,279:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.531e+07, tolerance: 8.494e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:24:22,291:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.367e+07, tolerance: 8.458e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:24:22,293:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.828e+07, tolerance: 8.550e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:24:22,293:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.557e+07, tolerance: 8.592e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:24:22,293:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.708e+07, tolerance: 8.632e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:24:22,312:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.598e+07, tolerance: 8.455e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:24:22,312:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.638e+07, tolerance: 8.468e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:24:22,312:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.593e+07, tolerance: 8.466e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:24:22,333:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.468e+07, tolerance: 8.623e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:24:22,348:INFO:Calculating mean and std
2023-09-28 16:24:22,348:INFO:Creating metrics dataframe
2023-09-28 16:24:22,348:INFO:Uploading results into container
2023-09-28 16:24:22,348:INFO:Uploading model into container now
2023-09-28 16:24:22,348:INFO:_master_model_container: 2
2023-09-28 16:24:22,348:INFO:_display_container: 2
2023-09-28 16:24:22,348:INFO:Lasso(random_state=8)
2023-09-28 16:24:22,348:INFO:create_model() successfully completed......................................
2023-09-28 16:24:22,415:INFO:SubProcess create_model() end ==================================
2023-09-28 16:24:22,415:INFO:Creating metrics dataframe
2023-09-28 16:24:22,428:INFO:Initializing Ridge Regression
2023-09-28 16:24:22,429:INFO:Total runtime is 0.010487226645151775 minutes
2023-09-28 16:24:22,431:INFO:SubProcess create_model() called ==================================
2023-09-28 16:24:22,431:INFO:Initializing create_model()
2023-09-28 16:24:22,431:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269B93D1810>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026994C0A890>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:24:22,431:INFO:Checking exceptions
2023-09-28 16:24:22,431:INFO:Importing libraries
2023-09-28 16:24:22,431:INFO:Copying training dataset
2023-09-28 16:24:22,431:INFO:Defining folds
2023-09-28 16:24:22,431:INFO:Declaring metric variables
2023-09-28 16:24:22,431:INFO:Importing untrained model
2023-09-28 16:24:22,431:INFO:Ridge Regression Imported successfully
2023-09-28 16:24:22,452:INFO:Starting cross validation
2023-09-28 16:24:22,452:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:24:22,562:INFO:Calculating mean and std
2023-09-28 16:24:22,563:INFO:Creating metrics dataframe
2023-09-28 16:24:22,563:INFO:Uploading results into container
2023-09-28 16:24:22,563:INFO:Uploading model into container now
2023-09-28 16:24:22,563:INFO:_master_model_container: 3
2023-09-28 16:24:22,563:INFO:_display_container: 2
2023-09-28 16:24:22,563:INFO:Ridge(random_state=8)
2023-09-28 16:24:22,563:INFO:create_model() successfully completed......................................
2023-09-28 16:24:22,629:INFO:SubProcess create_model() end ==================================
2023-09-28 16:24:22,629:INFO:Creating metrics dataframe
2023-09-28 16:24:22,645:INFO:Initializing Elastic Net
2023-09-28 16:24:22,646:INFO:Total runtime is 0.014109520117441814 minutes
2023-09-28 16:24:22,647:INFO:SubProcess create_model() called ==================================
2023-09-28 16:24:22,647:INFO:Initializing create_model()
2023-09-28 16:24:22,647:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269B93D1810>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026994C0A890>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:24:22,647:INFO:Checking exceptions
2023-09-28 16:24:22,647:INFO:Importing libraries
2023-09-28 16:24:22,647:INFO:Copying training dataset
2023-09-28 16:24:22,647:INFO:Defining folds
2023-09-28 16:24:22,647:INFO:Declaring metric variables
2023-09-28 16:24:22,647:INFO:Importing untrained model
2023-09-28 16:24:22,666:INFO:Elastic Net Imported successfully
2023-09-28 16:24:22,671:INFO:Starting cross validation
2023-09-28 16:24:22,671:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:24:22,735:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.948e+04, tolerance: 8.632e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:24:22,794:INFO:Calculating mean and std
2023-09-28 16:24:22,794:INFO:Creating metrics dataframe
2023-09-28 16:24:22,794:INFO:Uploading results into container
2023-09-28 16:24:22,794:INFO:Uploading model into container now
2023-09-28 16:24:22,794:INFO:_master_model_container: 4
2023-09-28 16:24:22,804:INFO:_display_container: 2
2023-09-28 16:24:22,804:INFO:ElasticNet(random_state=8)
2023-09-28 16:24:22,804:INFO:create_model() successfully completed......................................
2023-09-28 16:24:22,877:INFO:SubProcess create_model() end ==================================
2023-09-28 16:24:22,877:INFO:Creating metrics dataframe
2023-09-28 16:24:22,894:INFO:Initializing Least Angle Regression
2023-09-28 16:24:22,894:INFO:Total runtime is 0.018228940169016522 minutes
2023-09-28 16:24:22,898:INFO:SubProcess create_model() called ==================================
2023-09-28 16:24:22,898:INFO:Initializing create_model()
2023-09-28 16:24:22,898:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269B93D1810>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026994C0A890>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:24:22,898:INFO:Checking exceptions
2023-09-28 16:24:22,903:INFO:Importing libraries
2023-09-28 16:24:22,903:INFO:Copying training dataset
2023-09-28 16:24:22,903:INFO:Defining folds
2023-09-28 16:24:22,903:INFO:Declaring metric variables
2023-09-28 16:24:22,915:INFO:Importing untrained model
2023-09-28 16:24:22,916:INFO:Least Angle Regression Imported successfully
2023-09-28 16:24:22,932:INFO:Starting cross validation
2023-09-28 16:24:22,932:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:24:23,038:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=3.770e+00, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-09-28 16:24:23,077:INFO:Calculating mean and std
2023-09-28 16:24:23,077:INFO:Creating metrics dataframe
2023-09-28 16:24:23,085:INFO:Uploading results into container
2023-09-28 16:24:23,085:INFO:Uploading model into container now
2023-09-28 16:24:23,085:INFO:_master_model_container: 5
2023-09-28 16:24:23,085:INFO:_display_container: 2
2023-09-28 16:24:23,085:INFO:Lars(random_state=8)
2023-09-28 16:24:23,085:INFO:create_model() successfully completed......................................
2023-09-28 16:24:23,161:INFO:SubProcess create_model() end ==================================
2023-09-28 16:24:23,161:INFO:Creating metrics dataframe
2023-09-28 16:24:23,178:INFO:Initializing Lasso Least Angle Regression
2023-09-28 16:24:23,178:INFO:Total runtime is 0.022967068354288737 minutes
2023-09-28 16:24:23,178:INFO:SubProcess create_model() called ==================================
2023-09-28 16:24:23,178:INFO:Initializing create_model()
2023-09-28 16:24:23,178:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269B93D1810>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026994C0A890>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:24:23,178:INFO:Checking exceptions
2023-09-28 16:24:23,178:INFO:Importing libraries
2023-09-28 16:24:23,178:INFO:Copying training dataset
2023-09-28 16:24:23,195:INFO:Defining folds
2023-09-28 16:24:23,195:INFO:Declaring metric variables
2023-09-28 16:24:23,202:INFO:Importing untrained model
2023-09-28 16:24:23,207:INFO:Lasso Least Angle Regression Imported successfully
2023-09-28 16:24:23,215:INFO:Starting cross validation
2023-09-28 16:24:23,225:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:24:23,356:INFO:Calculating mean and std
2023-09-28 16:24:23,356:INFO:Creating metrics dataframe
2023-09-28 16:24:23,364:INFO:Uploading results into container
2023-09-28 16:24:23,364:INFO:Uploading model into container now
2023-09-28 16:24:23,364:INFO:_master_model_container: 6
2023-09-28 16:24:23,364:INFO:_display_container: 2
2023-09-28 16:24:23,364:INFO:LassoLars(random_state=8)
2023-09-28 16:24:23,364:INFO:create_model() successfully completed......................................
2023-09-28 16:24:23,427:INFO:SubProcess create_model() end ==================================
2023-09-28 16:24:23,427:INFO:Creating metrics dataframe
2023-09-28 16:24:23,444:INFO:Initializing Orthogonal Matching Pursuit
2023-09-28 16:24:23,444:INFO:Total runtime is 0.02740946610768636 minutes
2023-09-28 16:24:23,444:INFO:SubProcess create_model() called ==================================
2023-09-28 16:24:23,444:INFO:Initializing create_model()
2023-09-28 16:24:23,444:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269B93D1810>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026994C0A890>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:24:23,444:INFO:Checking exceptions
2023-09-28 16:24:23,444:INFO:Importing libraries
2023-09-28 16:24:23,444:INFO:Copying training dataset
2023-09-28 16:24:23,444:INFO:Defining folds
2023-09-28 16:24:23,444:INFO:Declaring metric variables
2023-09-28 16:24:23,444:INFO:Importing untrained model
2023-09-28 16:24:23,464:INFO:Orthogonal Matching Pursuit Imported successfully
2023-09-28 16:24:23,470:INFO:Starting cross validation
2023-09-28 16:24:23,470:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:24:23,576:INFO:Calculating mean and std
2023-09-28 16:24:23,578:INFO:Creating metrics dataframe
2023-09-28 16:24:23,581:INFO:Uploading results into container
2023-09-28 16:24:23,581:INFO:Uploading model into container now
2023-09-28 16:24:23,581:INFO:_master_model_container: 7
2023-09-28 16:24:23,581:INFO:_display_container: 2
2023-09-28 16:24:23,581:INFO:OrthogonalMatchingPursuit()
2023-09-28 16:24:23,581:INFO:create_model() successfully completed......................................
2023-09-28 16:24:23,660:INFO:SubProcess create_model() end ==================================
2023-09-28 16:24:23,660:INFO:Creating metrics dataframe
2023-09-28 16:24:23,660:INFO:Initializing Bayesian Ridge
2023-09-28 16:24:23,660:INFO:Total runtime is 0.03100045919418335 minutes
2023-09-28 16:24:23,679:INFO:SubProcess create_model() called ==================================
2023-09-28 16:24:23,680:INFO:Initializing create_model()
2023-09-28 16:24:23,680:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269B93D1810>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026994C0A890>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:24:23,681:INFO:Checking exceptions
2023-09-28 16:24:23,681:INFO:Importing libraries
2023-09-28 16:24:23,681:INFO:Copying training dataset
2023-09-28 16:24:23,681:INFO:Defining folds
2023-09-28 16:24:23,681:INFO:Declaring metric variables
2023-09-28 16:24:23,681:INFO:Importing untrained model
2023-09-28 16:24:23,681:INFO:Bayesian Ridge Imported successfully
2023-09-28 16:24:23,703:INFO:Starting cross validation
2023-09-28 16:24:23,704:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:24:23,910:INFO:Calculating mean and std
2023-09-28 16:24:23,913:INFO:Creating metrics dataframe
2023-09-28 16:24:23,915:INFO:Uploading results into container
2023-09-28 16:24:23,915:INFO:Uploading model into container now
2023-09-28 16:24:23,915:INFO:_master_model_container: 8
2023-09-28 16:24:23,915:INFO:_display_container: 2
2023-09-28 16:24:23,915:INFO:BayesianRidge()
2023-09-28 16:24:23,915:INFO:create_model() successfully completed......................................
2023-09-28 16:24:23,976:INFO:SubProcess create_model() end ==================================
2023-09-28 16:24:23,976:INFO:Creating metrics dataframe
2023-09-28 16:24:23,993:INFO:Initializing Passive Aggressive Regressor
2023-09-28 16:24:23,993:INFO:Total runtime is 0.03655461072921753 minutes
2023-09-28 16:24:24,010:INFO:SubProcess create_model() called ==================================
2023-09-28 16:24:24,011:INFO:Initializing create_model()
2023-09-28 16:24:24,011:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269B93D1810>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026994C0A890>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:24:24,012:INFO:Checking exceptions
2023-09-28 16:24:24,012:INFO:Importing libraries
2023-09-28 16:24:24,012:INFO:Copying training dataset
2023-09-28 16:24:24,014:INFO:Defining folds
2023-09-28 16:24:24,014:INFO:Declaring metric variables
2023-09-28 16:24:24,023:INFO:Importing untrained model
2023-09-28 16:24:24,029:INFO:Passive Aggressive Regressor Imported successfully
2023-09-28 16:24:24,044:INFO:Starting cross validation
2023-09-28 16:24:24,045:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:24:24,194:INFO:Calculating mean and std
2023-09-28 16:24:24,194:INFO:Creating metrics dataframe
2023-09-28 16:24:24,194:INFO:Uploading results into container
2023-09-28 16:24:24,194:INFO:Uploading model into container now
2023-09-28 16:24:24,194:INFO:_master_model_container: 9
2023-09-28 16:24:24,194:INFO:_display_container: 2
2023-09-28 16:24:24,194:INFO:PassiveAggressiveRegressor(random_state=8)
2023-09-28 16:24:24,194:INFO:create_model() successfully completed......................................
2023-09-28 16:24:24,278:INFO:SubProcess create_model() end ==================================
2023-09-28 16:24:24,278:INFO:Creating metrics dataframe
2023-09-28 16:24:24,298:INFO:Initializing Huber Regressor
2023-09-28 16:24:24,298:INFO:Total runtime is 0.041643834114074706 minutes
2023-09-28 16:24:24,310:INFO:SubProcess create_model() called ==================================
2023-09-28 16:24:24,310:INFO:Initializing create_model()
2023-09-28 16:24:24,310:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269B93D1810>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026994C0A890>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:24:24,310:INFO:Checking exceptions
2023-09-28 16:24:24,310:INFO:Importing libraries
2023-09-28 16:24:24,310:INFO:Copying training dataset
2023-09-28 16:24:24,315:INFO:Defining folds
2023-09-28 16:24:24,315:INFO:Declaring metric variables
2023-09-28 16:24:24,323:INFO:Importing untrained model
2023-09-28 16:24:24,330:INFO:Huber Regressor Imported successfully
2023-09-28 16:24:24,351:INFO:Starting cross validation
2023-09-28 16:24:24,352:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:24:24,469:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-28 16:24:24,485:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-28 16:24:24,485:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-28 16:24:24,510:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-28 16:24:24,515:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-28 16:24:24,533:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-28 16:24:24,547:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-28 16:24:24,557:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-28 16:24:24,588:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-28 16:24:24,594:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-28 16:24:24,624:INFO:Calculating mean and std
2023-09-28 16:24:24,627:INFO:Creating metrics dataframe
2023-09-28 16:24:24,627:INFO:Uploading results into container
2023-09-28 16:24:24,627:INFO:Uploading model into container now
2023-09-28 16:24:24,627:INFO:_master_model_container: 10
2023-09-28 16:24:24,627:INFO:_display_container: 2
2023-09-28 16:24:24,643:INFO:HuberRegressor()
2023-09-28 16:24:24,644:INFO:create_model() successfully completed......................................
2023-09-28 16:24:24,714:INFO:SubProcess create_model() end ==================================
2023-09-28 16:24:24,714:INFO:Creating metrics dataframe
2023-09-28 16:24:24,729:INFO:Initializing K Neighbors Regressor
2023-09-28 16:24:24,729:INFO:Total runtime is 0.048827310403188065 minutes
2023-09-28 16:24:24,729:INFO:SubProcess create_model() called ==================================
2023-09-28 16:24:24,729:INFO:Initializing create_model()
2023-09-28 16:24:24,729:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269B93D1810>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026994C0A890>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:24:24,729:INFO:Checking exceptions
2023-09-28 16:24:24,729:INFO:Importing libraries
2023-09-28 16:24:24,729:INFO:Copying training dataset
2023-09-28 16:24:24,745:INFO:Defining folds
2023-09-28 16:24:24,745:INFO:Declaring metric variables
2023-09-28 16:24:24,752:INFO:Importing untrained model
2023-09-28 16:24:24,754:INFO:K Neighbors Regressor Imported successfully
2023-09-28 16:24:24,769:INFO:Starting cross validation
2023-09-28 16:24:24,769:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:24:24,930:INFO:Calculating mean and std
2023-09-28 16:24:24,930:INFO:Creating metrics dataframe
2023-09-28 16:24:24,930:INFO:Uploading results into container
2023-09-28 16:24:24,930:INFO:Uploading model into container now
2023-09-28 16:24:24,930:INFO:_master_model_container: 11
2023-09-28 16:24:24,930:INFO:_display_container: 2
2023-09-28 16:24:24,930:INFO:KNeighborsRegressor(n_jobs=-1)
2023-09-28 16:24:24,930:INFO:create_model() successfully completed......................................
2023-09-28 16:24:25,010:INFO:SubProcess create_model() end ==================================
2023-09-28 16:24:25,010:INFO:Creating metrics dataframe
2023-09-28 16:24:25,010:INFO:Initializing Decision Tree Regressor
2023-09-28 16:24:25,010:INFO:Total runtime is 0.053507065773010246 minutes
2023-09-28 16:24:25,027:INFO:SubProcess create_model() called ==================================
2023-09-28 16:24:25,027:INFO:Initializing create_model()
2023-09-28 16:24:25,027:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269B93D1810>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026994C0A890>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:24:25,027:INFO:Checking exceptions
2023-09-28 16:24:25,027:INFO:Importing libraries
2023-09-28 16:24:25,027:INFO:Copying training dataset
2023-09-28 16:24:25,027:INFO:Defining folds
2023-09-28 16:24:25,027:INFO:Declaring metric variables
2023-09-28 16:24:25,027:INFO:Importing untrained model
2023-09-28 16:24:25,027:INFO:Decision Tree Regressor Imported successfully
2023-09-28 16:24:25,053:INFO:Starting cross validation
2023-09-28 16:24:25,053:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:24:25,182:INFO:Calculating mean and std
2023-09-28 16:24:25,183:INFO:Creating metrics dataframe
2023-09-28 16:24:25,186:INFO:Uploading results into container
2023-09-28 16:24:25,186:INFO:Uploading model into container now
2023-09-28 16:24:25,186:INFO:_master_model_container: 12
2023-09-28 16:24:25,186:INFO:_display_container: 2
2023-09-28 16:24:25,186:INFO:DecisionTreeRegressor(random_state=8)
2023-09-28 16:24:25,186:INFO:create_model() successfully completed......................................
2023-09-28 16:24:25,261:INFO:SubProcess create_model() end ==================================
2023-09-28 16:24:25,261:INFO:Creating metrics dataframe
2023-09-28 16:24:25,277:INFO:Initializing Random Forest Regressor
2023-09-28 16:24:25,277:INFO:Total runtime is 0.057960490385691316 minutes
2023-09-28 16:24:25,277:INFO:SubProcess create_model() called ==================================
2023-09-28 16:24:25,277:INFO:Initializing create_model()
2023-09-28 16:24:25,277:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269B93D1810>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026994C0A890>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:24:25,277:INFO:Checking exceptions
2023-09-28 16:24:25,277:INFO:Importing libraries
2023-09-28 16:24:25,277:INFO:Copying training dataset
2023-09-28 16:24:25,277:INFO:Defining folds
2023-09-28 16:24:25,277:INFO:Declaring metric variables
2023-09-28 16:24:25,277:INFO:Importing untrained model
2023-09-28 16:24:25,294:INFO:Random Forest Regressor Imported successfully
2023-09-28 16:24:25,306:INFO:Starting cross validation
2023-09-28 16:24:25,311:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:24:26,544:INFO:Calculating mean and std
2023-09-28 16:24:26,545:INFO:Creating metrics dataframe
2023-09-28 16:24:26,548:INFO:Uploading results into container
2023-09-28 16:24:26,548:INFO:Uploading model into container now
2023-09-28 16:24:26,548:INFO:_master_model_container: 13
2023-09-28 16:24:26,548:INFO:_display_container: 2
2023-09-28 16:24:26,548:INFO:RandomForestRegressor(n_jobs=-1, random_state=8)
2023-09-28 16:24:26,548:INFO:create_model() successfully completed......................................
2023-09-28 16:24:26,627:INFO:SubProcess create_model() end ==================================
2023-09-28 16:24:26,627:INFO:Creating metrics dataframe
2023-09-28 16:24:26,627:INFO:Initializing Extra Trees Regressor
2023-09-28 16:24:26,627:INFO:Total runtime is 0.08045243024826049 minutes
2023-09-28 16:24:26,649:INFO:SubProcess create_model() called ==================================
2023-09-28 16:24:26,649:INFO:Initializing create_model()
2023-09-28 16:24:26,649:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269B93D1810>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026994C0A890>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:24:26,649:INFO:Checking exceptions
2023-09-28 16:24:26,649:INFO:Importing libraries
2023-09-28 16:24:26,649:INFO:Copying training dataset
2023-09-28 16:24:26,655:INFO:Defining folds
2023-09-28 16:24:26,655:INFO:Declaring metric variables
2023-09-28 16:24:26,665:INFO:Importing untrained model
2023-09-28 16:24:26,673:INFO:Extra Trees Regressor Imported successfully
2023-09-28 16:24:26,698:INFO:Starting cross validation
2023-09-28 16:24:26,701:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:24:27,723:INFO:Calculating mean and std
2023-09-28 16:24:27,724:INFO:Creating metrics dataframe
2023-09-28 16:24:27,732:INFO:Uploading results into container
2023-09-28 16:24:27,733:INFO:Uploading model into container now
2023-09-28 16:24:27,733:INFO:_master_model_container: 14
2023-09-28 16:24:27,734:INFO:_display_container: 2
2023-09-28 16:24:27,734:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=8)
2023-09-28 16:24:27,734:INFO:create_model() successfully completed......................................
2023-09-28 16:24:27,863:INFO:SubProcess create_model() end ==================================
2023-09-28 16:24:27,863:INFO:Creating metrics dataframe
2023-09-28 16:24:27,880:INFO:Initializing AdaBoost Regressor
2023-09-28 16:24:27,881:INFO:Total runtime is 0.10135700305302936 minutes
2023-09-28 16:24:27,886:INFO:SubProcess create_model() called ==================================
2023-09-28 16:24:27,886:INFO:Initializing create_model()
2023-09-28 16:24:27,886:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269B93D1810>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026994C0A890>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:24:27,886:INFO:Checking exceptions
2023-09-28 16:24:27,886:INFO:Importing libraries
2023-09-28 16:24:27,887:INFO:Copying training dataset
2023-09-28 16:24:27,891:INFO:Defining folds
2023-09-28 16:24:27,891:INFO:Declaring metric variables
2023-09-28 16:24:27,898:INFO:Importing untrained model
2023-09-28 16:24:27,902:INFO:AdaBoost Regressor Imported successfully
2023-09-28 16:24:27,917:INFO:Starting cross validation
2023-09-28 16:24:27,918:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:24:28,379:INFO:Calculating mean and std
2023-09-28 16:24:28,379:INFO:Creating metrics dataframe
2023-09-28 16:24:28,379:INFO:Uploading results into container
2023-09-28 16:24:28,379:INFO:Uploading model into container now
2023-09-28 16:24:28,379:INFO:_master_model_container: 15
2023-09-28 16:24:28,379:INFO:_display_container: 2
2023-09-28 16:24:28,379:INFO:AdaBoostRegressor(random_state=8)
2023-09-28 16:24:28,379:INFO:create_model() successfully completed......................................
2023-09-28 16:24:28,443:INFO:SubProcess create_model() end ==================================
2023-09-28 16:24:28,443:INFO:Creating metrics dataframe
2023-09-28 16:24:28,462:INFO:Initializing Gradient Boosting Regressor
2023-09-28 16:24:28,462:INFO:Total runtime is 0.11103260119756062 minutes
2023-09-28 16:24:28,465:INFO:SubProcess create_model() called ==================================
2023-09-28 16:24:28,465:INFO:Initializing create_model()
2023-09-28 16:24:28,465:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269B93D1810>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026994C0A890>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:24:28,465:INFO:Checking exceptions
2023-09-28 16:24:28,465:INFO:Importing libraries
2023-09-28 16:24:28,465:INFO:Copying training dataset
2023-09-28 16:24:28,465:INFO:Defining folds
2023-09-28 16:24:28,465:INFO:Declaring metric variables
2023-09-28 16:24:28,465:INFO:Importing untrained model
2023-09-28 16:24:28,465:INFO:Gradient Boosting Regressor Imported successfully
2023-09-28 16:24:28,484:INFO:Starting cross validation
2023-09-28 16:24:28,485:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:24:28,928:INFO:Calculating mean and std
2023-09-28 16:24:28,928:INFO:Creating metrics dataframe
2023-09-28 16:24:28,928:INFO:Uploading results into container
2023-09-28 16:24:28,928:INFO:Uploading model into container now
2023-09-28 16:24:28,928:INFO:_master_model_container: 16
2023-09-28 16:24:28,928:INFO:_display_container: 2
2023-09-28 16:24:28,928:INFO:GradientBoostingRegressor(random_state=8)
2023-09-28 16:24:28,928:INFO:create_model() successfully completed......................................
2023-09-28 16:24:29,011:INFO:SubProcess create_model() end ==================================
2023-09-28 16:24:29,011:INFO:Creating metrics dataframe
2023-09-28 16:24:29,026:INFO:Initializing Extreme Gradient Boosting
2023-09-28 16:24:29,027:INFO:Total runtime is 0.12045319080352782 minutes
2023-09-28 16:24:29,029:INFO:SubProcess create_model() called ==================================
2023-09-28 16:24:29,029:INFO:Initializing create_model()
2023-09-28 16:24:29,029:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269B93D1810>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026994C0A890>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:24:29,029:INFO:Checking exceptions
2023-09-28 16:24:29,029:INFO:Importing libraries
2023-09-28 16:24:29,029:INFO:Copying training dataset
2023-09-28 16:24:29,029:INFO:Defining folds
2023-09-28 16:24:29,029:INFO:Declaring metric variables
2023-09-28 16:24:29,029:INFO:Importing untrained model
2023-09-28 16:24:29,049:INFO:Extreme Gradient Boosting Imported successfully
2023-09-28 16:24:29,057:INFO:Starting cross validation
2023-09-28 16:24:29,057:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:24:30,014:INFO:Calculating mean and std
2023-09-28 16:24:30,014:INFO:Creating metrics dataframe
2023-09-28 16:24:30,023:INFO:Uploading results into container
2023-09-28 16:24:30,023:INFO:Uploading model into container now
2023-09-28 16:24:30,026:INFO:_master_model_container: 17
2023-09-28 16:24:30,026:INFO:_display_container: 2
2023-09-28 16:24:30,029:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=8, ...)
2023-09-28 16:24:30,029:INFO:create_model() successfully completed......................................
2023-09-28 16:24:30,126:INFO:SubProcess create_model() end ==================================
2023-09-28 16:24:30,126:INFO:Creating metrics dataframe
2023-09-28 16:24:30,172:INFO:Initializing Light Gradient Boosting Machine
2023-09-28 16:24:30,172:INFO:Total runtime is 0.13953318993250527 minutes
2023-09-28 16:24:30,188:INFO:SubProcess create_model() called ==================================
2023-09-28 16:24:30,188:INFO:Initializing create_model()
2023-09-28 16:24:30,188:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269B93D1810>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026994C0A890>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:24:30,189:INFO:Checking exceptions
2023-09-28 16:24:30,189:INFO:Importing libraries
2023-09-28 16:24:30,189:INFO:Copying training dataset
2023-09-28 16:24:30,200:INFO:Defining folds
2023-09-28 16:24:30,200:INFO:Declaring metric variables
2023-09-28 16:24:30,211:INFO:Importing untrained model
2023-09-28 16:24:30,233:INFO:Light Gradient Boosting Machine Imported successfully
2023-09-28 16:24:30,249:INFO:Starting cross validation
2023-09-28 16:24:30,252:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:24:31,124:INFO:Calculating mean and std
2023-09-28 16:24:31,126:INFO:Creating metrics dataframe
2023-09-28 16:24:31,135:INFO:Uploading results into container
2023-09-28 16:24:31,136:INFO:Uploading model into container now
2023-09-28 16:24:31,137:INFO:_master_model_container: 18
2023-09-28 16:24:31,137:INFO:_display_container: 2
2023-09-28 16:24:31,138:INFO:LGBMRegressor(n_jobs=-1, random_state=8)
2023-09-28 16:24:31,139:INFO:create_model() successfully completed......................................
2023-09-28 16:24:31,250:INFO:SubProcess create_model() end ==================================
2023-09-28 16:24:31,250:INFO:Creating metrics dataframe
2023-09-28 16:24:31,275:INFO:Initializing Dummy Regressor
2023-09-28 16:24:31,275:INFO:Total runtime is 0.15791808764139809 minutes
2023-09-28 16:24:31,282:INFO:SubProcess create_model() called ==================================
2023-09-28 16:24:31,282:INFO:Initializing create_model()
2023-09-28 16:24:31,283:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269B93D1810>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026994C0A890>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:24:31,283:INFO:Checking exceptions
2023-09-28 16:24:31,283:INFO:Importing libraries
2023-09-28 16:24:31,283:INFO:Copying training dataset
2023-09-28 16:24:31,288:INFO:Defining folds
2023-09-28 16:24:31,289:INFO:Declaring metric variables
2023-09-28 16:24:31,295:INFO:Importing untrained model
2023-09-28 16:24:31,300:INFO:Dummy Regressor Imported successfully
2023-09-28 16:24:31,323:INFO:Starting cross validation
2023-09-28 16:24:31,326:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:24:31,477:INFO:Calculating mean and std
2023-09-28 16:24:31,480:INFO:Creating metrics dataframe
2023-09-28 16:24:31,484:INFO:Uploading results into container
2023-09-28 16:24:31,485:INFO:Uploading model into container now
2023-09-28 16:24:31,486:INFO:_master_model_container: 19
2023-09-28 16:24:31,486:INFO:_display_container: 2
2023-09-28 16:24:31,486:INFO:DummyRegressor()
2023-09-28 16:24:31,487:INFO:create_model() successfully completed......................................
2023-09-28 16:24:31,544:INFO:SubProcess create_model() end ==================================
2023-09-28 16:24:31,544:INFO:Creating metrics dataframe
2023-09-28 16:24:31,579:INFO:Initializing create_model()
2023-09-28 16:24:31,579:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269B93D1810>, estimator=LGBMRegressor(n_jobs=-1, random_state=8), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:24:31,579:INFO:Checking exceptions
2023-09-28 16:24:31,579:INFO:Importing libraries
2023-09-28 16:24:31,579:INFO:Copying training dataset
2023-09-28 16:24:31,579:INFO:Defining folds
2023-09-28 16:24:31,579:INFO:Declaring metric variables
2023-09-28 16:24:31,579:INFO:Importing untrained model
2023-09-28 16:24:31,579:INFO:Declaring custom model
2023-09-28 16:24:31,579:INFO:Light Gradient Boosting Machine Imported successfully
2023-09-28 16:24:31,579:INFO:Cross validation set to False
2023-09-28 16:24:31,579:INFO:Fitting Model
2023-09-28 16:24:31,604:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000221 seconds.
2023-09-28 16:24:31,604:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-09-28 16:24:31,604:INFO:[LightGBM] [Info] Total Bins 73
2023-09-28 16:24:31,605:INFO:[LightGBM] [Info] Number of data points in the train set: 543, number of used features: 13
2023-09-28 16:24:31,605:INFO:[LightGBM] [Info] Start training from score 6011.211822
2023-09-28 16:24:31,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:24:31,696:INFO:LGBMRegressor(n_jobs=-1, random_state=8)
2023-09-28 16:24:31,702:INFO:create_model() successfully completed......................................
2023-09-28 16:24:31,897:INFO:_master_model_container: 19
2023-09-28 16:24:31,897:INFO:_display_container: 2
2023-09-28 16:24:31,898:INFO:LGBMRegressor(n_jobs=-1, random_state=8)
2023-09-28 16:24:31,898:INFO:compare_models() successfully completed......................................
2023-09-28 16:24:41,945:INFO:Initializing predict_model()
2023-09-28 16:24:41,945:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269B93D1810>, estimator=LGBMRegressor(n_jobs=-1, random_state=8), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000269B98815A0>)
2023-09-28 16:24:41,945:INFO:Checking exceptions
2023-09-28 16:24:41,945:INFO:Preloading libraries
2023-09-28 16:24:52,938:INFO:Initializing predict_model()
2023-09-28 16:24:52,938:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269B93D1810>, estimator=LGBMRegressor(n_jobs=-1, random_state=8), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000269B98800D0>)
2023-09-28 16:24:52,938:INFO:Checking exceptions
2023-09-28 16:24:52,938:INFO:Preloading libraries
2023-09-28 16:25:03,060:INFO:Initializing tune_model()
2023-09-28 16:25:03,060:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=8), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269B93D1810>)
2023-09-28 16:25:03,060:INFO:Checking exceptions
2023-09-28 16:25:03,077:INFO:Copying training dataset
2023-09-28 16:25:03,077:INFO:Checking base model
2023-09-28 16:25:03,077:INFO:Base model : Light Gradient Boosting Machine
2023-09-28 16:25:03,094:INFO:Declaring metric variables
2023-09-28 16:25:03,094:INFO:Defining Hyperparameters
2023-09-28 16:25:03,187:INFO:Tuning with n_jobs=-1
2023-09-28 16:25:03,187:INFO:Initializing RandomizedSearchCV
2023-09-28 16:25:08,806:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 10, 'actual_estimator__num_leaves': 150, 'actual_estimator__n_estimators': 290, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 56, 'actual_estimator__learning_rate': 0.2, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 5, 'actual_estimator__bagging_fraction': 0.9}
2023-09-28 16:25:08,808:INFO:Hyperparameter search completed
2023-09-28 16:25:08,808:INFO:SubProcess create_model() called ==================================
2023-09-28 16:25:08,810:INFO:Initializing create_model()
2023-09-28 16:25:08,810:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269B93D1810>, estimator=LGBMRegressor(n_jobs=-1, random_state=8), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000269B9801C60>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 10, 'num_leaves': 150, 'n_estimators': 290, 'min_split_gain': 0.3, 'min_child_samples': 56, 'learning_rate': 0.2, 'feature_fraction': 0.4, 'bagging_freq': 5, 'bagging_fraction': 0.9})
2023-09-28 16:25:08,811:INFO:Checking exceptions
2023-09-28 16:25:08,811:INFO:Importing libraries
2023-09-28 16:25:08,811:INFO:Copying training dataset
2023-09-28 16:25:08,819:INFO:Defining folds
2023-09-28 16:25:08,819:INFO:Declaring metric variables
2023-09-28 16:25:08,826:INFO:Importing untrained model
2023-09-28 16:25:08,826:INFO:Declaring custom model
2023-09-28 16:25:08,836:INFO:Light Gradient Boosting Machine Imported successfully
2023-09-28 16:25:08,856:INFO:Starting cross validation
2023-09-28 16:25:08,858:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:25:09,993:INFO:Calculating mean and std
2023-09-28 16:25:09,993:INFO:Creating metrics dataframe
2023-09-28 16:25:10,012:INFO:Finalizing model
2023-09-28 16:25:10,074:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-09-28 16:25:10,074:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2023-09-28 16:25:10,074:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2023-09-28 16:25:10,079:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-09-28 16:25:10,079:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2023-09-28 16:25:10,080:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2023-09-28 16:25:10,080:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000325 seconds.
2023-09-28 16:25:10,081:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-09-28 16:25:10,081:INFO:[LightGBM] [Info] Total Bins 73
2023-09-28 16:25:10,081:INFO:[LightGBM] [Info] Number of data points in the train set: 543, number of used features: 13
2023-09-28 16:25:10,082:INFO:[LightGBM] [Info] Start training from score 6011.211822
2023-09-28 16:25:10,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:10,277:INFO:Uploading results into container
2023-09-28 16:25:10,279:INFO:Uploading model into container now
2023-09-28 16:25:10,280:INFO:_master_model_container: 20
2023-09-28 16:25:10,281:INFO:_display_container: 5
2023-09-28 16:25:10,281:INFO:LGBMRegressor(bagging_fraction=0.9, bagging_freq=5, feature_fraction=0.4,
              learning_rate=0.2, min_child_samples=56, min_split_gain=0.3,
              n_estimators=290, n_jobs=-1, num_leaves=150, random_state=8,
              reg_alpha=10, reg_lambda=3)
2023-09-28 16:25:10,281:INFO:create_model() successfully completed......................................
2023-09-28 16:25:10,397:INFO:SubProcess create_model() end ==================================
2023-09-28 16:25:10,397:INFO:choose_better activated
2023-09-28 16:25:10,401:INFO:SubProcess create_model() called ==================================
2023-09-28 16:25:10,402:INFO:Initializing create_model()
2023-09-28 16:25:10,402:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269B93D1810>, estimator=LGBMRegressor(n_jobs=-1, random_state=8), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:25:10,402:INFO:Checking exceptions
2023-09-28 16:25:10,404:INFO:Importing libraries
2023-09-28 16:25:10,405:INFO:Copying training dataset
2023-09-28 16:25:10,408:INFO:Defining folds
2023-09-28 16:25:10,409:INFO:Declaring metric variables
2023-09-28 16:25:10,409:INFO:Importing untrained model
2023-09-28 16:25:10,409:INFO:Declaring custom model
2023-09-28 16:25:10,410:INFO:Light Gradient Boosting Machine Imported successfully
2023-09-28 16:25:10,411:INFO:Starting cross validation
2023-09-28 16:25:10,412:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:25:11,280:INFO:Calculating mean and std
2023-09-28 16:25:11,281:INFO:Creating metrics dataframe
2023-09-28 16:25:11,282:INFO:Finalizing model
2023-09-28 16:25:11,301:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000298 seconds.
2023-09-28 16:25:11,301:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-09-28 16:25:11,301:INFO:[LightGBM] [Info] Total Bins 73
2023-09-28 16:25:11,301:INFO:[LightGBM] [Info] Number of data points in the train set: 543, number of used features: 13
2023-09-28 16:25:11,302:INFO:[LightGBM] [Info] Start training from score 6011.211822
2023-09-28 16:25:11,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-28 16:25:11,411:INFO:Uploading results into container
2023-09-28 16:25:11,411:INFO:Uploading model into container now
2023-09-28 16:25:11,411:INFO:_master_model_container: 21
2023-09-28 16:25:11,411:INFO:_display_container: 6
2023-09-28 16:25:11,411:INFO:LGBMRegressor(n_jobs=-1, random_state=8)
2023-09-28 16:25:11,411:INFO:create_model() successfully completed......................................
2023-09-28 16:25:11,532:INFO:SubProcess create_model() end ==================================
2023-09-28 16:25:11,532:INFO:LGBMRegressor(n_jobs=-1, random_state=8) result for R2 is 0.9613
2023-09-28 16:25:11,532:INFO:LGBMRegressor(bagging_fraction=0.9, bagging_freq=5, feature_fraction=0.4,
              learning_rate=0.2, min_child_samples=56, min_split_gain=0.3,
              n_estimators=290, n_jobs=-1, num_leaves=150, random_state=8,
              reg_alpha=10, reg_lambda=3) result for R2 is 0.956
2023-09-28 16:25:11,532:INFO:LGBMRegressor(n_jobs=-1, random_state=8) is best model
2023-09-28 16:25:11,532:INFO:choose_better completed
2023-09-28 16:25:11,532:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-09-28 16:25:11,563:INFO:_master_model_container: 21
2023-09-28 16:25:11,563:INFO:_display_container: 5
2023-09-28 16:25:11,563:INFO:LGBMRegressor(n_jobs=-1, random_state=8)
2023-09-28 16:25:11,563:INFO:tune_model() successfully completed......................................
2023-09-28 16:25:11,675:INFO:Initializing predict_model()
2023-09-28 16:25:11,675:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000269B93D1810>, estimator=LGBMRegressor(n_jobs=-1, random_state=8), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000269B9880670>)
2023-09-28 16:25:11,675:INFO:Checking exceptions
2023-09-28 16:25:11,675:INFO:Preloading libraries
2023-09-28 16:26:47,943:INFO:PyCaret RegressionExperiment
2023-09-28 16:26:47,944:INFO:Logging name: reg-default-name
2023-09-28 16:26:47,944:INFO:ML Usecase: MLUsecase.REGRESSION
2023-09-28 16:26:47,944:INFO:version 3.1.0
2023-09-28 16:26:47,944:INFO:Initializing setup()
2023-09-28 16:26:47,944:INFO:self.USI: 7c08
2023-09-28 16:26:47,944:INFO:self._variable_keys: {'gpu_param', 'seed', 'y_test', 'fold_groups_param', 'fold_shuffle_param', 'memory', '_available_plots', 'X', 'fold_generator', 'X_train', 'y_train', 'pipeline', '_ml_usecase', 'logging_param', 'exp_id', 'log_plots_param', 'y', 'exp_name_log', 'transform_target_param', 'html_param', 'idx', 'n_jobs_param', 'X_test', 'USI', 'target_param', 'gpu_n_jobs_param', 'data'}
2023-09-28 16:26:47,944:INFO:Checking environment
2023-09-28 16:26:47,944:INFO:python_version: 3.10.11
2023-09-28 16:26:47,944:INFO:python_build: ('main', 'May 16 2023 00:55:32')
2023-09-28 16:26:47,944:INFO:machine: AMD64
2023-09-28 16:26:47,944:INFO:platform: Windows-10-10.0.19045-SP0
2023-09-28 16:26:47,950:INFO:Memory: svmem(total=16931770368, available=7346221056, percent=56.6, used=9585549312, free=7346221056)
2023-09-28 16:26:47,950:INFO:Physical Core: 4
2023-09-28 16:26:47,950:INFO:Logical Core: 8
2023-09-28 16:26:47,950:INFO:Checking libraries
2023-09-28 16:26:47,950:INFO:System:
2023-09-28 16:26:47,952:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, May 16 2023, 00:55:32) [MSC v.1916 64 bit (AMD64)]
2023-09-28 16:26:47,952:INFO:executable: p:\Anaconda\envs\jupy\python.exe
2023-09-28 16:26:47,952:INFO:   machine: Windows-10-10.0.19045-SP0
2023-09-28 16:26:47,952:INFO:PyCaret required dependencies:
2023-09-28 16:26:47,952:INFO:                 pip: 23.2.1
2023-09-28 16:26:47,952:INFO:          setuptools: 68.0.0
2023-09-28 16:26:47,952:INFO:             pycaret: 3.1.0
2023-09-28 16:26:47,952:INFO:             IPython: 8.14.0
2023-09-28 16:26:47,952:INFO:          ipywidgets: 8.1.1
2023-09-28 16:26:47,953:INFO:                tqdm: 4.66.1
2023-09-28 16:26:47,953:INFO:               numpy: 1.23.5
2023-09-28 16:26:47,953:INFO:              pandas: 1.5.3
2023-09-28 16:26:47,953:INFO:              jinja2: 3.1.2
2023-09-28 16:26:47,953:INFO:               scipy: 1.11.1
2023-09-28 16:26:47,953:INFO:              joblib: 1.2.0
2023-09-28 16:26:47,953:INFO:             sklearn: 1.3.0
2023-09-28 16:26:47,953:INFO:                pyod: 1.1.0
2023-09-28 16:26:47,953:INFO:            imblearn: 0.11.0
2023-09-28 16:26:47,954:INFO:   category_encoders: 2.6.2
2023-09-28 16:26:47,954:INFO:            lightgbm: 4.1.0
2023-09-28 16:26:47,954:INFO:               numba: 0.57.1
2023-09-28 16:26:47,954:INFO:            requests: 2.31.0
2023-09-28 16:26:47,954:INFO:          matplotlib: 3.7.3
2023-09-28 16:26:47,955:INFO:          scikitplot: 0.3.7
2023-09-28 16:26:47,955:INFO:         yellowbrick: 1.5
2023-09-28 16:26:47,955:INFO:              plotly: 5.17.0
2023-09-28 16:26:47,955:INFO:    plotly-resampler: Not installed
2023-09-28 16:26:47,955:INFO:             kaleido: 0.2.1
2023-09-28 16:26:47,955:INFO:           schemdraw: 0.15
2023-09-28 16:26:47,955:INFO:         statsmodels: 0.14.0
2023-09-28 16:26:47,955:INFO:              sktime: 0.21.1
2023-09-28 16:26:47,955:INFO:               tbats: 1.1.3
2023-09-28 16:26:47,955:INFO:            pmdarima: 2.0.3
2023-09-28 16:26:47,955:INFO:              psutil: 5.9.5
2023-09-28 16:26:47,955:INFO:          markupsafe: 2.1.3
2023-09-28 16:26:47,955:INFO:             pickle5: Not installed
2023-09-28 16:26:47,955:INFO:         cloudpickle: 2.2.1
2023-09-28 16:26:47,955:INFO:         deprecation: 2.1.0
2023-09-28 16:26:47,955:INFO:              xxhash: 3.3.0
2023-09-28 16:26:47,956:INFO:           wurlitzer: Not installed
2023-09-28 16:26:47,956:INFO:PyCaret optional dependencies:
2023-09-28 16:26:47,956:INFO:                shap: 0.42.1
2023-09-28 16:26:47,957:INFO:           interpret: Not installed
2023-09-28 16:26:47,957:INFO:                umap: Not installed
2023-09-28 16:26:47,957:INFO:     ydata_profiling: Not installed
2023-09-28 16:26:47,957:INFO:  explainerdashboard: Not installed
2023-09-28 16:26:47,957:INFO:             autoviz: Not installed
2023-09-28 16:26:47,957:INFO:           fairlearn: Not installed
2023-09-28 16:26:47,957:INFO:          deepchecks: Not installed
2023-09-28 16:26:47,957:INFO:             xgboost: 2.0.0
2023-09-28 16:26:47,957:INFO:            catboost: Not installed
2023-09-28 16:26:47,958:INFO:              kmodes: Not installed
2023-09-28 16:26:47,958:INFO:             mlxtend: Not installed
2023-09-28 16:26:47,958:INFO:       statsforecast: Not installed
2023-09-28 16:26:47,958:INFO:        tune_sklearn: Not installed
2023-09-28 16:26:47,958:INFO:                 ray: Not installed
2023-09-28 16:26:47,958:INFO:            hyperopt: Not installed
2023-09-28 16:26:47,958:INFO:              optuna: 3.3.0
2023-09-28 16:26:47,958:INFO:               skopt: Not installed
2023-09-28 16:26:47,958:INFO:              mlflow: Not installed
2023-09-28 16:26:47,958:INFO:              gradio: Not installed
2023-09-28 16:26:47,958:INFO:             fastapi: 0.103.1
2023-09-28 16:26:47,958:INFO:             uvicorn: 0.23.2
2023-09-28 16:26:47,959:INFO:              m2cgen: Not installed
2023-09-28 16:26:47,959:INFO:           evidently: 0.4.5
2023-09-28 16:26:47,959:INFO:               fugue: Not installed
2023-09-28 16:26:47,960:INFO:           streamlit: 1.26.0
2023-09-28 16:26:47,960:INFO:             prophet: Not installed
2023-09-28 16:26:47,960:INFO:None
2023-09-28 16:26:47,960:INFO:Set up GPU usage.
2023-09-28 16:26:47,960:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-28 16:26:47,960:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2023-09-28 16:26:47,961:INFO:Set up data.
2023-09-28 16:26:47,976:INFO:Set up folding strategy.
2023-09-28 16:26:47,976:INFO:Set up train/test split.
2023-09-28 16:26:47,984:INFO:Set up index.
2023-09-28 16:26:47,985:INFO:Assigning column types.
2023-09-28 16:26:47,993:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-09-28 16:26:47,993:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-28 16:26:47,993:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-09-28 16:26:47,993:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-28 16:26:48,008:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-28 16:26:48,008:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-28 16:26:48,022:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-28 16:26:48,022:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-28 16:26:48,131:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-28 16:26:48,131:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-28 16:26:48,196:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-28 16:26:48,196:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-28 16:26:48,196:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-28 16:26:48,196:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:28:10,014:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-28 16:28:10,014:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-28 16:28:10,014:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-28 16:28:10,014:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-28 16:28:10,455:INFO:PyCaret RegressionExperiment
2023-09-28 16:28:10,455:INFO:Logging name: reg-default-name
2023-09-28 16:28:10,455:INFO:ML Usecase: MLUsecase.REGRESSION
2023-09-28 16:28:10,455:INFO:version 3.1.0
2023-09-28 16:28:10,455:INFO:Initializing setup()
2023-09-28 16:28:10,455:INFO:self.USI: 80aa
2023-09-28 16:28:10,456:INFO:self._variable_keys: {'transform_target_param', 'y_test', 'target_param', 'fold_shuffle_param', 'data', 'X_test', 'memory', 'USI', 'idx', '_available_plots', 'logging_param', 'y', '_ml_usecase', 'gpu_param', 'exp_id', 'fold_generator', 'n_jobs_param', 'html_param', 'exp_name_log', 'log_plots_param', 'fold_groups_param', 'X_train', 'pipeline', 'seed', 'y_train', 'X', 'gpu_n_jobs_param'}
2023-09-28 16:28:10,456:INFO:Checking environment
2023-09-28 16:28:10,456:INFO:python_version: 3.10.11
2023-09-28 16:28:10,456:INFO:python_build: ('main', 'May 16 2023 00:55:32')
2023-09-28 16:28:10,456:INFO:machine: AMD64
2023-09-28 16:28:10,456:INFO:platform: Windows-10-10.0.19045-SP0
2023-09-28 16:28:10,460:INFO:Memory: svmem(total=16931770368, available=7318302720, percent=56.8, used=9613467648, free=7318302720)
2023-09-28 16:28:10,460:INFO:Physical Core: 4
2023-09-28 16:28:10,460:INFO:Logical Core: 8
2023-09-28 16:28:10,460:INFO:Checking libraries
2023-09-28 16:28:10,461:INFO:System:
2023-09-28 16:28:10,461:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, May 16 2023, 00:55:32) [MSC v.1916 64 bit (AMD64)]
2023-09-28 16:28:10,461:INFO:executable: p:\Anaconda\envs\jupy\python.exe
2023-09-28 16:28:10,461:INFO:   machine: Windows-10-10.0.19045-SP0
2023-09-28 16:28:10,461:INFO:PyCaret required dependencies:
2023-09-28 16:28:10,494:INFO:                 pip: 23.2.1
2023-09-28 16:28:10,494:INFO:          setuptools: 68.0.0
2023-09-28 16:28:10,494:INFO:             pycaret: 3.1.0
2023-09-28 16:28:10,494:INFO:             IPython: 8.14.0
2023-09-28 16:28:10,494:INFO:          ipywidgets: 8.1.1
2023-09-28 16:28:10,494:INFO:                tqdm: 4.66.1
2023-09-28 16:28:10,494:INFO:               numpy: 1.23.5
2023-09-28 16:28:10,494:INFO:              pandas: 1.5.3
2023-09-28 16:28:10,494:INFO:              jinja2: 3.1.2
2023-09-28 16:28:10,494:INFO:               scipy: 1.11.1
2023-09-28 16:28:10,494:INFO:              joblib: 1.2.0
2023-09-28 16:28:10,494:INFO:             sklearn: 1.3.0
2023-09-28 16:28:10,494:INFO:                pyod: 1.1.0
2023-09-28 16:28:10,494:INFO:            imblearn: 0.11.0
2023-09-28 16:28:10,494:INFO:   category_encoders: 2.6.2
2023-09-28 16:28:10,494:INFO:            lightgbm: 4.1.0
2023-09-28 16:28:10,494:INFO:               numba: 0.57.1
2023-09-28 16:28:10,494:INFO:            requests: 2.31.0
2023-09-28 16:28:10,494:INFO:          matplotlib: 3.7.3
2023-09-28 16:28:10,494:INFO:          scikitplot: 0.3.7
2023-09-28 16:28:10,494:INFO:         yellowbrick: 1.5
2023-09-28 16:28:10,494:INFO:              plotly: 5.17.0
2023-09-28 16:28:10,494:INFO:    plotly-resampler: Not installed
2023-09-28 16:28:10,494:INFO:             kaleido: 0.2.1
2023-09-28 16:28:10,494:INFO:           schemdraw: 0.15
2023-09-28 16:28:10,494:INFO:         statsmodels: 0.14.0
2023-09-28 16:28:10,494:INFO:              sktime: 0.21.1
2023-09-28 16:28:10,494:INFO:               tbats: 1.1.3
2023-09-28 16:28:10,494:INFO:            pmdarima: 2.0.3
2023-09-28 16:28:10,494:INFO:              psutil: 5.9.5
2023-09-28 16:28:10,494:INFO:          markupsafe: 2.1.3
2023-09-28 16:28:10,494:INFO:             pickle5: Not installed
2023-09-28 16:28:10,494:INFO:         cloudpickle: 2.2.1
2023-09-28 16:28:10,494:INFO:         deprecation: 2.1.0
2023-09-28 16:28:10,494:INFO:              xxhash: 3.3.0
2023-09-28 16:28:10,494:INFO:           wurlitzer: Not installed
2023-09-28 16:28:10,494:INFO:PyCaret optional dependencies:
2023-09-28 16:28:10,805:INFO:                shap: 0.42.1
2023-09-28 16:28:10,805:INFO:           interpret: Not installed
2023-09-28 16:28:10,805:INFO:                umap: Not installed
2023-09-28 16:28:10,805:INFO:     ydata_profiling: Not installed
2023-09-28 16:28:10,805:INFO:  explainerdashboard: Not installed
2023-09-28 16:28:10,805:INFO:             autoviz: Not installed
2023-09-28 16:28:10,805:INFO:           fairlearn: Not installed
2023-09-28 16:28:10,805:INFO:          deepchecks: Not installed
2023-09-28 16:28:10,806:INFO:             xgboost: 2.0.0
2023-09-28 16:28:10,806:INFO:            catboost: Not installed
2023-09-28 16:28:10,806:INFO:              kmodes: Not installed
2023-09-28 16:28:10,806:INFO:             mlxtend: Not installed
2023-09-28 16:28:10,806:INFO:       statsforecast: Not installed
2023-09-28 16:28:10,806:INFO:        tune_sklearn: Not installed
2023-09-28 16:28:10,806:INFO:                 ray: Not installed
2023-09-28 16:28:10,806:INFO:            hyperopt: Not installed
2023-09-28 16:28:10,806:INFO:              optuna: 3.3.0
2023-09-28 16:28:10,806:INFO:               skopt: Not installed
2023-09-28 16:28:10,806:INFO:              mlflow: Not installed
2023-09-28 16:28:10,806:INFO:              gradio: Not installed
2023-09-28 16:28:10,806:INFO:             fastapi: 0.103.1
2023-09-28 16:28:10,806:INFO:             uvicorn: 0.23.2
2023-09-28 16:28:10,806:INFO:              m2cgen: Not installed
2023-09-28 16:28:10,806:INFO:           evidently: 0.4.5
2023-09-28 16:28:10,806:INFO:               fugue: Not installed
2023-09-28 16:28:10,806:INFO:           streamlit: 1.26.0
2023-09-28 16:28:10,806:INFO:             prophet: Not installed
2023-09-28 16:28:10,806:INFO:None
2023-09-28 16:28:10,806:INFO:Set up data.
2023-09-28 16:28:10,810:INFO:Set up folding strategy.
2023-09-28 16:28:10,810:INFO:Set up train/test split.
2023-09-28 16:28:10,810:INFO:Set up index.
2023-09-28 16:28:10,810:INFO:Assigning column types.
2023-09-28 16:28:10,810:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-09-28 16:28:10,810:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-09-28 16:28:10,826:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-28 16:28:10,826:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-28 16:28:10,910:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-28 16:28:10,960:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-28 16:28:10,960:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:28:10,978:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:28:10,979:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-09-28 16:28:10,980:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-28 16:28:10,980:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-28 16:28:11,043:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-28 16:28:11,109:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-28 16:28:11,109:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:28:11,109:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:28:11,109:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-09-28 16:28:11,109:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-28 16:28:11,127:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-28 16:28:11,197:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-28 16:28:11,260:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-28 16:28:11,260:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:28:11,260:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:28:11,260:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-28 16:28:11,278:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-28 16:28:11,360:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-28 16:28:11,410:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-28 16:28:11,410:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:28:11,410:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:28:11,410:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-09-28 16:28:11,430:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-28 16:28:11,477:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-28 16:28:11,529:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-28 16:28:11,529:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:28:11,529:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:28:11,529:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-28 16:28:11,586:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-28 16:28:11,646:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-28 16:28:11,646:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:28:11,646:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:28:11,646:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-09-28 16:28:11,726:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-28 16:28:11,776:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-28 16:28:11,776:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:28:11,793:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:28:11,863:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-28 16:28:11,910:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-28 16:28:11,910:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:28:11,926:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:28:11,926:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-09-28 16:28:12,008:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-28 16:28:12,061:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:28:12,061:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:28:12,197:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-28 16:28:12,259:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:28:12,259:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:28:12,259:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-09-28 16:28:12,429:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:28:12,429:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:28:12,560:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:28:12,560:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:28:12,560:INFO:Preparing preprocessing pipeline...
2023-09-28 16:28:12,560:INFO:Set up simple imputation.
2023-09-28 16:28:12,576:INFO:Finished creating preprocessing pipeline.
2023-09-28 16:28:12,592:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\maxxk\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['clonesize', 'honeybee', 'bumbles',
                                             'andrena', 'osmia',
                                             'MaxOfUpperTRange',
                                             'MinOfUpperTRange',
                                             'AverageOfUpperTRange',
                                             'MaxOfLowerTRange',
                                             'MinOfLowerTRange',
                                             'AverageOfLowerTRange',
                                             'RainingDays',
                                             'AverageRainingDays'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-09-28 16:28:12,592:INFO:Creating final display dataframe.
2023-09-28 16:28:12,661:INFO:Setup _display_container:                     Description             Value
0                    Session id                11
1                        Target             yield
2                   Target type        Regression
3           Original data shape         (777, 14)
4        Transformed data shape         (777, 14)
5   Transformed train set shape         (543, 14)
6    Transformed test set shape         (234, 14)
7              Numeric features                13
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                12
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              80aa
2023-09-28 16:28:12,830:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:28:12,830:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:28:12,977:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-28 16:28:12,994:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-28 16:28:12,994:INFO:setup() successfully completed in 2.55s...............
2023-09-28 16:28:30,570:INFO:Initializing compare_models()
2023-09-28 16:28:30,570:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A0C3A9E0E0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001A0C3A9E0E0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-09-28 16:28:30,570:INFO:Checking exceptions
2023-09-28 16:28:30,577:INFO:Preparing display monitor
2023-09-28 16:28:30,614:INFO:Initializing Linear Regression
2023-09-28 16:28:30,614:INFO:Total runtime is 0.0 minutes
2023-09-28 16:28:30,621:INFO:SubProcess create_model() called ==================================
2023-09-28 16:28:30,622:INFO:Initializing create_model()
2023-09-28 16:28:30,622:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A0C3A9E0E0>, estimator=lr, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A0D87D29B0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:28:30,622:INFO:Checking exceptions
2023-09-28 16:28:30,622:INFO:Importing libraries
2023-09-28 16:28:30,623:INFO:Copying training dataset
2023-09-28 16:28:30,630:INFO:Defining folds
2023-09-28 16:28:30,630:INFO:Declaring metric variables
2023-09-28 16:28:30,637:INFO:Importing untrained model
2023-09-28 16:28:30,647:INFO:Linear Regression Imported successfully
2023-09-28 16:28:30,667:INFO:Starting cross validation
2023-09-28 16:28:30,676:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:28:39,029:INFO:Calculating mean and std
2023-09-28 16:28:39,029:INFO:Creating metrics dataframe
2023-09-28 16:28:39,029:INFO:Uploading results into container
2023-09-28 16:28:39,029:INFO:Uploading model into container now
2023-09-28 16:28:39,029:INFO:_master_model_container: 1
2023-09-28 16:28:39,029:INFO:_display_container: 2
2023-09-28 16:28:39,029:INFO:LinearRegression(n_jobs=-1)
2023-09-28 16:28:39,029:INFO:create_model() successfully completed......................................
2023-09-28 16:28:39,110:INFO:SubProcess create_model() end ==================================
2023-09-28 16:28:39,110:INFO:Creating metrics dataframe
2023-09-28 16:28:39,132:INFO:Initializing Lasso Regression
2023-09-28 16:28:39,132:INFO:Total runtime is 0.14197403987248738 minutes
2023-09-28 16:28:39,144:INFO:SubProcess create_model() called ==================================
2023-09-28 16:28:39,144:INFO:Initializing create_model()
2023-09-28 16:28:39,144:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A0C3A9E0E0>, estimator=lasso, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A0D87D29B0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:28:39,144:INFO:Checking exceptions
2023-09-28 16:28:39,144:INFO:Importing libraries
2023-09-28 16:28:39,144:INFO:Copying training dataset
2023-09-28 16:28:39,144:INFO:Defining folds
2023-09-28 16:28:39,144:INFO:Declaring metric variables
2023-09-28 16:28:39,163:INFO:Importing untrained model
2023-09-28 16:28:39,168:INFO:Lasso Regression Imported successfully
2023-09-28 16:28:39,182:INFO:Starting cross validation
2023-09-28 16:28:39,184:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:28:39,229:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.212e+07, tolerance: 9.385e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:28:39,240:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.148e+07, tolerance: 9.381e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:28:39,243:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.958e+07, tolerance: 9.066e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:28:39,246:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.050e+07, tolerance: 9.268e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:28:39,246:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.958e+07, tolerance: 9.449e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:28:39,261:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.003e+07, tolerance: 9.291e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:28:39,278:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.899e+07, tolerance: 9.342e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:28:39,295:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.718e+07, tolerance: 9.110e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:28:39,295:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.875e+07, tolerance: 8.849e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:28:39,299:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.001e+07, tolerance: 9.637e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:28:39,310:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.112e+07, tolerance: 9.124e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:28:39,310:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.054e+07, tolerance: 9.393e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-28 16:28:39,342:INFO:Calculating mean and std
2023-09-28 16:28:39,344:INFO:Creating metrics dataframe
2023-09-28 16:28:39,346:INFO:Uploading results into container
2023-09-28 16:28:39,346:INFO:Uploading model into container now
2023-09-28 16:28:39,346:INFO:_master_model_container: 2
2023-09-28 16:28:39,346:INFO:_display_container: 2
2023-09-28 16:28:39,346:INFO:Lasso(random_state=11)
2023-09-28 16:28:39,346:INFO:create_model() successfully completed......................................
2023-09-28 16:28:39,411:INFO:SubProcess create_model() end ==================================
2023-09-28 16:28:39,426:INFO:Creating metrics dataframe
2023-09-28 16:28:39,429:INFO:Initializing Ridge Regression
2023-09-28 16:28:39,429:INFO:Total runtime is 0.14692711035410563 minutes
2023-09-28 16:28:39,443:INFO:SubProcess create_model() called ==================================
2023-09-28 16:28:39,444:INFO:Initializing create_model()
2023-09-28 16:28:39,444:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A0C3A9E0E0>, estimator=ridge, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A0D87D29B0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:28:39,445:INFO:Checking exceptions
2023-09-28 16:28:39,446:INFO:Importing libraries
2023-09-28 16:28:39,446:INFO:Copying training dataset
2023-09-28 16:28:39,451:INFO:Defining folds
2023-09-28 16:28:39,452:INFO:Declaring metric variables
2023-09-28 16:28:39,457:INFO:Importing untrained model
2023-09-28 16:28:39,464:INFO:Ridge Regression Imported successfully
2023-09-28 16:28:39,471:INFO:Starting cross validation
2023-09-28 16:28:39,476:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:28:39,626:INFO:Calculating mean and std
2023-09-28 16:28:39,627:INFO:Creating metrics dataframe
2023-09-28 16:28:39,627:INFO:Uploading results into container
2023-09-28 16:28:39,627:INFO:Uploading model into container now
2023-09-28 16:28:39,627:INFO:_master_model_container: 3
2023-09-28 16:28:39,627:INFO:_display_container: 2
2023-09-28 16:28:39,627:INFO:Ridge(random_state=11)
2023-09-28 16:28:39,627:INFO:create_model() successfully completed......................................
2023-09-28 16:28:39,693:INFO:SubProcess create_model() end ==================================
2023-09-28 16:28:39,693:INFO:Creating metrics dataframe
2023-09-28 16:28:39,693:INFO:Initializing Elastic Net
2023-09-28 16:28:39,693:INFO:Total runtime is 0.15131384531656902 minutes
2023-09-28 16:28:39,708:INFO:SubProcess create_model() called ==================================
2023-09-28 16:28:39,708:INFO:Initializing create_model()
2023-09-28 16:28:39,708:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A0C3A9E0E0>, estimator=en, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A0D87D29B0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:28:39,708:INFO:Checking exceptions
2023-09-28 16:28:39,708:INFO:Importing libraries
2023-09-28 16:28:39,708:INFO:Copying training dataset
2023-09-28 16:28:39,708:INFO:Defining folds
2023-09-28 16:28:39,708:INFO:Declaring metric variables
2023-09-28 16:28:39,708:INFO:Importing untrained model
2023-09-28 16:28:39,720:INFO:Elastic Net Imported successfully
2023-09-28 16:28:39,730:INFO:Starting cross validation
2023-09-28 16:28:39,731:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:28:39,841:INFO:Calculating mean and std
2023-09-28 16:28:39,841:INFO:Creating metrics dataframe
2023-09-28 16:28:39,849:INFO:Uploading results into container
2023-09-28 16:28:39,849:INFO:Uploading model into container now
2023-09-28 16:28:39,849:INFO:_master_model_container: 4
2023-09-28 16:28:39,849:INFO:_display_container: 2
2023-09-28 16:28:39,849:INFO:ElasticNet(random_state=11)
2023-09-28 16:28:39,849:INFO:create_model() successfully completed......................................
2023-09-28 16:28:39,910:INFO:SubProcess create_model() end ==================================
2023-09-28 16:28:39,910:INFO:Creating metrics dataframe
2023-09-28 16:28:39,928:INFO:Initializing Least Angle Regression
2023-09-28 16:28:39,928:INFO:Total runtime is 0.15523126920064292 minutes
2023-09-28 16:28:39,928:INFO:SubProcess create_model() called ==================================
2023-09-28 16:28:39,928:INFO:Initializing create_model()
2023-09-28 16:28:39,928:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A0C3A9E0E0>, estimator=lar, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A0D87D29B0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:28:39,928:INFO:Checking exceptions
2023-09-28 16:28:39,928:INFO:Importing libraries
2023-09-28 16:28:39,928:INFO:Copying training dataset
2023-09-28 16:28:39,928:INFO:Defining folds
2023-09-28 16:28:39,928:INFO:Declaring metric variables
2023-09-28 16:28:39,928:INFO:Importing untrained model
2023-09-28 16:28:39,944:INFO:Least Angle Regression Imported successfully
2023-09-28 16:28:39,955:INFO:Starting cross validation
2023-09-28 16:28:39,955:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:28:40,029:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.904e+01, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-09-28 16:28:40,110:INFO:Calculating mean and std
2023-09-28 16:28:40,110:INFO:Creating metrics dataframe
2023-09-28 16:28:40,110:INFO:Uploading results into container
2023-09-28 16:28:40,110:INFO:Uploading model into container now
2023-09-28 16:28:40,110:INFO:_master_model_container: 5
2023-09-28 16:28:40,110:INFO:_display_container: 2
2023-09-28 16:28:40,110:INFO:Lars(random_state=11)
2023-09-28 16:28:40,110:INFO:create_model() successfully completed......................................
2023-09-28 16:28:40,176:INFO:SubProcess create_model() end ==================================
2023-09-28 16:28:40,176:INFO:Creating metrics dataframe
2023-09-28 16:28:40,195:INFO:Initializing Lasso Least Angle Regression
2023-09-28 16:28:40,195:INFO:Total runtime is 0.15969365040461225 minutes
2023-09-28 16:28:40,195:INFO:SubProcess create_model() called ==================================
2023-09-28 16:28:40,195:INFO:Initializing create_model()
2023-09-28 16:28:40,195:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A0C3A9E0E0>, estimator=llar, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A0D87D29B0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:28:40,195:INFO:Checking exceptions
2023-09-28 16:28:40,195:INFO:Importing libraries
2023-09-28 16:28:40,195:INFO:Copying training dataset
2023-09-28 16:28:40,195:INFO:Defining folds
2023-09-28 16:28:40,195:INFO:Declaring metric variables
2023-09-28 16:28:40,211:INFO:Importing untrained model
2023-09-28 16:28:40,215:INFO:Lasso Least Angle Regression Imported successfully
2023-09-28 16:28:40,220:INFO:Starting cross validation
2023-09-28 16:28:40,220:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:28:40,268:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=1.367e+00, previous alpha=1.361e+00, with an active set of 11 regressors.
  warnings.warn(

2023-09-28 16:28:40,361:INFO:Calculating mean and std
2023-09-28 16:28:40,361:INFO:Creating metrics dataframe
2023-09-28 16:28:40,361:INFO:Uploading results into container
2023-09-28 16:28:40,361:INFO:Uploading model into container now
2023-09-28 16:28:40,361:INFO:_master_model_container: 6
2023-09-28 16:28:40,361:INFO:_display_container: 2
2023-09-28 16:28:40,361:INFO:LassoLars(random_state=11)
2023-09-28 16:28:40,361:INFO:create_model() successfully completed......................................
2023-09-28 16:28:40,443:INFO:SubProcess create_model() end ==================================
2023-09-28 16:28:40,443:INFO:Creating metrics dataframe
2023-09-28 16:28:40,443:INFO:Initializing Orthogonal Matching Pursuit
2023-09-28 16:28:40,443:INFO:Total runtime is 0.16381152868270876 minutes
2023-09-28 16:28:40,459:INFO:SubProcess create_model() called ==================================
2023-09-28 16:28:40,459:INFO:Initializing create_model()
2023-09-28 16:28:40,459:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A0C3A9E0E0>, estimator=omp, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A0D87D29B0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:28:40,459:INFO:Checking exceptions
2023-09-28 16:28:40,459:INFO:Importing libraries
2023-09-28 16:28:40,459:INFO:Copying training dataset
2023-09-28 16:28:40,459:INFO:Defining folds
2023-09-28 16:28:40,459:INFO:Declaring metric variables
2023-09-28 16:28:40,459:INFO:Importing untrained model
2023-09-28 16:28:40,459:INFO:Orthogonal Matching Pursuit Imported successfully
2023-09-28 16:28:40,481:INFO:Starting cross validation
2023-09-28 16:28:40,483:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:28:40,609:INFO:Calculating mean and std
2023-09-28 16:28:40,611:INFO:Creating metrics dataframe
2023-09-28 16:28:40,617:INFO:Uploading results into container
2023-09-28 16:28:40,617:INFO:Uploading model into container now
2023-09-28 16:28:40,617:INFO:_master_model_container: 7
2023-09-28 16:28:40,617:INFO:_display_container: 2
2023-09-28 16:28:40,617:INFO:OrthogonalMatchingPursuit()
2023-09-28 16:28:40,617:INFO:create_model() successfully completed......................................
2023-09-28 16:28:40,676:INFO:SubProcess create_model() end ==================================
2023-09-28 16:28:40,676:INFO:Creating metrics dataframe
2023-09-28 16:28:40,692:INFO:Initializing Bayesian Ridge
2023-09-28 16:28:40,692:INFO:Total runtime is 0.16796404918034874 minutes
2023-09-28 16:28:40,692:INFO:SubProcess create_model() called ==================================
2023-09-28 16:28:40,692:INFO:Initializing create_model()
2023-09-28 16:28:40,692:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A0C3A9E0E0>, estimator=br, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A0D87D29B0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:28:40,692:INFO:Checking exceptions
2023-09-28 16:28:40,692:INFO:Importing libraries
2023-09-28 16:28:40,692:INFO:Copying training dataset
2023-09-28 16:28:40,692:INFO:Defining folds
2023-09-28 16:28:40,692:INFO:Declaring metric variables
2023-09-28 16:28:40,692:INFO:Importing untrained model
2023-09-28 16:28:40,707:INFO:Bayesian Ridge Imported successfully
2023-09-28 16:28:40,717:INFO:Starting cross validation
2023-09-28 16:28:40,717:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:28:40,926:INFO:Calculating mean and std
2023-09-28 16:28:40,927:INFO:Creating metrics dataframe
2023-09-28 16:28:40,930:INFO:Uploading results into container
2023-09-28 16:28:40,930:INFO:Uploading model into container now
2023-09-28 16:28:40,930:INFO:_master_model_container: 8
2023-09-28 16:28:40,930:INFO:_display_container: 2
2023-09-28 16:28:40,930:INFO:BayesianRidge()
2023-09-28 16:28:40,930:INFO:create_model() successfully completed......................................
2023-09-28 16:28:40,994:INFO:SubProcess create_model() end ==================================
2023-09-28 16:28:40,994:INFO:Creating metrics dataframe
2023-09-28 16:28:41,012:INFO:Initializing Passive Aggressive Regressor
2023-09-28 16:28:41,012:INFO:Total runtime is 0.17331074873606367 minutes
2023-09-28 16:28:41,012:INFO:SubProcess create_model() called ==================================
2023-09-28 16:28:41,012:INFO:Initializing create_model()
2023-09-28 16:28:41,012:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A0C3A9E0E0>, estimator=par, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A0D87D29B0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:28:41,012:INFO:Checking exceptions
2023-09-28 16:28:41,012:INFO:Importing libraries
2023-09-28 16:28:41,012:INFO:Copying training dataset
2023-09-28 16:28:41,012:INFO:Defining folds
2023-09-28 16:28:41,012:INFO:Declaring metric variables
2023-09-28 16:28:41,027:INFO:Importing untrained model
2023-09-28 16:28:41,034:INFO:Passive Aggressive Regressor Imported successfully
2023-09-28 16:28:41,047:INFO:Starting cross validation
2023-09-28 16:28:41,049:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:28:41,226:INFO:Calculating mean and std
2023-09-28 16:28:41,227:INFO:Creating metrics dataframe
2023-09-28 16:28:41,229:INFO:Uploading results into container
2023-09-28 16:28:41,229:INFO:Uploading model into container now
2023-09-28 16:28:41,229:INFO:_master_model_container: 9
2023-09-28 16:28:41,229:INFO:_display_container: 2
2023-09-28 16:28:41,229:INFO:PassiveAggressiveRegressor(random_state=11)
2023-09-28 16:28:41,229:INFO:create_model() successfully completed......................................
2023-09-28 16:28:41,298:INFO:SubProcess create_model() end ==================================
2023-09-28 16:28:41,298:INFO:Creating metrics dataframe
2023-09-28 16:28:41,308:INFO:Initializing Huber Regressor
2023-09-28 16:28:41,308:INFO:Total runtime is 0.17823803424835208 minutes
2023-09-28 16:28:41,310:INFO:SubProcess create_model() called ==================================
2023-09-28 16:28:41,310:INFO:Initializing create_model()
2023-09-28 16:28:41,310:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A0C3A9E0E0>, estimator=huber, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A0D87D29B0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:28:41,310:INFO:Checking exceptions
2023-09-28 16:28:41,310:INFO:Importing libraries
2023-09-28 16:28:41,310:INFO:Copying training dataset
2023-09-28 16:28:41,310:INFO:Defining folds
2023-09-28 16:28:41,310:INFO:Declaring metric variables
2023-09-28 16:28:41,310:INFO:Importing untrained model
2023-09-28 16:28:41,310:INFO:Huber Regressor Imported successfully
2023-09-28 16:28:41,333:INFO:Starting cross validation
2023-09-28 16:28:41,334:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:28:41,443:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-28 16:28:41,443:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-28 16:28:41,464:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-28 16:28:41,464:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-28 16:28:41,480:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-28 16:28:41,493:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-28 16:28:41,509:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-28 16:28:41,509:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-28 16:28:41,576:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-28 16:28:41,576:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-28 16:28:41,576:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-28 16:28:41,593:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-28 16:28:41,608:INFO:Calculating mean and std
2023-09-28 16:28:41,610:INFO:Creating metrics dataframe
2023-09-28 16:28:41,617:INFO:Uploading results into container
2023-09-28 16:28:41,617:INFO:Uploading model into container now
2023-09-28 16:28:41,617:INFO:_master_model_container: 10
2023-09-28 16:28:41,617:INFO:_display_container: 2
2023-09-28 16:28:41,617:INFO:HuberRegressor()
2023-09-28 16:28:41,617:INFO:create_model() successfully completed......................................
2023-09-28 16:28:41,695:INFO:SubProcess create_model() end ==================================
2023-09-28 16:28:41,695:INFO:Creating metrics dataframe
2023-09-28 16:28:41,705:INFO:Initializing K Neighbors Regressor
2023-09-28 16:28:41,705:INFO:Total runtime is 0.18485719760258995 minutes
2023-09-28 16:28:41,709:INFO:SubProcess create_model() called ==================================
2023-09-28 16:28:41,709:INFO:Initializing create_model()
2023-09-28 16:28:41,709:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A0C3A9E0E0>, estimator=knn, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A0D87D29B0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:28:41,709:INFO:Checking exceptions
2023-09-28 16:28:41,709:INFO:Importing libraries
2023-09-28 16:28:41,709:INFO:Copying training dataset
2023-09-28 16:28:41,709:INFO:Defining folds
2023-09-28 16:28:41,709:INFO:Declaring metric variables
2023-09-28 16:28:41,709:INFO:Importing untrained model
2023-09-28 16:28:41,709:INFO:K Neighbors Regressor Imported successfully
2023-09-28 16:28:41,731:INFO:Starting cross validation
2023-09-28 16:28:41,733:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:28:41,913:INFO:Calculating mean and std
2023-09-28 16:28:41,913:INFO:Creating metrics dataframe
2023-09-28 16:28:41,913:INFO:Uploading results into container
2023-09-28 16:28:41,913:INFO:Uploading model into container now
2023-09-28 16:28:41,913:INFO:_master_model_container: 11
2023-09-28 16:28:41,913:INFO:_display_container: 2
2023-09-28 16:28:41,913:INFO:KNeighborsRegressor(n_jobs=-1)
2023-09-28 16:28:41,913:INFO:create_model() successfully completed......................................
2023-09-28 16:28:41,992:INFO:SubProcess create_model() end ==================================
2023-09-28 16:28:41,993:INFO:Creating metrics dataframe
2023-09-28 16:28:41,994:INFO:Initializing Decision Tree Regressor
2023-09-28 16:28:41,994:INFO:Total runtime is 0.18966621160507205 minutes
2023-09-28 16:28:42,010:INFO:SubProcess create_model() called ==================================
2023-09-28 16:28:42,010:INFO:Initializing create_model()
2023-09-28 16:28:42,010:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A0C3A9E0E0>, estimator=dt, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A0D87D29B0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:28:42,010:INFO:Checking exceptions
2023-09-28 16:28:42,010:INFO:Importing libraries
2023-09-28 16:28:42,010:INFO:Copying training dataset
2023-09-28 16:28:42,010:INFO:Defining folds
2023-09-28 16:28:42,010:INFO:Declaring metric variables
2023-09-28 16:28:42,010:INFO:Importing untrained model
2023-09-28 16:28:42,030:INFO:Decision Tree Regressor Imported successfully
2023-09-28 16:28:42,043:INFO:Starting cross validation
2023-09-28 16:28:42,044:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:28:42,193:INFO:Calculating mean and std
2023-09-28 16:28:42,194:INFO:Creating metrics dataframe
2023-09-28 16:28:42,196:INFO:Uploading results into container
2023-09-28 16:28:42,196:INFO:Uploading model into container now
2023-09-28 16:28:42,196:INFO:_master_model_container: 12
2023-09-28 16:28:42,196:INFO:_display_container: 2
2023-09-28 16:28:42,196:INFO:DecisionTreeRegressor(random_state=11)
2023-09-28 16:28:42,196:INFO:create_model() successfully completed......................................
2023-09-28 16:28:42,259:INFO:SubProcess create_model() end ==================================
2023-09-28 16:28:42,259:INFO:Creating metrics dataframe
2023-09-28 16:28:42,275:INFO:Initializing Random Forest Regressor
2023-09-28 16:28:42,275:INFO:Total runtime is 0.19435447454452517 minutes
2023-09-28 16:28:42,275:INFO:SubProcess create_model() called ==================================
2023-09-28 16:28:42,275:INFO:Initializing create_model()
2023-09-28 16:28:42,275:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A0C3A9E0E0>, estimator=rf, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A0D87D29B0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:28:42,275:INFO:Checking exceptions
2023-09-28 16:28:42,275:INFO:Importing libraries
2023-09-28 16:28:42,275:INFO:Copying training dataset
2023-09-28 16:28:42,275:INFO:Defining folds
2023-09-28 16:28:42,275:INFO:Declaring metric variables
2023-09-28 16:28:42,291:INFO:Importing untrained model
2023-09-28 16:28:42,294:INFO:Random Forest Regressor Imported successfully
2023-09-28 16:28:42,302:INFO:Starting cross validation
2023-09-28 16:28:42,303:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:28:43,816:INFO:Calculating mean and std
2023-09-28 16:28:43,816:INFO:Creating metrics dataframe
2023-09-28 16:28:43,816:INFO:Uploading results into container
2023-09-28 16:28:43,816:INFO:Uploading model into container now
2023-09-28 16:28:43,816:INFO:_master_model_container: 13
2023-09-28 16:28:43,816:INFO:_display_container: 2
2023-09-28 16:28:43,816:INFO:RandomForestRegressor(n_jobs=-1, random_state=11)
2023-09-28 16:28:43,816:INFO:create_model() successfully completed......................................
2023-09-28 16:28:43,890:INFO:SubProcess create_model() end ==================================
2023-09-28 16:28:43,890:INFO:Creating metrics dataframe
2023-09-28 16:28:43,910:INFO:Initializing Extra Trees Regressor
2023-09-28 16:28:43,910:INFO:Total runtime is 0.2215996861457825 minutes
2023-09-28 16:28:43,910:INFO:SubProcess create_model() called ==================================
2023-09-28 16:28:43,910:INFO:Initializing create_model()
2023-09-28 16:28:43,910:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A0C3A9E0E0>, estimator=et, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A0D87D29B0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:28:43,910:INFO:Checking exceptions
2023-09-28 16:28:43,910:INFO:Importing libraries
2023-09-28 16:28:43,910:INFO:Copying training dataset
2023-09-28 16:28:43,910:INFO:Defining folds
2023-09-28 16:28:43,910:INFO:Declaring metric variables
2023-09-28 16:28:43,927:INFO:Importing untrained model
2023-09-28 16:28:43,927:INFO:Extra Trees Regressor Imported successfully
2023-09-28 16:28:43,942:INFO:Starting cross validation
2023-09-28 16:28:43,944:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:28:45,142:INFO:Calculating mean and std
2023-09-28 16:28:45,143:INFO:Creating metrics dataframe
2023-09-28 16:28:45,148:INFO:Uploading results into container
2023-09-28 16:28:45,148:INFO:Uploading model into container now
2023-09-28 16:28:45,148:INFO:_master_model_container: 14
2023-09-28 16:28:45,148:INFO:_display_container: 2
2023-09-28 16:28:45,148:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=11)
2023-09-28 16:28:45,148:INFO:create_model() successfully completed......................................
2023-09-28 16:28:45,227:INFO:SubProcess create_model() end ==================================
2023-09-28 16:28:45,227:INFO:Creating metrics dataframe
2023-09-28 16:28:45,246:INFO:Initializing AdaBoost Regressor
2023-09-28 16:28:45,246:INFO:Total runtime is 0.2438680171966553 minutes
2023-09-28 16:28:45,246:INFO:SubProcess create_model() called ==================================
2023-09-28 16:28:45,246:INFO:Initializing create_model()
2023-09-28 16:28:45,246:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A0C3A9E0E0>, estimator=ada, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A0D87D29B0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:28:45,246:INFO:Checking exceptions
2023-09-28 16:28:45,246:INFO:Importing libraries
2023-09-28 16:28:45,246:INFO:Copying training dataset
2023-09-28 16:28:45,260:INFO:Defining folds
2023-09-28 16:28:45,260:INFO:Declaring metric variables
2023-09-28 16:28:45,260:INFO:Importing untrained model
2023-09-28 16:28:45,271:INFO:AdaBoost Regressor Imported successfully
2023-09-28 16:28:45,286:INFO:Starting cross validation
2023-09-28 16:28:45,286:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:28:45,794:INFO:Calculating mean and std
2023-09-28 16:28:45,794:INFO:Creating metrics dataframe
2023-09-28 16:28:45,794:INFO:Uploading results into container
2023-09-28 16:28:45,794:INFO:Uploading model into container now
2023-09-28 16:28:45,794:INFO:_master_model_container: 15
2023-09-28 16:28:45,794:INFO:_display_container: 2
2023-09-28 16:28:45,794:INFO:AdaBoostRegressor(random_state=11)
2023-09-28 16:28:45,794:INFO:create_model() successfully completed......................................
2023-09-28 16:28:45,859:INFO:SubProcess create_model() end ==================================
2023-09-28 16:28:45,859:INFO:Creating metrics dataframe
2023-09-28 16:28:45,863:INFO:Initializing Gradient Boosting Regressor
2023-09-28 16:28:45,863:INFO:Total runtime is 0.254157288869222 minutes
2023-09-28 16:28:45,879:INFO:SubProcess create_model() called ==================================
2023-09-28 16:28:45,879:INFO:Initializing create_model()
2023-09-28 16:28:45,879:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A0C3A9E0E0>, estimator=gbr, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A0D87D29B0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:28:45,879:INFO:Checking exceptions
2023-09-28 16:28:45,880:INFO:Importing libraries
2023-09-28 16:28:45,880:INFO:Copying training dataset
2023-09-28 16:28:45,883:INFO:Defining folds
2023-09-28 16:28:45,883:INFO:Declaring metric variables
2023-09-28 16:28:45,883:INFO:Importing untrained model
2023-09-28 16:28:45,895:INFO:Gradient Boosting Regressor Imported successfully
2023-09-28 16:28:45,906:INFO:Starting cross validation
2023-09-28 16:28:45,907:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:28:46,342:INFO:Calculating mean and std
2023-09-28 16:28:46,343:INFO:Creating metrics dataframe
2023-09-28 16:28:46,345:INFO:Uploading results into container
2023-09-28 16:28:46,345:INFO:Uploading model into container now
2023-09-28 16:28:46,345:INFO:_master_model_container: 16
2023-09-28 16:28:46,345:INFO:_display_container: 2
2023-09-28 16:28:46,345:INFO:GradientBoostingRegressor(random_state=11)
2023-09-28 16:28:46,345:INFO:create_model() successfully completed......................................
2023-09-28 16:28:46,410:INFO:SubProcess create_model() end ==================================
2023-09-28 16:28:46,410:INFO:Creating metrics dataframe
2023-09-28 16:28:46,426:INFO:Initializing Extreme Gradient Boosting
2023-09-28 16:28:46,426:INFO:Total runtime is 0.2635421991348267 minutes
2023-09-28 16:28:46,426:INFO:SubProcess create_model() called ==================================
2023-09-28 16:28:46,426:INFO:Initializing create_model()
2023-09-28 16:28:46,426:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A0C3A9E0E0>, estimator=xgboost, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A0D87D29B0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:28:46,426:INFO:Checking exceptions
2023-09-28 16:28:46,426:INFO:Importing libraries
2023-09-28 16:28:46,426:INFO:Copying training dataset
2023-09-28 16:28:46,426:INFO:Defining folds
2023-09-28 16:28:46,426:INFO:Declaring metric variables
2023-09-28 16:28:46,445:INFO:Importing untrained model
2023-09-28 16:28:46,451:INFO:Extreme Gradient Boosting Imported successfully
2023-09-28 16:28:46,460:INFO:Starting cross validation
2023-09-28 16:28:46,462:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:28:47,860:INFO:Calculating mean and std
2023-09-28 16:28:47,860:INFO:Creating metrics dataframe
2023-09-28 16:28:47,860:INFO:Uploading results into container
2023-09-28 16:28:47,860:INFO:Uploading model into container now
2023-09-28 16:28:47,860:INFO:_master_model_container: 17
2023-09-28 16:28:47,860:INFO:_display_container: 2
2023-09-28 16:28:47,860:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=11, ...)
2023-09-28 16:28:47,867:INFO:create_model() successfully completed......................................
2023-09-28 16:28:47,926:INFO:SubProcess create_model() end ==================================
2023-09-28 16:28:47,926:INFO:Creating metrics dataframe
2023-09-28 16:28:47,946:INFO:Initializing Light Gradient Boosting Machine
2023-09-28 16:28:47,946:INFO:Total runtime is 0.28886304299036664 minutes
2023-09-28 16:28:47,946:INFO:SubProcess create_model() called ==================================
2023-09-28 16:28:47,946:INFO:Initializing create_model()
2023-09-28 16:28:47,946:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A0C3A9E0E0>, estimator=lightgbm, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A0D87D29B0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:28:47,946:INFO:Checking exceptions
2023-09-28 16:28:47,946:INFO:Importing libraries
2023-09-28 16:28:47,946:INFO:Copying training dataset
2023-09-28 16:28:47,946:INFO:Defining folds
2023-09-28 16:28:47,946:INFO:Declaring metric variables
2023-09-28 16:28:47,959:INFO:Importing untrained model
2023-09-28 16:28:47,960:INFO:Light Gradient Boosting Machine Imported successfully
2023-09-28 16:28:47,970:INFO:Starting cross validation
2023-09-28 16:28:47,971:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:28:48,792:INFO:Calculating mean and std
2023-09-28 16:28:48,793:INFO:Creating metrics dataframe
2023-09-28 16:28:48,801:INFO:Uploading results into container
2023-09-28 16:28:48,802:INFO:Uploading model into container now
2023-09-28 16:28:48,803:INFO:_master_model_container: 18
2023-09-28 16:28:48,803:INFO:_display_container: 2
2023-09-28 16:28:48,804:INFO:LGBMRegressor(n_jobs=-1, random_state=11)
2023-09-28 16:28:48,804:INFO:create_model() successfully completed......................................
2023-09-28 16:28:48,893:INFO:SubProcess create_model() end ==================================
2023-09-28 16:28:48,893:INFO:Creating metrics dataframe
2023-09-28 16:28:48,910:INFO:Initializing Dummy Regressor
2023-09-28 16:28:48,910:INFO:Total runtime is 0.3049372673034668 minutes
2023-09-28 16:28:48,910:INFO:SubProcess create_model() called ==================================
2023-09-28 16:28:48,910:INFO:Initializing create_model()
2023-09-28 16:28:48,926:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A0C3A9E0E0>, estimator=dummy, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A0D87D29B0>, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:28:48,926:INFO:Checking exceptions
2023-09-28 16:28:48,926:INFO:Importing libraries
2023-09-28 16:28:48,926:INFO:Copying training dataset
2023-09-28 16:28:48,932:INFO:Defining folds
2023-09-28 16:28:48,932:INFO:Declaring metric variables
2023-09-28 16:28:48,937:INFO:Importing untrained model
2023-09-28 16:28:48,943:INFO:Dummy Regressor Imported successfully
2023-09-28 16:28:48,953:INFO:Starting cross validation
2023-09-28 16:28:48,954:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:28:49,059:INFO:Calculating mean and std
2023-09-28 16:28:49,060:INFO:Creating metrics dataframe
2023-09-28 16:28:49,066:INFO:Uploading results into container
2023-09-28 16:28:49,066:INFO:Uploading model into container now
2023-09-28 16:28:49,066:INFO:_master_model_container: 19
2023-09-28 16:28:49,066:INFO:_display_container: 2
2023-09-28 16:28:49,066:INFO:DummyRegressor()
2023-09-28 16:28:49,066:INFO:create_model() successfully completed......................................
2023-09-28 16:28:49,127:INFO:SubProcess create_model() end ==================================
2023-09-28 16:28:49,127:INFO:Creating metrics dataframe
2023-09-28 16:28:49,160:INFO:Initializing create_model()
2023-09-28 16:28:49,160:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A0C3A9E0E0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=11, ...), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:28:49,160:INFO:Checking exceptions
2023-09-28 16:28:49,160:INFO:Importing libraries
2023-09-28 16:28:49,160:INFO:Copying training dataset
2023-09-28 16:28:49,160:INFO:Defining folds
2023-09-28 16:28:49,160:INFO:Declaring metric variables
2023-09-28 16:28:49,160:INFO:Importing untrained model
2023-09-28 16:28:49,160:INFO:Declaring custom model
2023-09-28 16:28:49,160:INFO:Extreme Gradient Boosting Imported successfully
2023-09-28 16:28:49,160:INFO:Cross validation set to False
2023-09-28 16:28:49,160:INFO:Fitting Model
2023-09-28 16:28:49,327:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=11, ...)
2023-09-28 16:28:49,327:INFO:create_model() successfully completed......................................
2023-09-28 16:28:49,504:INFO:_master_model_container: 19
2023-09-28 16:28:49,505:INFO:_display_container: 2
2023-09-28 16:28:49,507:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=11, ...)
2023-09-28 16:28:49,507:INFO:compare_models() successfully completed......................................
2023-09-28 16:28:55,166:INFO:Initializing predict_model()
2023-09-28 16:28:55,166:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A0C3A9E0E0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=11, ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001A0D8636E60>)
2023-09-28 16:28:55,166:INFO:Checking exceptions
2023-09-28 16:28:55,167:INFO:Preloading libraries
2023-09-28 16:29:02,415:INFO:Initializing predict_model()
2023-09-28 16:29:02,415:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A0C3A9E0E0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=11, ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001A0D86371C0>)
2023-09-28 16:29:02,415:INFO:Checking exceptions
2023-09-28 16:29:02,415:INFO:Preloading libraries
2023-09-28 16:29:14,166:INFO:Initializing tune_model()
2023-09-28 16:29:14,166:INFO:tune_model(estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=11, ...), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A0C3A9E0E0>)
2023-09-28 16:29:14,167:INFO:Checking exceptions
2023-09-28 16:29:14,192:INFO:Copying training dataset
2023-09-28 16:29:14,197:INFO:Checking base model
2023-09-28 16:29:14,198:INFO:Base model : Extreme Gradient Boosting
2023-09-28 16:29:14,204:INFO:Declaring metric variables
2023-09-28 16:29:14,208:INFO:Defining Hyperparameters
2023-09-28 16:29:14,306:INFO:Tuning with n_jobs=-1
2023-09-28 16:29:14,314:INFO:Initializing RandomizedSearchCV
2023-09-28 16:29:23,630:INFO:best_params: {'actual_estimator__subsample': 0.5, 'actual_estimator__scale_pos_weight': 21.0, 'actual_estimator__reg_lambda': 10, 'actual_estimator__reg_alpha': 0.0001, 'actual_estimator__n_estimators': 30, 'actual_estimator__min_child_weight': 2, 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.3, 'actual_estimator__colsample_bytree': 0.5}
2023-09-28 16:29:23,630:INFO:Hyperparameter search completed
2023-09-28 16:29:23,630:INFO:SubProcess create_model() called ==================================
2023-09-28 16:29:23,637:INFO:Initializing create_model()
2023-09-28 16:29:23,637:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A0C3A9E0E0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=11, ...), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A0D5229330>, model_only=True, return_train_score=False, kwargs={'subsample': 0.5, 'scale_pos_weight': 21.0, 'reg_lambda': 10, 'reg_alpha': 0.0001, 'n_estimators': 30, 'min_child_weight': 2, 'max_depth': 7, 'learning_rate': 0.3, 'colsample_bytree': 0.5})
2023-09-28 16:29:23,637:INFO:Checking exceptions
2023-09-28 16:29:23,638:INFO:Importing libraries
2023-09-28 16:29:23,638:INFO:Copying training dataset
2023-09-28 16:29:23,646:INFO:Defining folds
2023-09-28 16:29:23,647:INFO:Declaring metric variables
2023-09-28 16:29:23,655:INFO:Importing untrained model
2023-09-28 16:29:23,655:INFO:Declaring custom model
2023-09-28 16:29:23,666:INFO:Extreme Gradient Boosting Imported successfully
2023-09-28 16:29:23,677:INFO:Starting cross validation
2023-09-28 16:29:23,677:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:29:24,072:INFO:Calculating mean and std
2023-09-28 16:29:24,075:INFO:Creating metrics dataframe
2023-09-28 16:29:24,086:INFO:Finalizing model
2023-09-28 16:29:24,175:INFO:Uploading results into container
2023-09-28 16:29:24,177:INFO:Uploading model into container now
2023-09-28 16:29:24,178:INFO:_master_model_container: 20
2023-09-28 16:29:24,179:INFO:_display_container: 5
2023-09-28 16:29:24,181:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.5, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=0.3, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=7, max_leaves=None,
             min_child_weight=2, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=30, n_jobs=-1,
             num_parallel_tree=None, random_state=11, ...)
2023-09-28 16:29:24,182:INFO:create_model() successfully completed......................................
2023-09-28 16:29:24,289:INFO:SubProcess create_model() end ==================================
2023-09-28 16:29:24,289:INFO:choose_better activated
2023-09-28 16:29:24,295:INFO:SubProcess create_model() called ==================================
2023-09-28 16:29:24,296:INFO:Initializing create_model()
2023-09-28 16:29:24,296:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A0C3A9E0E0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=11, ...), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-28 16:29:24,297:INFO:Checking exceptions
2023-09-28 16:29:24,300:INFO:Importing libraries
2023-09-28 16:29:24,300:INFO:Copying training dataset
2023-09-28 16:29:24,304:INFO:Defining folds
2023-09-28 16:29:24,304:INFO:Declaring metric variables
2023-09-28 16:29:24,305:INFO:Importing untrained model
2023-09-28 16:29:24,305:INFO:Declaring custom model
2023-09-28 16:29:24,306:INFO:Extreme Gradient Boosting Imported successfully
2023-09-28 16:29:24,307:INFO:Starting cross validation
2023-09-28 16:29:24,307:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2023-09-28 16:29:25,176:INFO:Calculating mean and std
2023-09-28 16:29:25,177:INFO:Creating metrics dataframe
2023-09-28 16:29:25,182:INFO:Finalizing model
2023-09-28 16:29:25,328:INFO:Uploading results into container
2023-09-28 16:29:25,328:INFO:Uploading model into container now
2023-09-28 16:29:25,328:INFO:_master_model_container: 21
2023-09-28 16:29:25,328:INFO:_display_container: 6
2023-09-28 16:29:25,328:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=11, ...)
2023-09-28 16:29:25,328:INFO:create_model() successfully completed......................................
2023-09-28 16:29:25,511:INFO:SubProcess create_model() end ==================================
2023-09-28 16:29:25,511:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=11, ...) result for R2 is 0.9478
2023-09-28 16:29:25,511:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.5, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=0.3, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=7, max_leaves=None,
             min_child_weight=2, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=30, n_jobs=-1,
             num_parallel_tree=None, random_state=11, ...) result for R2 is 0.9402
2023-09-28 16:29:25,511:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=11, ...) is best model
2023-09-28 16:29:25,511:INFO:choose_better completed
2023-09-28 16:29:25,511:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-09-28 16:29:25,527:INFO:_master_model_container: 21
2023-09-28 16:29:25,527:INFO:_display_container: 5
2023-09-28 16:29:25,527:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=11, ...)
2023-09-28 16:29:25,527:INFO:tune_model() successfully completed......................................
2023-09-28 16:29:25,603:INFO:Initializing predict_model()
2023-09-28 16:29:25,603:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A0C3A9E0E0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=11, ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001A0B410B640>)
2023-09-28 16:29:25,603:INFO:Checking exceptions
2023-09-28 16:29:25,603:INFO:Preloading libraries
2023-09-28 16:30:04,963:INFO:Initializing finalize_model()
2023-09-28 16:30:04,965:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A0C3A9E0E0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=11, ...), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-09-28 16:30:04,967:INFO:Finalizing XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=11, ...)
2023-09-28 16:30:04,976:INFO:Initializing create_model()
2023-09-28 16:30:04,977:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A0C3A9E0E0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=11, ...), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-09-28 16:30:04,977:INFO:Checking exceptions
2023-09-28 16:30:04,981:INFO:Importing libraries
2023-09-28 16:30:04,982:INFO:Copying training dataset
2023-09-28 16:30:04,982:INFO:Defining folds
2023-09-28 16:30:04,982:INFO:Declaring metric variables
2023-09-28 16:30:04,983:INFO:Importing untrained model
2023-09-28 16:30:04,983:INFO:Declaring custom model
2023-09-28 16:30:04,986:INFO:Extreme Gradient Boosting Imported successfully
2023-09-28 16:30:04,988:INFO:Cross validation set to False
2023-09-28 16:30:04,989:INFO:Fitting Model
2023-09-28 16:30:05,196:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['clonesize', 'honeybee', 'bumbles',
                                             'andrena', 'osmia',
                                             'MaxOfUpperTRange',
                                             'MinOfUpperTRange',
                                             'AverageOfUpperTRange',
                                             'MaxOfLowerTRange',
                                             'MinOfLowerTRange',
                                             'AverageOfLowerTRange',
                                             'RainingDays',
                                             'AverageRainingDays'],
                                    transformer=SimpleImputer())),
                ('categorical_imp...
                              feature_types=None, gamma=None, grow_policy=None,
                              importance_type=None,
                              interaction_constraints=None, learning_rate=None,
                              max_bin=None, max_cat_threshold=None,
                              max_cat_to_onehot=None, max_delta_step=None,
                              max_depth=None, max_leaves=None,
                              min_child_weight=None, missing=nan,
                              monotone_constraints=None, multi_strategy=None,
                              n_estimators=None, n_jobs=-1,
                              num_parallel_tree=None, random_state=11, ...))])
2023-09-28 16:30:05,197:INFO:create_model() successfully completed......................................
2023-09-28 16:30:05,293:INFO:_master_model_container: 21
2023-09-28 16:30:05,293:INFO:_display_container: 6
2023-09-28 16:30:05,312:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['clonesize', 'honeybee', 'bumbles',
                                             'andrena', 'osmia',
                                             'MaxOfUpperTRange',
                                             'MinOfUpperTRange',
                                             'AverageOfUpperTRange',
                                             'MaxOfLowerTRange',
                                             'MinOfLowerTRange',
                                             'AverageOfLowerTRange',
                                             'RainingDays',
                                             'AverageRainingDays'],
                                    transformer=SimpleImputer())),
                ('categorical_imp...
                              feature_types=None, gamma=None, grow_policy=None,
                              importance_type=None,
                              interaction_constraints=None, learning_rate=None,
                              max_bin=None, max_cat_threshold=None,
                              max_cat_to_onehot=None, max_delta_step=None,
                              max_depth=None, max_leaves=None,
                              min_child_weight=None, missing=nan,
                              monotone_constraints=None, multi_strategy=None,
                              n_estimators=None, n_jobs=-1,
                              num_parallel_tree=None, random_state=11, ...))])
2023-09-28 16:30:05,312:INFO:finalize_model() successfully completed......................................
2023-09-28 16:30:05,390:INFO:Initializing save_model()
2023-09-28 16:30:05,391:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['clonesize', 'honeybee', 'bumbles',
                                             'andrena', 'osmia',
                                             'MaxOfUpperTRange',
                                             'MinOfUpperTRange',
                                             'AverageOfUpperTRange',
                                             'MaxOfLowerTRange',
                                             'MinOfLowerTRange',
                                             'AverageOfLowerTRange',
                                             'RainingDays',
                                             'AverageRainingDays'],
                                    transformer=SimpleImputer())),
                ('categorical_imp...
                              feature_types=None, gamma=None, grow_policy=None,
                              importance_type=None,
                              interaction_constraints=None, learning_rate=None,
                              max_bin=None, max_cat_threshold=None,
                              max_cat_to_onehot=None, max_delta_step=None,
                              max_depth=None, max_leaves=None,
                              min_child_weight=None, missing=nan,
                              monotone_constraints=None, multi_strategy=None,
                              n_estimators=None, n_jobs=-1,
                              num_parallel_tree=None, random_state=11, ...))]), model_name=pycaret_automl_blueberry_yield_xgb12fold, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\maxxk\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['clonesize', 'honeybee', 'bumbles',
                                             'andrena', 'osmia',
                                             'MaxOfUpperTRange',
                                             'MinOfUpperTRange',
                                             'AverageOfUpperTRange',
                                             'MaxOfLowerTRange',
                                             'MinOfLowerTRange',
                                             'AverageOfLowerTRange',
                                             'RainingDays',
                                             'AverageRainingDays'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-09-28 16:30:05,391:INFO:Adding model into prep_pipe
2023-09-28 16:30:05,391:WARNING:Only Model saved as it was a pipeline.
2023-09-28 16:30:05,400:INFO:pycaret_automl_blueberry_yield_xgb12fold.pkl saved in current working directory
2023-09-28 16:30:05,411:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['clonesize', 'honeybee', 'bumbles',
                                             'andrena', 'osmia',
                                             'MaxOfUpperTRange',
                                             'MinOfUpperTRange',
                                             'AverageOfUpperTRange',
                                             'MaxOfLowerTRange',
                                             'MinOfLowerTRange',
                                             'AverageOfLowerTRange',
                                             'RainingDays',
                                             'AverageRainingDays'],
                                    transformer=SimpleImputer())),
                ('categorical_imp...
                              feature_types=None, gamma=None, grow_policy=None,
                              importance_type=None,
                              interaction_constraints=None, learning_rate=None,
                              max_bin=None, max_cat_threshold=None,
                              max_cat_to_onehot=None, max_delta_step=None,
                              max_depth=None, max_leaves=None,
                              min_child_weight=None, missing=nan,
                              monotone_constraints=None, multi_strategy=None,
                              n_estimators=None, n_jobs=-1,
                              num_parallel_tree=None, random_state=11, ...))])
2023-09-28 16:30:05,411:INFO:save_model() successfully completed......................................
2023-09-28 16:30:30,628:INFO:Initializing plot_model()
2023-09-28 16:30:30,628:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=11, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A0C3A9E0E0>, system=True)
2023-09-28 16:30:30,628:INFO:Checking exceptions
2023-09-28 16:30:30,637:INFO:Preloading libraries
2023-09-28 16:30:30,646:INFO:Copying training dataset
2023-09-28 16:30:30,647:INFO:Plot type: residuals
2023-09-28 16:30:30,828:INFO:Fitting Model
2023-09-28 16:30:30,932:INFO:Scoring test/hold-out set
2023-09-28 16:30:31,741:INFO:Visual Rendered Successfully
2023-09-28 16:30:31,904:INFO:plot_model() successfully completed......................................
2023-09-30 16:40:39,993:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-30 16:40:39,993:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-30 16:40:39,993:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-30 16:40:39,993:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-30 16:40:45,490:INFO:PyCaret RegressionExperiment
2023-09-30 16:40:45,491:INFO:Logging name: reg-default-name
2023-09-30 16:40:45,491:INFO:ML Usecase: MLUsecase.REGRESSION
2023-09-30 16:40:45,491:INFO:version 3.1.0
2023-09-30 16:40:45,491:INFO:Initializing setup()
2023-09-30 16:40:45,491:INFO:self.USI: a8b4
2023-09-30 16:40:45,491:INFO:self._variable_keys: {'pipeline', 'fold_groups_param', 'log_plots_param', 'target_param', 'html_param', 'gpu_param', 'logging_param', 'X_train', 'y_train', 'X_test', 'gpu_n_jobs_param', '_available_plots', 'X', 'seed', 'y_test', 'fold_shuffle_param', 'y', 'memory', '_ml_usecase', 'exp_id', 'data', 'USI', 'exp_name_log', 'n_jobs_param', 'idx', 'fold_generator', 'transform_target_param'}
2023-09-30 16:40:45,491:INFO:Checking environment
2023-09-30 16:40:45,491:INFO:python_version: 3.10.11
2023-09-30 16:40:45,491:INFO:python_build: ('main', 'May 16 2023 00:55:32')
2023-09-30 16:40:45,493:INFO:machine: AMD64
2023-09-30 16:40:45,493:INFO:platform: Windows-10-10.0.19045-SP0
2023-09-30 16:40:45,493:INFO:Memory: svmem(total=16931770368, available=8961093632, percent=47.1, used=7970676736, free=8961093632)
2023-09-30 16:40:45,493:INFO:Physical Core: 4
2023-09-30 16:40:45,493:INFO:Logical Core: 8
2023-09-30 16:40:45,493:INFO:Checking libraries
2023-09-30 16:40:45,493:INFO:System:
2023-09-30 16:40:45,493:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, May 16 2023, 00:55:32) [MSC v.1916 64 bit (AMD64)]
2023-09-30 16:40:45,493:INFO:executable: p:\Anaconda\envs\jupy\python.exe
2023-09-30 16:40:45,493:INFO:   machine: Windows-10-10.0.19045-SP0
2023-09-30 16:40:45,493:INFO:PyCaret required dependencies:
2023-09-30 16:40:45,644:INFO:                 pip: 23.2.1
2023-09-30 16:40:45,644:INFO:          setuptools: 68.0.0
2023-09-30 16:40:45,644:INFO:             pycaret: 3.1.0
2023-09-30 16:40:45,644:INFO:             IPython: 8.14.0
2023-09-30 16:40:45,644:INFO:          ipywidgets: 8.1.1
2023-09-30 16:40:45,644:INFO:                tqdm: 4.66.1
2023-09-30 16:40:45,644:INFO:               numpy: 1.23.5
2023-09-30 16:40:45,644:INFO:              pandas: 1.5.3
2023-09-30 16:40:45,644:INFO:              jinja2: 3.1.2
2023-09-30 16:40:45,644:INFO:               scipy: 1.11.1
2023-09-30 16:40:45,644:INFO:              joblib: 1.2.0
2023-09-30 16:40:45,644:INFO:             sklearn: 1.3.0
2023-09-30 16:40:45,644:INFO:                pyod: 1.1.0
2023-09-30 16:40:45,644:INFO:            imblearn: 0.11.0
2023-09-30 16:40:45,644:INFO:   category_encoders: 2.6.2
2023-09-30 16:40:45,644:INFO:            lightgbm: 4.1.0
2023-09-30 16:40:45,644:INFO:               numba: 0.57.1
2023-09-30 16:40:45,644:INFO:            requests: 2.31.0
2023-09-30 16:40:45,644:INFO:          matplotlib: 3.7.3
2023-09-30 16:40:45,644:INFO:          scikitplot: 0.3.7
2023-09-30 16:40:45,644:INFO:         yellowbrick: 1.5
2023-09-30 16:40:45,644:INFO:              plotly: 5.17.0
2023-09-30 16:40:45,644:INFO:    plotly-resampler: Not installed
2023-09-30 16:40:45,644:INFO:             kaleido: 0.2.1
2023-09-30 16:40:45,644:INFO:           schemdraw: 0.15
2023-09-30 16:40:45,644:INFO:         statsmodels: 0.14.0
2023-09-30 16:40:45,644:INFO:              sktime: 0.21.1
2023-09-30 16:40:45,644:INFO:               tbats: 1.1.3
2023-09-30 16:40:45,644:INFO:            pmdarima: 2.0.3
2023-09-30 16:40:45,644:INFO:              psutil: 5.9.5
2023-09-30 16:40:45,644:INFO:          markupsafe: 2.1.3
2023-09-30 16:40:45,644:INFO:             pickle5: Not installed
2023-09-30 16:40:45,644:INFO:         cloudpickle: 2.2.1
2023-09-30 16:40:45,644:INFO:         deprecation: 2.1.0
2023-09-30 16:40:45,644:INFO:              xxhash: 3.3.0
2023-09-30 16:40:45,644:INFO:           wurlitzer: Not installed
2023-09-30 16:40:45,644:INFO:PyCaret optional dependencies:
2023-09-30 16:40:47,590:INFO:                shap: 0.42.1
2023-09-30 16:40:47,590:INFO:           interpret: Not installed
2023-09-30 16:40:47,590:INFO:                umap: Not installed
2023-09-30 16:40:47,590:INFO:     ydata_profiling: Not installed
2023-09-30 16:40:47,590:INFO:  explainerdashboard: Not installed
2023-09-30 16:40:47,590:INFO:             autoviz: Not installed
2023-09-30 16:40:47,590:INFO:           fairlearn: Not installed
2023-09-30 16:40:47,590:INFO:          deepchecks: Not installed
2023-09-30 16:40:47,590:INFO:             xgboost: 2.0.0
2023-09-30 16:40:47,590:INFO:            catboost: Not installed
2023-09-30 16:40:47,590:INFO:              kmodes: Not installed
2023-09-30 16:40:47,590:INFO:             mlxtend: Not installed
2023-09-30 16:40:47,590:INFO:       statsforecast: Not installed
2023-09-30 16:40:47,590:INFO:        tune_sklearn: Not installed
2023-09-30 16:40:47,590:INFO:                 ray: Not installed
2023-09-30 16:40:47,590:INFO:            hyperopt: Not installed
2023-09-30 16:40:47,590:INFO:              optuna: 3.3.0
2023-09-30 16:40:47,590:INFO:               skopt: Not installed
2023-09-30 16:40:47,590:INFO:              mlflow: Not installed
2023-09-30 16:40:47,590:INFO:              gradio: Not installed
2023-09-30 16:40:47,590:INFO:             fastapi: 0.103.1
2023-09-30 16:40:47,590:INFO:             uvicorn: 0.23.2
2023-09-30 16:40:47,590:INFO:              m2cgen: Not installed
2023-09-30 16:40:47,590:INFO:           evidently: 0.4.5
2023-09-30 16:40:47,590:INFO:               fugue: Not installed
2023-09-30 16:40:47,590:INFO:           streamlit: 1.26.0
2023-09-30 16:40:47,590:INFO:             prophet: Not installed
2023-09-30 16:40:47,590:INFO:None
2023-09-30 16:40:47,590:INFO:Set up data.
2023-09-30 16:40:47,607:INFO:Set up folding strategy.
2023-09-30 16:40:47,607:INFO:Set up train/test split.
2023-09-30 16:40:47,621:INFO:Set up index.
2023-09-30 16:40:47,621:INFO:Assigning column types.
2023-09-30 16:40:47,624:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-09-30 16:40:47,624:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-09-30 16:40:47,641:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-30 16:40:47,653:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-30 16:40:47,775:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-30 16:40:47,838:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-30 16:40:47,838:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-30 16:40:47,838:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-30 16:40:47,838:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-09-30 16:40:47,838:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-30 16:40:47,854:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-30 16:40:47,908:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-30 16:40:47,954:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-30 16:40:47,954:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-30 16:40:48,073:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-30 16:40:48,073:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-09-30 16:40:48,073:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-30 16:40:48,093:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-30 16:40:48,167:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-30 16:40:48,225:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-30 16:40:48,225:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-30 16:40:48,225:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-30 16:40:48,241:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-30 16:40:48,241:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-30 16:40:48,304:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-30 16:40:48,340:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-30 16:40:48,353:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-30 16:40:48,355:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-30 16:40:48,355:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-09-30 16:40:48,355:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-30 16:40:48,425:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-30 16:40:48,478:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-30 16:40:48,478:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-30 16:40:48,478:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-30 16:40:48,487:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-30 16:40:48,556:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-30 16:40:48,588:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-30 16:40:48,588:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-30 16:40:48,605:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-30 16:40:48,605:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-09-30 16:40:48,673:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-30 16:40:48,720:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-30 16:40:48,720:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-30 16:40:48,720:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-30 16:40:48,806:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-30 16:40:48,842:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-30 16:40:48,854:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-30 16:40:48,855:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-30 16:40:48,855:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-09-30 16:40:48,918:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-30 16:40:48,981:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-30 16:40:48,981:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-30 16:40:49,061:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-30 16:40:49,123:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-30 16:40:49,123:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-30 16:40:49,123:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-09-30 16:40:49,236:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-30 16:40:49,253:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-30 16:40:49,375:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-30 16:40:49,375:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-30 16:40:49,375:INFO:Preparing preprocessing pipeline...
2023-09-30 16:40:49,375:INFO:Set up simple imputation.
2023-09-30 16:40:49,422:INFO:Finished creating preprocessing pipeline.
2023-09-30 16:40:49,438:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\maxxk\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['clonesize', 'honeybee', 'bumbles',
                                             'andrena', 'osmia',
                                             'MaxOfUpperTRange',
                                             'MinOfUpperTRange',
                                             'AverageOfUpperTRange',
                                             'MaxOfLowerTRange',
                                             'MinOfLowerTRange',
                                             'AverageOfLowerTRange',
                                             'RainingDays',
                                             'AverageRainingDays'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-09-30 16:40:49,438:INFO:Creating final display dataframe.
2023-09-30 16:40:49,538:INFO:Setup _display_container:                     Description             Value
0                    Session id                88
1                        Target             yield
2                   Target type        Regression
3           Original data shape         (777, 14)
4        Transformed data shape         (777, 14)
5   Transformed train set shape         (543, 14)
6    Transformed test set shape         (234, 14)
7              Numeric features                13
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                15
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              a8b4
2023-09-30 16:40:49,776:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-30 16:40:49,776:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-30 16:40:49,923:INFO:Soft dependency imported: xgboost: 2.0.0
2023-09-30 16:40:49,923:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-09-30 16:40:49,923:INFO:setup() successfully completed in 4.44s...............
2023-09-30 16:41:19,191:INFO:Initializing compare_models()
2023-09-30 16:41:19,192:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-09-30 16:41:19,193:INFO:Checking exceptions
2023-09-30 16:41:19,193:INFO:Preparing display monitor
2023-09-30 16:41:19,256:INFO:Initializing Linear Regression
2023-09-30 16:41:19,256:INFO:Total runtime is 0.0 minutes
2023-09-30 16:41:19,272:INFO:SubProcess create_model() called ==================================
2023-09-30 16:41:19,272:INFO:Initializing create_model()
2023-09-30 16:41:19,272:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=lr, fold=KFold(n_splits=15, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170B3D0C1F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-30 16:41:19,272:INFO:Checking exceptions
2023-09-30 16:41:19,272:INFO:Importing libraries
2023-09-30 16:41:19,272:INFO:Copying training dataset
2023-09-30 16:41:19,280:INFO:Defining folds
2023-09-30 16:41:19,280:INFO:Declaring metric variables
2023-09-30 16:41:19,296:INFO:Importing untrained model
2023-09-30 16:41:19,296:INFO:Linear Regression Imported successfully
2023-09-30 16:41:19,312:INFO:Starting cross validation
2023-09-30 16:41:19,337:INFO:Cross validating with KFold(n_splits=15, random_state=None, shuffle=False), n_jobs=-1
2023-09-30 16:41:38,434:INFO:Calculating mean and std
2023-09-30 16:41:38,438:INFO:Creating metrics dataframe
2023-09-30 16:41:38,450:INFO:Uploading results into container
2023-09-30 16:41:38,450:INFO:Uploading model into container now
2023-09-30 16:41:38,454:INFO:_master_model_container: 1
2023-09-30 16:41:38,454:INFO:_display_container: 2
2023-09-30 16:41:38,454:INFO:LinearRegression(n_jobs=-1)
2023-09-30 16:41:38,454:INFO:create_model() successfully completed......................................
2023-09-30 16:41:38,539:INFO:SubProcess create_model() end ==================================
2023-09-30 16:41:38,539:INFO:Creating metrics dataframe
2023-09-30 16:41:38,555:INFO:Initializing Lasso Regression
2023-09-30 16:41:38,555:INFO:Total runtime is 0.3216556946436564 minutes
2023-09-30 16:41:38,555:INFO:SubProcess create_model() called ==================================
2023-09-30 16:41:38,555:INFO:Initializing create_model()
2023-09-30 16:41:38,555:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=lasso, fold=KFold(n_splits=15, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170B3D0C1F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-30 16:41:38,555:INFO:Checking exceptions
2023-09-30 16:41:38,555:INFO:Importing libraries
2023-09-30 16:41:38,555:INFO:Copying training dataset
2023-09-30 16:41:38,576:INFO:Defining folds
2023-09-30 16:41:38,576:INFO:Declaring metric variables
2023-09-30 16:41:38,576:INFO:Importing untrained model
2023-09-30 16:41:38,585:INFO:Lasso Regression Imported successfully
2023-09-30 16:41:38,604:INFO:Starting cross validation
2023-09-30 16:41:38,612:INFO:Cross validating with KFold(n_splits=15, random_state=None, shuffle=False), n_jobs=-1
2023-09-30 16:41:38,706:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.154e+07, tolerance: 9.470e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-30 16:41:38,706:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.008e+07, tolerance: 9.540e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-30 16:41:38,706:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.247e+07, tolerance: 9.332e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-30 16:41:38,706:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.007e+07, tolerance: 9.465e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-30 16:41:38,722:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.933e+07, tolerance: 9.374e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-30 16:41:38,738:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.965e+07, tolerance: 9.513e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-30 16:41:38,738:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.887e+07, tolerance: 9.614e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-30 16:41:38,761:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.962e+07, tolerance: 9.388e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-30 16:41:38,780:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.092e+07, tolerance: 9.648e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-30 16:41:38,780:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.051e+07, tolerance: 9.508e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-30 16:41:38,793:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.112e+07, tolerance: 9.588e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-30 16:41:38,798:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.031e+07, tolerance: 9.378e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-30 16:41:38,811:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.143e+07, tolerance: 9.703e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-30 16:41:38,823:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.170e+07, tolerance: 9.612e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-30 16:41:38,823:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.899e+07, tolerance: 9.514e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-30 16:41:38,854:INFO:Calculating mean and std
2023-09-30 16:41:38,854:INFO:Creating metrics dataframe
2023-09-30 16:41:38,854:INFO:Uploading results into container
2023-09-30 16:41:38,854:INFO:Uploading model into container now
2023-09-30 16:41:38,854:INFO:_master_model_container: 2
2023-09-30 16:41:38,854:INFO:_display_container: 2
2023-09-30 16:41:38,854:INFO:Lasso(random_state=88)
2023-09-30 16:41:38,854:INFO:create_model() successfully completed......................................
2023-09-30 16:41:38,957:INFO:SubProcess create_model() end ==================================
2023-09-30 16:41:38,957:INFO:Creating metrics dataframe
2023-09-30 16:41:38,993:INFO:Initializing Ridge Regression
2023-09-30 16:41:38,993:INFO:Total runtime is 0.32895419200261433 minutes
2023-09-30 16:41:38,993:INFO:SubProcess create_model() called ==================================
2023-09-30 16:41:38,993:INFO:Initializing create_model()
2023-09-30 16:41:38,993:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=ridge, fold=KFold(n_splits=15, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170B3D0C1F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-30 16:41:38,993:INFO:Checking exceptions
2023-09-30 16:41:38,993:INFO:Importing libraries
2023-09-30 16:41:38,993:INFO:Copying training dataset
2023-09-30 16:41:39,014:INFO:Defining folds
2023-09-30 16:41:39,014:INFO:Declaring metric variables
2023-09-30 16:41:39,021:INFO:Importing untrained model
2023-09-30 16:41:39,031:INFO:Ridge Regression Imported successfully
2023-09-30 16:41:39,054:INFO:Starting cross validation
2023-09-30 16:41:39,060:INFO:Cross validating with KFold(n_splits=15, random_state=None, shuffle=False), n_jobs=-1
2023-09-30 16:41:39,255:INFO:Calculating mean and std
2023-09-30 16:41:39,258:INFO:Creating metrics dataframe
2023-09-30 16:41:39,260:INFO:Uploading results into container
2023-09-30 16:41:39,260:INFO:Uploading model into container now
2023-09-30 16:41:39,260:INFO:_master_model_container: 3
2023-09-30 16:41:39,268:INFO:_display_container: 2
2023-09-30 16:41:39,268:INFO:Ridge(random_state=88)
2023-09-30 16:41:39,268:INFO:create_model() successfully completed......................................
2023-09-30 16:41:39,388:INFO:SubProcess create_model() end ==================================
2023-09-30 16:41:39,388:INFO:Creating metrics dataframe
2023-09-30 16:41:39,421:INFO:Initializing Elastic Net
2023-09-30 16:41:39,421:INFO:Total runtime is 0.3360879023869832 minutes
2023-09-30 16:41:39,426:INFO:SubProcess create_model() called ==================================
2023-09-30 16:41:39,426:INFO:Initializing create_model()
2023-09-30 16:41:39,426:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=en, fold=KFold(n_splits=15, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170B3D0C1F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-30 16:41:39,426:INFO:Checking exceptions
2023-09-30 16:41:39,426:INFO:Importing libraries
2023-09-30 16:41:39,426:INFO:Copying training dataset
2023-09-30 16:41:39,443:INFO:Defining folds
2023-09-30 16:41:39,443:INFO:Declaring metric variables
2023-09-30 16:41:39,454:INFO:Importing untrained model
2023-09-30 16:41:39,461:INFO:Elastic Net Imported successfully
2023-09-30 16:41:39,478:INFO:Starting cross validation
2023-09-30 16:41:39,489:INFO:Cross validating with KFold(n_splits=15, random_state=None, shuffle=False), n_jobs=-1
2023-09-30 16:41:39,706:INFO:Calculating mean and std
2023-09-30 16:41:39,708:INFO:Creating metrics dataframe
2023-09-30 16:41:39,708:INFO:Uploading results into container
2023-09-30 16:41:39,708:INFO:Uploading model into container now
2023-09-30 16:41:39,708:INFO:_master_model_container: 4
2023-09-30 16:41:39,708:INFO:_display_container: 2
2023-09-30 16:41:39,708:INFO:ElasticNet(random_state=88)
2023-09-30 16:41:39,708:INFO:create_model() successfully completed......................................
2023-09-30 16:41:39,822:INFO:SubProcess create_model() end ==================================
2023-09-30 16:41:39,822:INFO:Creating metrics dataframe
2023-09-30 16:41:39,843:INFO:Initializing Least Angle Regression
2023-09-30 16:41:39,843:INFO:Total runtime is 0.34311590194702146 minutes
2023-09-30 16:41:39,843:INFO:SubProcess create_model() called ==================================
2023-09-30 16:41:39,843:INFO:Initializing create_model()
2023-09-30 16:41:39,843:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=lar, fold=KFold(n_splits=15, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170B3D0C1F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-30 16:41:39,843:INFO:Checking exceptions
2023-09-30 16:41:39,843:INFO:Importing libraries
2023-09-30 16:41:39,843:INFO:Copying training dataset
2023-09-30 16:41:39,858:INFO:Defining folds
2023-09-30 16:41:39,858:INFO:Declaring metric variables
2023-09-30 16:41:39,858:INFO:Importing untrained model
2023-09-30 16:41:39,870:INFO:Least Angle Regression Imported successfully
2023-09-30 16:41:39,888:INFO:Starting cross validation
2023-09-30 16:41:39,888:INFO:Cross validating with KFold(n_splits=15, random_state=None, shuffle=False), n_jobs=-1
2023-09-30 16:41:40,138:INFO:Calculating mean and std
2023-09-30 16:41:40,138:INFO:Creating metrics dataframe
2023-09-30 16:41:40,144:INFO:Uploading results into container
2023-09-30 16:41:40,144:INFO:Uploading model into container now
2023-09-30 16:41:40,144:INFO:_master_model_container: 5
2023-09-30 16:41:40,144:INFO:_display_container: 2
2023-09-30 16:41:40,144:INFO:Lars(random_state=88)
2023-09-30 16:41:40,144:INFO:create_model() successfully completed......................................
2023-09-30 16:41:40,260:INFO:SubProcess create_model() end ==================================
2023-09-30 16:41:40,260:INFO:Creating metrics dataframe
2023-09-30 16:41:40,287:INFO:Initializing Lasso Least Angle Regression
2023-09-30 16:41:40,287:INFO:Total runtime is 0.3505274415016174 minutes
2023-09-30 16:41:40,295:INFO:SubProcess create_model() called ==================================
2023-09-30 16:41:40,295:INFO:Initializing create_model()
2023-09-30 16:41:40,295:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=llar, fold=KFold(n_splits=15, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170B3D0C1F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-30 16:41:40,295:INFO:Checking exceptions
2023-09-30 16:41:40,295:INFO:Importing libraries
2023-09-30 16:41:40,295:INFO:Copying training dataset
2023-09-30 16:41:40,307:INFO:Defining folds
2023-09-30 16:41:40,307:INFO:Declaring metric variables
2023-09-30 16:41:40,312:INFO:Importing untrained model
2023-09-30 16:41:40,320:INFO:Lasso Least Angle Regression Imported successfully
2023-09-30 16:41:40,336:INFO:Starting cross validation
2023-09-30 16:41:40,344:INFO:Cross validating with KFold(n_splits=15, random_state=None, shuffle=False), n_jobs=-1
2023-09-30 16:41:40,553:INFO:Calculating mean and std
2023-09-30 16:41:40,553:INFO:Creating metrics dataframe
2023-09-30 16:41:40,553:INFO:Uploading results into container
2023-09-30 16:41:40,553:INFO:Uploading model into container now
2023-09-30 16:41:40,553:INFO:_master_model_container: 6
2023-09-30 16:41:40,553:INFO:_display_container: 2
2023-09-30 16:41:40,553:INFO:LassoLars(random_state=88)
2023-09-30 16:41:40,553:INFO:create_model() successfully completed......................................
2023-09-30 16:41:40,658:INFO:SubProcess create_model() end ==================================
2023-09-30 16:41:40,658:INFO:Creating metrics dataframe
2023-09-30 16:41:40,679:INFO:Initializing Orthogonal Matching Pursuit
2023-09-30 16:41:40,679:INFO:Total runtime is 0.3570547223091125 minutes
2023-09-30 16:41:40,691:INFO:SubProcess create_model() called ==================================
2023-09-30 16:41:40,691:INFO:Initializing create_model()
2023-09-30 16:41:40,691:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=omp, fold=KFold(n_splits=15, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170B3D0C1F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-30 16:41:40,691:INFO:Checking exceptions
2023-09-30 16:41:40,691:INFO:Importing libraries
2023-09-30 16:41:40,691:INFO:Copying training dataset
2023-09-30 16:41:40,691:INFO:Defining folds
2023-09-30 16:41:40,691:INFO:Declaring metric variables
2023-09-30 16:41:40,711:INFO:Importing untrained model
2023-09-30 16:41:40,720:INFO:Orthogonal Matching Pursuit Imported successfully
2023-09-30 16:41:40,737:INFO:Starting cross validation
2023-09-30 16:41:40,737:INFO:Cross validating with KFold(n_splits=15, random_state=None, shuffle=False), n_jobs=-1
2023-09-30 16:41:40,928:INFO:Calculating mean and std
2023-09-30 16:41:40,943:INFO:Creating metrics dataframe
2023-09-30 16:41:40,943:INFO:Uploading results into container
2023-09-30 16:41:40,943:INFO:Uploading model into container now
2023-09-30 16:41:40,943:INFO:_master_model_container: 7
2023-09-30 16:41:40,943:INFO:_display_container: 2
2023-09-30 16:41:40,943:INFO:OrthogonalMatchingPursuit()
2023-09-30 16:41:40,943:INFO:create_model() successfully completed......................................
2023-09-30 16:41:41,070:INFO:SubProcess create_model() end ==================================
2023-09-30 16:41:41,070:INFO:Creating metrics dataframe
2023-09-30 16:41:41,095:INFO:Initializing Bayesian Ridge
2023-09-30 16:41:41,095:INFO:Total runtime is 0.3639815290768941 minutes
2023-09-30 16:41:41,103:INFO:SubProcess create_model() called ==================================
2023-09-30 16:41:41,103:INFO:Initializing create_model()
2023-09-30 16:41:41,103:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=br, fold=KFold(n_splits=15, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170B3D0C1F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-30 16:41:41,103:INFO:Checking exceptions
2023-09-30 16:41:41,103:INFO:Importing libraries
2023-09-30 16:41:41,103:INFO:Copying training dataset
2023-09-30 16:41:41,112:INFO:Defining folds
2023-09-30 16:41:41,112:INFO:Declaring metric variables
2023-09-30 16:41:41,121:INFO:Importing untrained model
2023-09-30 16:41:41,129:INFO:Bayesian Ridge Imported successfully
2023-09-30 16:41:41,154:INFO:Starting cross validation
2023-09-30 16:41:41,154:INFO:Cross validating with KFold(n_splits=15, random_state=None, shuffle=False), n_jobs=-1
2023-09-30 16:41:41,559:INFO:Calculating mean and std
2023-09-30 16:41:41,560:INFO:Creating metrics dataframe
2023-09-30 16:41:41,560:INFO:Uploading results into container
2023-09-30 16:41:41,568:INFO:Uploading model into container now
2023-09-30 16:41:41,568:INFO:_master_model_container: 8
2023-09-30 16:41:41,571:INFO:_display_container: 2
2023-09-30 16:41:41,573:INFO:BayesianRidge()
2023-09-30 16:41:41,574:INFO:create_model() successfully completed......................................
2023-09-30 16:41:41,688:INFO:SubProcess create_model() end ==================================
2023-09-30 16:41:41,688:INFO:Creating metrics dataframe
2023-09-30 16:41:41,706:INFO:Initializing Passive Aggressive Regressor
2023-09-30 16:41:41,706:INFO:Total runtime is 0.37417474587758376 minutes
2023-09-30 16:41:41,706:INFO:SubProcess create_model() called ==================================
2023-09-30 16:41:41,723:INFO:Initializing create_model()
2023-09-30 16:41:41,723:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=par, fold=KFold(n_splits=15, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170B3D0C1F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-30 16:41:41,723:INFO:Checking exceptions
2023-09-30 16:41:41,723:INFO:Importing libraries
2023-09-30 16:41:41,723:INFO:Copying training dataset
2023-09-30 16:41:41,723:INFO:Defining folds
2023-09-30 16:41:41,723:INFO:Declaring metric variables
2023-09-30 16:41:41,738:INFO:Importing untrained model
2023-09-30 16:41:41,740:INFO:Passive Aggressive Regressor Imported successfully
2023-09-30 16:41:41,756:INFO:Starting cross validation
2023-09-30 16:41:41,765:INFO:Cross validating with KFold(n_splits=15, random_state=None, shuffle=False), n_jobs=-1
2023-09-30 16:41:41,978:INFO:Calculating mean and std
2023-09-30 16:41:41,978:INFO:Creating metrics dataframe
2023-09-30 16:41:41,978:INFO:Uploading results into container
2023-09-30 16:41:41,978:INFO:Uploading model into container now
2023-09-30 16:41:41,978:INFO:_master_model_container: 9
2023-09-30 16:41:41,978:INFO:_display_container: 2
2023-09-30 16:41:41,978:INFO:PassiveAggressiveRegressor(random_state=88)
2023-09-30 16:41:41,978:INFO:create_model() successfully completed......................................
2023-09-30 16:41:42,076:INFO:SubProcess create_model() end ==================================
2023-09-30 16:41:42,076:INFO:Creating metrics dataframe
2023-09-30 16:41:42,095:INFO:Initializing Huber Regressor
2023-09-30 16:41:42,095:INFO:Total runtime is 0.3806582967440287 minutes
2023-09-30 16:41:42,095:INFO:SubProcess create_model() called ==================================
2023-09-30 16:41:42,095:INFO:Initializing create_model()
2023-09-30 16:41:42,095:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=huber, fold=KFold(n_splits=15, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170B3D0C1F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-30 16:41:42,095:INFO:Checking exceptions
2023-09-30 16:41:42,095:INFO:Importing libraries
2023-09-30 16:41:42,103:INFO:Copying training dataset
2023-09-30 16:41:42,111:INFO:Defining folds
2023-09-30 16:41:42,111:INFO:Declaring metric variables
2023-09-30 16:41:42,111:INFO:Importing untrained model
2023-09-30 16:41:42,129:INFO:Huber Regressor Imported successfully
2023-09-30 16:41:42,145:INFO:Starting cross validation
2023-09-30 16:41:42,145:INFO:Cross validating with KFold(n_splits=15, random_state=None, shuffle=False), n_jobs=-1
2023-09-30 16:41:42,358:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-30 16:41:42,358:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-30 16:41:42,358:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-30 16:41:42,358:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-30 16:41:42,358:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-30 16:41:42,358:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-30 16:41:42,358:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-30 16:41:42,488:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-30 16:41:42,496:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-30 16:41:42,506:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-30 16:41:42,506:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-30 16:41:42,506:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-30 16:41:42,522:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-30 16:41:42,522:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-30 16:41:42,554:INFO:Calculating mean and std
2023-09-30 16:41:42,554:INFO:Creating metrics dataframe
2023-09-30 16:41:42,554:INFO:Uploading results into container
2023-09-30 16:41:42,554:INFO:Uploading model into container now
2023-09-30 16:41:42,554:INFO:_master_model_container: 10
2023-09-30 16:41:42,554:INFO:_display_container: 2
2023-09-30 16:41:42,554:INFO:HuberRegressor()
2023-09-30 16:41:42,554:INFO:create_model() successfully completed......................................
2023-09-30 16:41:42,662:INFO:SubProcess create_model() end ==================================
2023-09-30 16:41:42,662:INFO:Creating metrics dataframe
2023-09-30 16:41:42,678:INFO:Initializing K Neighbors Regressor
2023-09-30 16:41:42,678:INFO:Total runtime is 0.39037066698074335 minutes
2023-09-30 16:41:42,693:INFO:SubProcess create_model() called ==================================
2023-09-30 16:41:42,693:INFO:Initializing create_model()
2023-09-30 16:41:42,693:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=knn, fold=KFold(n_splits=15, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170B3D0C1F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-30 16:41:42,693:INFO:Checking exceptions
2023-09-30 16:41:42,693:INFO:Importing libraries
2023-09-30 16:41:42,693:INFO:Copying training dataset
2023-09-30 16:41:42,693:INFO:Defining folds
2023-09-30 16:41:42,693:INFO:Declaring metric variables
2023-09-30 16:41:42,710:INFO:Importing untrained model
2023-09-30 16:41:42,720:INFO:K Neighbors Regressor Imported successfully
2023-09-30 16:41:42,738:INFO:Starting cross validation
2023-09-30 16:41:42,738:INFO:Cross validating with KFold(n_splits=15, random_state=None, shuffle=False), n_jobs=-1
2023-09-30 16:41:42,992:INFO:Calculating mean and std
2023-09-30 16:41:42,992:INFO:Creating metrics dataframe
2023-09-30 16:41:42,992:INFO:Uploading results into container
2023-09-30 16:41:42,992:INFO:Uploading model into container now
2023-09-30 16:41:42,992:INFO:_master_model_container: 11
2023-09-30 16:41:42,992:INFO:_display_container: 2
2023-09-30 16:41:42,992:INFO:KNeighborsRegressor(n_jobs=-1)
2023-09-30 16:41:42,992:INFO:create_model() successfully completed......................................
2023-09-30 16:41:43,110:INFO:SubProcess create_model() end ==================================
2023-09-30 16:41:43,110:INFO:Creating metrics dataframe
2023-09-30 16:41:43,126:INFO:Initializing Decision Tree Regressor
2023-09-30 16:41:43,126:INFO:Total runtime is 0.39784571727116896 minutes
2023-09-30 16:41:43,142:INFO:SubProcess create_model() called ==================================
2023-09-30 16:41:43,142:INFO:Initializing create_model()
2023-09-30 16:41:43,142:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=dt, fold=KFold(n_splits=15, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170B3D0C1F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-30 16:41:43,142:INFO:Checking exceptions
2023-09-30 16:41:43,142:INFO:Importing libraries
2023-09-30 16:41:43,142:INFO:Copying training dataset
2023-09-30 16:41:43,142:INFO:Defining folds
2023-09-30 16:41:43,142:INFO:Declaring metric variables
2023-09-30 16:41:43,154:INFO:Importing untrained model
2023-09-30 16:41:43,162:INFO:Decision Tree Regressor Imported successfully
2023-09-30 16:41:43,178:INFO:Starting cross validation
2023-09-30 16:41:43,178:INFO:Cross validating with KFold(n_splits=15, random_state=None, shuffle=False), n_jobs=-1
2023-09-30 16:41:43,374:INFO:Calculating mean and std
2023-09-30 16:41:43,374:INFO:Creating metrics dataframe
2023-09-30 16:41:43,374:INFO:Uploading results into container
2023-09-30 16:41:43,374:INFO:Uploading model into container now
2023-09-30 16:41:43,374:INFO:_master_model_container: 12
2023-09-30 16:41:43,374:INFO:_display_container: 2
2023-09-30 16:41:43,374:INFO:DecisionTreeRegressor(random_state=88)
2023-09-30 16:41:43,374:INFO:create_model() successfully completed......................................
2023-09-30 16:41:43,454:INFO:SubProcess create_model() end ==================================
2023-09-30 16:41:43,459:INFO:Creating metrics dataframe
2023-09-30 16:41:43,477:INFO:Initializing Random Forest Regressor
2023-09-30 16:41:43,477:INFO:Total runtime is 0.4036810199419657 minutes
2023-09-30 16:41:43,488:INFO:SubProcess create_model() called ==================================
2023-09-30 16:41:43,488:INFO:Initializing create_model()
2023-09-30 16:41:43,488:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=rf, fold=KFold(n_splits=15, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170B3D0C1F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-30 16:41:43,488:INFO:Checking exceptions
2023-09-30 16:41:43,488:INFO:Importing libraries
2023-09-30 16:41:43,488:INFO:Copying training dataset
2023-09-30 16:41:43,496:INFO:Defining folds
2023-09-30 16:41:43,496:INFO:Declaring metric variables
2023-09-30 16:41:43,511:INFO:Importing untrained model
2023-09-30 16:41:43,511:INFO:Random Forest Regressor Imported successfully
2023-09-30 16:41:43,545:INFO:Starting cross validation
2023-09-30 16:41:43,545:INFO:Cross validating with KFold(n_splits=15, random_state=None, shuffle=False), n_jobs=-1
2023-09-30 16:41:45,589:INFO:Calculating mean and std
2023-09-30 16:41:45,589:INFO:Creating metrics dataframe
2023-09-30 16:41:45,589:INFO:Uploading results into container
2023-09-30 16:41:45,589:INFO:Uploading model into container now
2023-09-30 16:41:45,589:INFO:_master_model_container: 13
2023-09-30 16:41:45,589:INFO:_display_container: 2
2023-09-30 16:41:45,589:INFO:RandomForestRegressor(n_jobs=-1, random_state=88)
2023-09-30 16:41:45,589:INFO:create_model() successfully completed......................................
2023-09-30 16:41:45,673:INFO:SubProcess create_model() end ==================================
2023-09-30 16:41:45,673:INFO:Creating metrics dataframe
2023-09-30 16:41:45,712:INFO:Initializing Extra Trees Regressor
2023-09-30 16:41:45,712:INFO:Total runtime is 0.440933616956075 minutes
2023-09-30 16:41:45,728:INFO:SubProcess create_model() called ==================================
2023-09-30 16:41:45,728:INFO:Initializing create_model()
2023-09-30 16:41:45,728:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=et, fold=KFold(n_splits=15, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170B3D0C1F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-30 16:41:45,728:INFO:Checking exceptions
2023-09-30 16:41:45,728:INFO:Importing libraries
2023-09-30 16:41:45,728:INFO:Copying training dataset
2023-09-30 16:41:45,739:INFO:Defining folds
2023-09-30 16:41:45,739:INFO:Declaring metric variables
2023-09-30 16:41:45,739:INFO:Importing untrained model
2023-09-30 16:41:45,760:INFO:Extra Trees Regressor Imported successfully
2023-09-30 16:41:45,780:INFO:Starting cross validation
2023-09-30 16:41:45,780:INFO:Cross validating with KFold(n_splits=15, random_state=None, shuffle=False), n_jobs=-1
2023-09-30 16:41:47,307:INFO:Calculating mean and std
2023-09-30 16:41:47,307:INFO:Creating metrics dataframe
2023-09-30 16:41:47,307:INFO:Uploading results into container
2023-09-30 16:41:47,307:INFO:Uploading model into container now
2023-09-30 16:41:47,307:INFO:_master_model_container: 14
2023-09-30 16:41:47,307:INFO:_display_container: 2
2023-09-30 16:41:47,307:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=88)
2023-09-30 16:41:47,321:INFO:create_model() successfully completed......................................
2023-09-30 16:41:47,404:INFO:SubProcess create_model() end ==================================
2023-09-30 16:41:47,404:INFO:Creating metrics dataframe
2023-09-30 16:41:47,426:INFO:Initializing AdaBoost Regressor
2023-09-30 16:41:47,426:INFO:Total runtime is 0.46951236327489215 minutes
2023-09-30 16:41:47,446:INFO:SubProcess create_model() called ==================================
2023-09-30 16:41:47,446:INFO:Initializing create_model()
2023-09-30 16:41:47,446:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=ada, fold=KFold(n_splits=15, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170B3D0C1F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-30 16:41:47,446:INFO:Checking exceptions
2023-09-30 16:41:47,446:INFO:Importing libraries
2023-09-30 16:41:47,446:INFO:Copying training dataset
2023-09-30 16:41:47,446:INFO:Defining folds
2023-09-30 16:41:47,446:INFO:Declaring metric variables
2023-09-30 16:41:47,456:INFO:Importing untrained model
2023-09-30 16:41:47,456:INFO:AdaBoost Regressor Imported successfully
2023-09-30 16:41:47,488:INFO:Starting cross validation
2023-09-30 16:41:47,488:INFO:Cross validating with KFold(n_splits=15, random_state=None, shuffle=False), n_jobs=-1
2023-09-30 16:41:48,226:INFO:Calculating mean and std
2023-09-30 16:41:48,226:INFO:Creating metrics dataframe
2023-09-30 16:41:48,226:INFO:Uploading results into container
2023-09-30 16:41:48,226:INFO:Uploading model into container now
2023-09-30 16:41:48,226:INFO:_master_model_container: 15
2023-09-30 16:41:48,226:INFO:_display_container: 2
2023-09-30 16:41:48,234:INFO:AdaBoostRegressor(random_state=88)
2023-09-30 16:41:48,234:INFO:create_model() successfully completed......................................
2023-09-30 16:41:48,314:INFO:SubProcess create_model() end ==================================
2023-09-30 16:41:48,314:INFO:Creating metrics dataframe
2023-09-30 16:41:48,339:INFO:Initializing Gradient Boosting Regressor
2023-09-30 16:41:48,339:INFO:Total runtime is 0.48472866614659627 minutes
2023-09-30 16:41:48,339:INFO:SubProcess create_model() called ==================================
2023-09-30 16:41:48,339:INFO:Initializing create_model()
2023-09-30 16:41:48,339:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=gbr, fold=KFold(n_splits=15, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170B3D0C1F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-30 16:41:48,339:INFO:Checking exceptions
2023-09-30 16:41:48,339:INFO:Importing libraries
2023-09-30 16:41:48,339:INFO:Copying training dataset
2023-09-30 16:41:48,339:INFO:Defining folds
2023-09-30 16:41:48,339:INFO:Declaring metric variables
2023-09-30 16:41:48,355:INFO:Importing untrained model
2023-09-30 16:41:48,362:INFO:Gradient Boosting Regressor Imported successfully
2023-09-30 16:41:48,386:INFO:Starting cross validation
2023-09-30 16:41:48,387:INFO:Cross validating with KFold(n_splits=15, random_state=None, shuffle=False), n_jobs=-1
2023-09-30 16:41:48,992:INFO:Calculating mean and std
2023-09-30 16:41:48,992:INFO:Creating metrics dataframe
2023-09-30 16:41:48,997:INFO:Uploading results into container
2023-09-30 16:41:48,997:INFO:Uploading model into container now
2023-09-30 16:41:48,997:INFO:_master_model_container: 16
2023-09-30 16:41:48,997:INFO:_display_container: 2
2023-09-30 16:41:48,997:INFO:GradientBoostingRegressor(random_state=88)
2023-09-30 16:41:48,997:INFO:create_model() successfully completed......................................
2023-09-30 16:41:49,094:INFO:SubProcess create_model() end ==================================
2023-09-30 16:41:49,094:INFO:Creating metrics dataframe
2023-09-30 16:41:49,109:INFO:Initializing Extreme Gradient Boosting
2023-09-30 16:41:49,109:INFO:Total runtime is 0.49756087859471637 minutes
2023-09-30 16:41:49,121:INFO:SubProcess create_model() called ==================================
2023-09-30 16:41:49,121:INFO:Initializing create_model()
2023-09-30 16:41:49,121:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=xgboost, fold=KFold(n_splits=15, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170B3D0C1F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-30 16:41:49,121:INFO:Checking exceptions
2023-09-30 16:41:49,121:INFO:Importing libraries
2023-09-30 16:41:49,121:INFO:Copying training dataset
2023-09-30 16:41:49,129:INFO:Defining folds
2023-09-30 16:41:49,129:INFO:Declaring metric variables
2023-09-30 16:41:49,139:INFO:Importing untrained model
2023-09-30 16:41:49,139:INFO:Extreme Gradient Boosting Imported successfully
2023-09-30 16:41:49,171:INFO:Starting cross validation
2023-09-30 16:41:49,171:INFO:Cross validating with KFold(n_splits=15, random_state=None, shuffle=False), n_jobs=-1
2023-09-30 16:41:51,873:INFO:Calculating mean and std
2023-09-30 16:41:51,873:INFO:Creating metrics dataframe
2023-09-30 16:41:51,890:INFO:Uploading results into container
2023-09-30 16:41:51,890:INFO:Uploading model into container now
2023-09-30 16:41:51,890:INFO:_master_model_container: 17
2023-09-30 16:41:51,890:INFO:_display_container: 2
2023-09-30 16:41:51,907:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=88, ...)
2023-09-30 16:41:51,907:INFO:create_model() successfully completed......................................
2023-09-30 16:41:52,137:INFO:SubProcess create_model() end ==================================
2023-09-30 16:41:52,137:INFO:Creating metrics dataframe
2023-09-30 16:41:52,224:INFO:Initializing Light Gradient Boosting Machine
2023-09-30 16:41:52,224:INFO:Total runtime is 0.5494648655255635 minutes
2023-09-30 16:41:52,241:INFO:SubProcess create_model() called ==================================
2023-09-30 16:41:52,241:INFO:Initializing create_model()
2023-09-30 16:41:52,249:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=lightgbm, fold=KFold(n_splits=15, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170B3D0C1F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-30 16:41:52,249:INFO:Checking exceptions
2023-09-30 16:41:52,249:INFO:Importing libraries
2023-09-30 16:41:52,249:INFO:Copying training dataset
2023-09-30 16:41:52,269:INFO:Defining folds
2023-09-30 16:41:52,272:INFO:Declaring metric variables
2023-09-30 16:41:52,285:INFO:Importing untrained model
2023-09-30 16:41:52,303:INFO:Light Gradient Boosting Machine Imported successfully
2023-09-30 16:41:52,344:INFO:Starting cross validation
2023-09-30 16:41:52,357:INFO:Cross validating with KFold(n_splits=15, random_state=None, shuffle=False), n_jobs=-1
2023-09-30 16:41:55,880:INFO:Calculating mean and std
2023-09-30 16:41:55,886:INFO:Creating metrics dataframe
2023-09-30 16:41:55,910:INFO:Uploading results into container
2023-09-30 16:41:55,910:INFO:Uploading model into container now
2023-09-30 16:41:55,910:INFO:_master_model_container: 18
2023-09-30 16:41:55,910:INFO:_display_container: 2
2023-09-30 16:41:55,910:INFO:LGBMRegressor(n_jobs=-1, random_state=88)
2023-09-30 16:41:55,918:INFO:create_model() successfully completed......................................
2023-09-30 16:41:56,113:INFO:SubProcess create_model() end ==================================
2023-09-30 16:41:56,113:INFO:Creating metrics dataframe
2023-09-30 16:41:56,160:INFO:Initializing Dummy Regressor
2023-09-30 16:41:56,160:INFO:Total runtime is 0.6150656183560689 minutes
2023-09-30 16:41:56,172:INFO:SubProcess create_model() called ==================================
2023-09-30 16:41:56,172:INFO:Initializing create_model()
2023-09-30 16:41:56,172:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=dummy, fold=KFold(n_splits=15, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170B3D0C1F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-30 16:41:56,172:INFO:Checking exceptions
2023-09-30 16:41:56,172:INFO:Importing libraries
2023-09-30 16:41:56,180:INFO:Copying training dataset
2023-09-30 16:41:56,182:INFO:Defining folds
2023-09-30 16:41:56,182:INFO:Declaring metric variables
2023-09-30 16:41:56,213:INFO:Importing untrained model
2023-09-30 16:41:56,229:INFO:Dummy Regressor Imported successfully
2023-09-30 16:41:56,269:INFO:Starting cross validation
2023-09-30 16:41:56,277:INFO:Cross validating with KFold(n_splits=15, random_state=None, shuffle=False), n_jobs=-1
2023-09-30 16:41:56,732:INFO:Calculating mean and std
2023-09-30 16:41:56,732:INFO:Creating metrics dataframe
2023-09-30 16:41:56,748:INFO:Uploading results into container
2023-09-30 16:41:56,748:INFO:Uploading model into container now
2023-09-30 16:41:56,748:INFO:_master_model_container: 19
2023-09-30 16:41:56,754:INFO:_display_container: 2
2023-09-30 16:41:56,754:INFO:DummyRegressor()
2023-09-30 16:41:56,754:INFO:create_model() successfully completed......................................
2023-09-30 16:41:56,908:INFO:SubProcess create_model() end ==================================
2023-09-30 16:41:56,908:INFO:Creating metrics dataframe
2023-09-30 16:41:57,009:INFO:Initializing create_model()
2023-09-30 16:41:57,009:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=88), fold=KFold(n_splits=15, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-30 16:41:57,009:INFO:Checking exceptions
2023-09-30 16:41:57,025:INFO:Importing libraries
2023-09-30 16:41:57,025:INFO:Copying training dataset
2023-09-30 16:41:57,039:INFO:Defining folds
2023-09-30 16:41:57,039:INFO:Declaring metric variables
2023-09-30 16:41:57,039:INFO:Importing untrained model
2023-09-30 16:41:57,039:INFO:Declaring custom model
2023-09-30 16:41:57,047:INFO:Extra Trees Regressor Imported successfully
2023-09-30 16:41:57,047:INFO:Cross validation set to False
2023-09-30 16:41:57,047:INFO:Fitting Model
2023-09-30 16:41:57,696:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=88)
2023-09-30 16:41:57,696:INFO:create_model() successfully completed......................................
2023-09-30 16:41:58,081:INFO:_master_model_container: 19
2023-09-30 16:41:58,081:INFO:_display_container: 2
2023-09-30 16:41:58,081:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=88)
2023-09-30 16:41:58,089:INFO:compare_models() successfully completed......................................
2023-09-30 16:43:09,322:INFO:Initializing compare_models()
2023-09-30 16:43:09,322:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, include=None, fold=None, round=4, cross_validation=True, sort=RMSE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'RMSE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-09-30 16:43:09,322:INFO:Checking exceptions
2023-09-30 16:43:09,339:INFO:Preparing display monitor
2023-09-30 16:43:09,412:INFO:Initializing Linear Regression
2023-09-30 16:43:09,412:INFO:Total runtime is 0.0 minutes
2023-09-30 16:43:09,420:INFO:SubProcess create_model() called ==================================
2023-09-30 16:43:09,420:INFO:Initializing create_model()
2023-09-30 16:43:09,420:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=lr, fold=KFold(n_splits=15, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170B10A0A30>, model_only=True, return_train_score=False, kwargs={})
2023-09-30 16:43:09,420:INFO:Checking exceptions
2023-09-30 16:43:09,420:INFO:Importing libraries
2023-09-30 16:43:09,420:INFO:Copying training dataset
2023-09-30 16:43:09,437:INFO:Defining folds
2023-09-30 16:43:09,437:INFO:Declaring metric variables
2023-09-30 16:43:09,453:INFO:Importing untrained model
2023-09-30 16:43:09,461:INFO:Linear Regression Imported successfully
2023-09-30 16:43:09,485:INFO:Starting cross validation
2023-09-30 16:43:09,485:INFO:Cross validating with KFold(n_splits=15, random_state=None, shuffle=False), n_jobs=-1
2023-09-30 16:43:09,857:INFO:Calculating mean and std
2023-09-30 16:43:09,857:INFO:Creating metrics dataframe
2023-09-30 16:43:09,872:INFO:Uploading results into container
2023-09-30 16:43:09,880:INFO:Uploading model into container now
2023-09-30 16:43:09,880:INFO:_master_model_container: 20
2023-09-30 16:43:09,880:INFO:_display_container: 3
2023-09-30 16:43:09,880:INFO:LinearRegression(n_jobs=-1)
2023-09-30 16:43:09,880:INFO:create_model() successfully completed......................................
2023-09-30 16:43:10,079:INFO:SubProcess create_model() end ==================================
2023-09-30 16:43:10,079:INFO:Creating metrics dataframe
2023-09-30 16:43:10,121:INFO:Initializing Lasso Regression
2023-09-30 16:43:10,121:INFO:Total runtime is 0.011819096406300862 minutes
2023-09-30 16:43:10,134:INFO:SubProcess create_model() called ==================================
2023-09-30 16:43:10,134:INFO:Initializing create_model()
2023-09-30 16:43:10,142:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=lasso, fold=KFold(n_splits=15, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170B10A0A30>, model_only=True, return_train_score=False, kwargs={})
2023-09-30 16:43:10,142:INFO:Checking exceptions
2023-09-30 16:43:10,142:INFO:Importing libraries
2023-09-30 16:43:10,142:INFO:Copying training dataset
2023-09-30 16:43:10,153:INFO:Defining folds
2023-09-30 16:43:10,153:INFO:Declaring metric variables
2023-09-30 16:43:10,166:INFO:Importing untrained model
2023-09-30 16:43:10,174:INFO:Lasso Regression Imported successfully
2023-09-30 16:43:10,191:INFO:Starting cross validation
2023-09-30 16:43:10,191:INFO:Cross validating with KFold(n_splits=15, random_state=None, shuffle=False), n_jobs=-1
2023-09-30 16:43:10,278:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.008e+07, tolerance: 9.540e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-30 16:43:10,290:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.247e+07, tolerance: 9.332e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-30 16:43:10,306:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.154e+07, tolerance: 9.470e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-30 16:43:10,324:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.007e+07, tolerance: 9.465e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-30 16:43:10,324:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.933e+07, tolerance: 9.374e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-30 16:43:10,358:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.965e+07, tolerance: 9.513e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-30 16:43:10,368:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.887e+07, tolerance: 9.614e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-30 16:43:10,378:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.962e+07, tolerance: 9.388e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-30 16:43:10,395:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.092e+07, tolerance: 9.648e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-30 16:43:10,408:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.051e+07, tolerance: 9.508e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-30 16:43:10,425:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.112e+07, tolerance: 9.588e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-30 16:43:10,425:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.031e+07, tolerance: 9.378e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-30 16:43:10,439:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.143e+07, tolerance: 9.703e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-30 16:43:10,463:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.899e+07, tolerance: 9.514e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-30 16:43:10,475:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.170e+07, tolerance: 9.612e+04
  model = cd_fast.enet_coordinate_descent(

2023-09-30 16:43:10,497:INFO:Calculating mean and std
2023-09-30 16:43:10,497:INFO:Creating metrics dataframe
2023-09-30 16:43:10,508:INFO:Uploading results into container
2023-09-30 16:43:10,508:INFO:Uploading model into container now
2023-09-30 16:43:10,514:INFO:_master_model_container: 21
2023-09-30 16:43:10,514:INFO:_display_container: 3
2023-09-30 16:43:10,515:INFO:Lasso(random_state=88)
2023-09-30 16:43:10,516:INFO:create_model() successfully completed......................................
2023-09-30 16:43:10,635:INFO:SubProcess create_model() end ==================================
2023-09-30 16:43:10,635:INFO:Creating metrics dataframe
2023-09-30 16:43:10,664:INFO:Initializing Ridge Regression
2023-09-30 16:43:10,664:INFO:Total runtime is 0.020854059855143228 minutes
2023-09-30 16:43:10,672:INFO:SubProcess create_model() called ==================================
2023-09-30 16:43:10,672:INFO:Initializing create_model()
2023-09-30 16:43:10,674:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=ridge, fold=KFold(n_splits=15, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170B10A0A30>, model_only=True, return_train_score=False, kwargs={})
2023-09-30 16:43:10,676:INFO:Checking exceptions
2023-09-30 16:43:10,676:INFO:Importing libraries
2023-09-30 16:43:10,676:INFO:Copying training dataset
2023-09-30 16:43:10,676:INFO:Defining folds
2023-09-30 16:43:10,676:INFO:Declaring metric variables
2023-09-30 16:43:10,690:INFO:Importing untrained model
2023-09-30 16:43:10,703:INFO:Ridge Regression Imported successfully
2023-09-30 16:43:10,716:INFO:Starting cross validation
2023-09-30 16:43:10,716:INFO:Cross validating with KFold(n_splits=15, random_state=None, shuffle=False), n_jobs=-1
2023-09-30 16:43:10,990:INFO:Calculating mean and std
2023-09-30 16:43:10,995:INFO:Creating metrics dataframe
2023-09-30 16:43:11,004:INFO:Uploading results into container
2023-09-30 16:43:11,008:INFO:Uploading model into container now
2023-09-30 16:43:11,010:INFO:_master_model_container: 22
2023-09-30 16:43:11,010:INFO:_display_container: 3
2023-09-30 16:43:11,011:INFO:Ridge(random_state=88)
2023-09-30 16:43:11,011:INFO:create_model() successfully completed......................................
2023-09-30 16:43:11,125:INFO:SubProcess create_model() end ==================================
2023-09-30 16:43:11,125:INFO:Creating metrics dataframe
2023-09-30 16:43:11,148:INFO:Initializing Elastic Net
2023-09-30 16:43:11,148:INFO:Total runtime is 0.028924103577931723 minutes
2023-09-30 16:43:11,148:INFO:SubProcess create_model() called ==================================
2023-09-30 16:43:11,148:INFO:Initializing create_model()
2023-09-30 16:43:11,148:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=en, fold=KFold(n_splits=15, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170B10A0A30>, model_only=True, return_train_score=False, kwargs={})
2023-09-30 16:43:11,148:INFO:Checking exceptions
2023-09-30 16:43:11,156:INFO:Importing libraries
2023-09-30 16:43:11,156:INFO:Copying training dataset
2023-09-30 16:43:11,158:INFO:Defining folds
2023-09-30 16:43:11,158:INFO:Declaring metric variables
2023-09-30 16:43:11,175:INFO:Importing untrained model
2023-09-30 16:43:11,180:INFO:Elastic Net Imported successfully
2023-09-30 16:43:11,197:INFO:Starting cross validation
2023-09-30 16:43:11,206:INFO:Cross validating with KFold(n_splits=15, random_state=None, shuffle=False), n_jobs=-1
2023-09-30 16:43:11,456:INFO:Calculating mean and std
2023-09-30 16:43:11,460:INFO:Creating metrics dataframe
2023-09-30 16:43:11,460:INFO:Uploading results into container
2023-09-30 16:43:11,460:INFO:Uploading model into container now
2023-09-30 16:43:11,460:INFO:_master_model_container: 23
2023-09-30 16:43:11,460:INFO:_display_container: 3
2023-09-30 16:43:11,460:INFO:ElasticNet(random_state=88)
2023-09-30 16:43:11,460:INFO:create_model() successfully completed......................................
2023-09-30 16:43:11,592:INFO:SubProcess create_model() end ==================================
2023-09-30 16:43:11,592:INFO:Creating metrics dataframe
2023-09-30 16:43:11,614:INFO:Initializing Least Angle Regression
2023-09-30 16:43:11,614:INFO:Total runtime is 0.03669414122899373 minutes
2023-09-30 16:43:11,622:INFO:SubProcess create_model() called ==================================
2023-09-30 16:43:11,622:INFO:Initializing create_model()
2023-09-30 16:43:11,622:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=lar, fold=KFold(n_splits=15, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170B10A0A30>, model_only=True, return_train_score=False, kwargs={})
2023-09-30 16:43:11,622:INFO:Checking exceptions
2023-09-30 16:43:11,622:INFO:Importing libraries
2023-09-30 16:43:11,622:INFO:Copying training dataset
2023-09-30 16:43:11,628:INFO:Defining folds
2023-09-30 16:43:11,628:INFO:Declaring metric variables
2023-09-30 16:43:11,639:INFO:Importing untrained model
2023-09-30 16:43:11,647:INFO:Least Angle Regression Imported successfully
2023-09-30 16:43:11,672:INFO:Starting cross validation
2023-09-30 16:43:11,672:INFO:Cross validating with KFold(n_splits=15, random_state=None, shuffle=False), n_jobs=-1
2023-09-30 16:43:11,923:INFO:Calculating mean and std
2023-09-30 16:43:11,923:INFO:Creating metrics dataframe
2023-09-30 16:43:11,923:INFO:Uploading results into container
2023-09-30 16:43:11,923:INFO:Uploading model into container now
2023-09-30 16:43:11,923:INFO:_master_model_container: 24
2023-09-30 16:43:11,923:INFO:_display_container: 3
2023-09-30 16:43:11,923:INFO:Lars(random_state=88)
2023-09-30 16:43:11,923:INFO:create_model() successfully completed......................................
2023-09-30 16:43:12,056:INFO:SubProcess create_model() end ==================================
2023-09-30 16:43:12,056:INFO:Creating metrics dataframe
2023-09-30 16:43:12,088:INFO:Initializing Lasso Least Angle Regression
2023-09-30 16:43:12,096:INFO:Total runtime is 0.044724678993225096 minutes
2023-09-30 16:43:12,104:INFO:SubProcess create_model() called ==================================
2023-09-30 16:43:12,104:INFO:Initializing create_model()
2023-09-30 16:43:12,104:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=llar, fold=KFold(n_splits=15, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170B10A0A30>, model_only=True, return_train_score=False, kwargs={})
2023-09-30 16:43:12,104:INFO:Checking exceptions
2023-09-30 16:43:12,104:INFO:Importing libraries
2023-09-30 16:43:12,104:INFO:Copying training dataset
2023-09-30 16:43:12,117:INFO:Defining folds
2023-09-30 16:43:12,117:INFO:Declaring metric variables
2023-09-30 16:43:12,125:INFO:Importing untrained model
2023-09-30 16:43:12,138:INFO:Lasso Least Angle Regression Imported successfully
2023-09-30 16:43:12,156:INFO:Starting cross validation
2023-09-30 16:43:12,156:INFO:Cross validating with KFold(n_splits=15, random_state=None, shuffle=False), n_jobs=-1
2023-09-30 16:43:12,346:INFO:Calculating mean and std
2023-09-30 16:43:12,346:INFO:Creating metrics dataframe
2023-09-30 16:43:12,346:INFO:Uploading results into container
2023-09-30 16:43:12,346:INFO:Uploading model into container now
2023-09-30 16:43:12,346:INFO:_master_model_container: 25
2023-09-30 16:43:12,346:INFO:_display_container: 3
2023-09-30 16:43:12,346:INFO:LassoLars(random_state=88)
2023-09-30 16:43:12,346:INFO:create_model() successfully completed......................................
2023-09-30 16:43:12,408:INFO:SubProcess create_model() end ==================================
2023-09-30 16:43:12,424:INFO:Creating metrics dataframe
2023-09-30 16:43:12,439:INFO:Initializing Orthogonal Matching Pursuit
2023-09-30 16:43:12,439:INFO:Total runtime is 0.050452975432078044 minutes
2023-09-30 16:43:12,448:INFO:SubProcess create_model() called ==================================
2023-09-30 16:43:12,448:INFO:Initializing create_model()
2023-09-30 16:43:12,448:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=omp, fold=KFold(n_splits=15, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170B10A0A30>, model_only=True, return_train_score=False, kwargs={})
2023-09-30 16:43:12,448:INFO:Checking exceptions
2023-09-30 16:43:12,448:INFO:Importing libraries
2023-09-30 16:43:12,448:INFO:Copying training dataset
2023-09-30 16:43:12,456:INFO:Defining folds
2023-09-30 16:43:12,456:INFO:Declaring metric variables
2023-09-30 16:43:12,462:INFO:Importing untrained model
2023-09-30 16:43:12,473:INFO:Orthogonal Matching Pursuit Imported successfully
2023-09-30 16:43:12,489:INFO:Starting cross validation
2023-09-30 16:43:12,497:INFO:Cross validating with KFold(n_splits=15, random_state=None, shuffle=False), n_jobs=-1
2023-09-30 16:43:12,669:INFO:Calculating mean and std
2023-09-30 16:43:12,669:INFO:Creating metrics dataframe
2023-09-30 16:43:12,676:INFO:Uploading results into container
2023-09-30 16:43:12,676:INFO:Uploading model into container now
2023-09-30 16:43:12,676:INFO:_master_model_container: 26
2023-09-30 16:43:12,676:INFO:_display_container: 3
2023-09-30 16:43:12,676:INFO:OrthogonalMatchingPursuit()
2023-09-30 16:43:12,676:INFO:create_model() successfully completed......................................
2023-09-30 16:43:12,766:INFO:SubProcess create_model() end ==================================
2023-09-30 16:43:12,766:INFO:Creating metrics dataframe
2023-09-30 16:43:12,790:INFO:Initializing Bayesian Ridge
2023-09-30 16:43:12,790:INFO:Total runtime is 0.05629000266393026 minutes
2023-09-30 16:43:12,796:INFO:SubProcess create_model() called ==================================
2023-09-30 16:43:12,796:INFO:Initializing create_model()
2023-09-30 16:43:12,796:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=br, fold=KFold(n_splits=15, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170B10A0A30>, model_only=True, return_train_score=False, kwargs={})
2023-09-30 16:43:12,796:INFO:Checking exceptions
2023-09-30 16:43:12,796:INFO:Importing libraries
2023-09-30 16:43:12,796:INFO:Copying training dataset
2023-09-30 16:43:12,805:INFO:Defining folds
2023-09-30 16:43:12,805:INFO:Declaring metric variables
2023-09-30 16:43:12,817:INFO:Importing untrained model
2023-09-30 16:43:12,828:INFO:Bayesian Ridge Imported successfully
2023-09-30 16:43:12,840:INFO:Starting cross validation
2023-09-30 16:43:12,840:INFO:Cross validating with KFold(n_splits=15, random_state=None, shuffle=False), n_jobs=-1
2023-09-30 16:43:13,205:INFO:Calculating mean and std
2023-09-30 16:43:13,206:INFO:Creating metrics dataframe
2023-09-30 16:43:13,211:INFO:Uploading results into container
2023-09-30 16:43:13,211:INFO:Uploading model into container now
2023-09-30 16:43:13,211:INFO:_master_model_container: 27
2023-09-30 16:43:13,211:INFO:_display_container: 3
2023-09-30 16:43:13,211:INFO:BayesianRidge()
2023-09-30 16:43:13,211:INFO:create_model() successfully completed......................................
2023-09-30 16:43:13,306:INFO:SubProcess create_model() end ==================================
2023-09-30 16:43:13,312:INFO:Creating metrics dataframe
2023-09-30 16:43:13,330:INFO:Initializing Passive Aggressive Regressor
2023-09-30 16:43:13,330:INFO:Total runtime is 0.06529471476872761 minutes
2023-09-30 16:43:13,339:INFO:SubProcess create_model() called ==================================
2023-09-30 16:43:13,347:INFO:Initializing create_model()
2023-09-30 16:43:13,347:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=par, fold=KFold(n_splits=15, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170B10A0A30>, model_only=True, return_train_score=False, kwargs={})
2023-09-30 16:43:13,347:INFO:Checking exceptions
2023-09-30 16:43:13,347:INFO:Importing libraries
2023-09-30 16:43:13,347:INFO:Copying training dataset
2023-09-30 16:43:13,357:INFO:Defining folds
2023-09-30 16:43:13,357:INFO:Declaring metric variables
2023-09-30 16:43:13,365:INFO:Importing untrained model
2023-09-30 16:43:13,373:INFO:Passive Aggressive Regressor Imported successfully
2023-09-30 16:43:13,397:INFO:Starting cross validation
2023-09-30 16:43:13,397:INFO:Cross validating with KFold(n_splits=15, random_state=None, shuffle=False), n_jobs=-1
2023-09-30 16:43:13,592:INFO:Calculating mean and std
2023-09-30 16:43:13,592:INFO:Creating metrics dataframe
2023-09-30 16:43:13,599:INFO:Uploading results into container
2023-09-30 16:43:13,599:INFO:Uploading model into container now
2023-09-30 16:43:13,599:INFO:_master_model_container: 28
2023-09-30 16:43:13,599:INFO:_display_container: 3
2023-09-30 16:43:13,599:INFO:PassiveAggressiveRegressor(random_state=88)
2023-09-30 16:43:13,599:INFO:create_model() successfully completed......................................
2023-09-30 16:43:13,689:INFO:SubProcess create_model() end ==================================
2023-09-30 16:43:13,689:INFO:Creating metrics dataframe
2023-09-30 16:43:13,723:INFO:Initializing Huber Regressor
2023-09-30 16:43:13,723:INFO:Total runtime is 0.07185017665227253 minutes
2023-09-30 16:43:13,728:INFO:SubProcess create_model() called ==================================
2023-09-30 16:43:13,728:INFO:Initializing create_model()
2023-09-30 16:43:13,728:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=huber, fold=KFold(n_splits=15, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170B10A0A30>, model_only=True, return_train_score=False, kwargs={})
2023-09-30 16:43:13,728:INFO:Checking exceptions
2023-09-30 16:43:13,728:INFO:Importing libraries
2023-09-30 16:43:13,728:INFO:Copying training dataset
2023-09-30 16:43:13,728:INFO:Defining folds
2023-09-30 16:43:13,728:INFO:Declaring metric variables
2023-09-30 16:43:13,744:INFO:Importing untrained model
2023-09-30 16:43:13,747:INFO:Huber Regressor Imported successfully
2023-09-30 16:43:13,763:INFO:Starting cross validation
2023-09-30 16:43:13,763:INFO:Cross validating with KFold(n_splits=15, random_state=None, shuffle=False), n_jobs=-1
2023-09-30 16:43:13,980:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-30 16:43:13,989:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-30 16:43:14,004:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-30 16:43:14,018:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-30 16:43:14,034:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-30 16:43:14,034:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-30 16:43:14,067:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-30 16:43:14,076:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-30 16:43:14,158:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-30 16:43:14,176:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-30 16:43:14,176:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-30 16:43:14,193:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-30 16:43:14,193:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-30 16:43:14,213:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-30 16:43:14,213:WARNING:C:\Users\maxxk\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-30 16:43:14,249:INFO:Calculating mean and std
2023-09-30 16:43:14,249:INFO:Creating metrics dataframe
2023-09-30 16:43:14,256:INFO:Uploading results into container
2023-09-30 16:43:14,256:INFO:Uploading model into container now
2023-09-30 16:43:14,256:INFO:_master_model_container: 29
2023-09-30 16:43:14,256:INFO:_display_container: 3
2023-09-30 16:43:14,256:INFO:HuberRegressor()
2023-09-30 16:43:14,256:INFO:create_model() successfully completed......................................
2023-09-30 16:43:14,359:INFO:SubProcess create_model() end ==================================
2023-09-30 16:43:14,359:INFO:Creating metrics dataframe
2023-09-30 16:43:14,382:INFO:Initializing K Neighbors Regressor
2023-09-30 16:43:14,382:INFO:Total runtime is 0.08282502889633178 minutes
2023-09-30 16:43:14,396:INFO:SubProcess create_model() called ==================================
2023-09-30 16:43:14,396:INFO:Initializing create_model()
2023-09-30 16:43:14,396:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=knn, fold=KFold(n_splits=15, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170B10A0A30>, model_only=True, return_train_score=False, kwargs={})
2023-09-30 16:43:14,396:INFO:Checking exceptions
2023-09-30 16:43:14,396:INFO:Importing libraries
2023-09-30 16:43:14,396:INFO:Copying training dataset
2023-09-30 16:43:14,406:INFO:Defining folds
2023-09-30 16:43:14,406:INFO:Declaring metric variables
2023-09-30 16:43:14,415:INFO:Importing untrained model
2023-09-30 16:43:14,432:INFO:K Neighbors Regressor Imported successfully
2023-09-30 16:43:14,441:INFO:Starting cross validation
2023-09-30 16:43:14,449:INFO:Cross validating with KFold(n_splits=15, random_state=None, shuffle=False), n_jobs=-1
2023-09-30 16:43:14,695:INFO:Calculating mean and std
2023-09-30 16:43:14,695:INFO:Creating metrics dataframe
2023-09-30 16:43:14,695:INFO:Uploading results into container
2023-09-30 16:43:14,695:INFO:Uploading model into container now
2023-09-30 16:43:14,695:INFO:_master_model_container: 30
2023-09-30 16:43:14,695:INFO:_display_container: 3
2023-09-30 16:43:14,695:INFO:KNeighborsRegressor(n_jobs=-1)
2023-09-30 16:43:14,695:INFO:create_model() successfully completed......................................
2023-09-30 16:43:14,791:INFO:SubProcess create_model() end ==================================
2023-09-30 16:43:14,791:INFO:Creating metrics dataframe
2023-09-30 16:43:14,815:INFO:Initializing Decision Tree Regressor
2023-09-30 16:43:14,815:INFO:Total runtime is 0.0900530219078064 minutes
2023-09-30 16:43:14,829:INFO:SubProcess create_model() called ==================================
2023-09-30 16:43:14,829:INFO:Initializing create_model()
2023-09-30 16:43:14,829:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=dt, fold=KFold(n_splits=15, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170B10A0A30>, model_only=True, return_train_score=False, kwargs={})
2023-09-30 16:43:14,829:INFO:Checking exceptions
2023-09-30 16:43:14,829:INFO:Importing libraries
2023-09-30 16:43:14,829:INFO:Copying training dataset
2023-09-30 16:43:14,829:INFO:Defining folds
2023-09-30 16:43:14,829:INFO:Declaring metric variables
2023-09-30 16:43:14,842:INFO:Importing untrained model
2023-09-30 16:43:14,850:INFO:Decision Tree Regressor Imported successfully
2023-09-30 16:43:14,866:INFO:Starting cross validation
2023-09-30 16:43:14,866:INFO:Cross validating with KFold(n_splits=15, random_state=None, shuffle=False), n_jobs=-1
2023-09-30 16:43:15,060:INFO:Calculating mean and std
2023-09-30 16:43:15,060:INFO:Creating metrics dataframe
2023-09-30 16:43:15,066:INFO:Uploading results into container
2023-09-30 16:43:15,066:INFO:Uploading model into container now
2023-09-30 16:43:15,066:INFO:_master_model_container: 31
2023-09-30 16:43:15,066:INFO:_display_container: 3
2023-09-30 16:43:15,074:INFO:DecisionTreeRegressor(random_state=88)
2023-09-30 16:43:15,074:INFO:create_model() successfully completed......................................
2023-09-30 16:43:15,161:INFO:SubProcess create_model() end ==================================
2023-09-30 16:43:15,161:INFO:Creating metrics dataframe
2023-09-30 16:43:15,179:INFO:Initializing Random Forest Regressor
2023-09-30 16:43:15,191:INFO:Total runtime is 0.09630857308705648 minutes
2023-09-30 16:43:15,191:INFO:SubProcess create_model() called ==================================
2023-09-30 16:43:15,199:INFO:Initializing create_model()
2023-09-30 16:43:15,199:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=rf, fold=KFold(n_splits=15, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170B10A0A30>, model_only=True, return_train_score=False, kwargs={})
2023-09-30 16:43:15,199:INFO:Checking exceptions
2023-09-30 16:43:15,199:INFO:Importing libraries
2023-09-30 16:43:15,199:INFO:Copying training dataset
2023-09-30 16:43:15,208:INFO:Defining folds
2023-09-30 16:43:15,208:INFO:Declaring metric variables
2023-09-30 16:43:15,208:INFO:Importing untrained model
2023-09-30 16:43:15,230:INFO:Random Forest Regressor Imported successfully
2023-09-30 16:43:15,247:INFO:Starting cross validation
2023-09-30 16:43:15,247:INFO:Cross validating with KFold(n_splits=15, random_state=None, shuffle=False), n_jobs=-1
2023-09-30 16:43:17,357:INFO:Calculating mean and std
2023-09-30 16:43:17,357:INFO:Creating metrics dataframe
2023-09-30 16:43:17,363:INFO:Uploading results into container
2023-09-30 16:43:17,363:INFO:Uploading model into container now
2023-09-30 16:43:17,363:INFO:_master_model_container: 32
2023-09-30 16:43:17,363:INFO:_display_container: 3
2023-09-30 16:43:17,363:INFO:RandomForestRegressor(n_jobs=-1, random_state=88)
2023-09-30 16:43:17,363:INFO:create_model() successfully completed......................................
2023-09-30 16:43:17,464:INFO:SubProcess create_model() end ==================================
2023-09-30 16:43:17,464:INFO:Creating metrics dataframe
2023-09-30 16:43:17,499:INFO:Initializing Extra Trees Regressor
2023-09-30 16:43:17,499:INFO:Total runtime is 0.1347793420155843 minutes
2023-09-30 16:43:17,515:INFO:SubProcess create_model() called ==================================
2023-09-30 16:43:17,515:INFO:Initializing create_model()
2023-09-30 16:43:17,515:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=et, fold=KFold(n_splits=15, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170B10A0A30>, model_only=True, return_train_score=False, kwargs={})
2023-09-30 16:43:17,515:INFO:Checking exceptions
2023-09-30 16:43:17,515:INFO:Importing libraries
2023-09-30 16:43:17,515:INFO:Copying training dataset
2023-09-30 16:43:17,531:INFO:Defining folds
2023-09-30 16:43:17,531:INFO:Declaring metric variables
2023-09-30 16:43:17,531:INFO:Importing untrained model
2023-09-30 16:43:17,547:INFO:Extra Trees Regressor Imported successfully
2023-09-30 16:43:17,565:INFO:Starting cross validation
2023-09-30 16:43:17,570:INFO:Cross validating with KFold(n_splits=15, random_state=None, shuffle=False), n_jobs=-1
2023-09-30 16:43:19,223:INFO:Calculating mean and std
2023-09-30 16:43:19,223:INFO:Creating metrics dataframe
2023-09-30 16:43:19,231:INFO:Uploading results into container
2023-09-30 16:43:19,231:INFO:Uploading model into container now
2023-09-30 16:43:19,239:INFO:_master_model_container: 33
2023-09-30 16:43:19,239:INFO:_display_container: 3
2023-09-30 16:43:19,239:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=88)
2023-09-30 16:43:19,239:INFO:create_model() successfully completed......................................
2023-09-30 16:43:19,324:INFO:SubProcess create_model() end ==================================
2023-09-30 16:43:19,324:INFO:Creating metrics dataframe
2023-09-30 16:43:19,356:INFO:Initializing AdaBoost Regressor
2023-09-30 16:43:19,356:INFO:Total runtime is 0.1657240390777588 minutes
2023-09-30 16:43:19,356:INFO:SubProcess create_model() called ==================================
2023-09-30 16:43:19,356:INFO:Initializing create_model()
2023-09-30 16:43:19,356:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=ada, fold=KFold(n_splits=15, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170B10A0A30>, model_only=True, return_train_score=False, kwargs={})
2023-09-30 16:43:19,356:INFO:Checking exceptions
2023-09-30 16:43:19,356:INFO:Importing libraries
2023-09-30 16:43:19,356:INFO:Copying training dataset
2023-09-30 16:43:19,373:INFO:Defining folds
2023-09-30 16:43:19,373:INFO:Declaring metric variables
2023-09-30 16:43:19,387:INFO:Importing untrained model
2023-09-30 16:43:19,390:INFO:AdaBoost Regressor Imported successfully
2023-09-30 16:43:19,407:INFO:Starting cross validation
2023-09-30 16:43:19,414:INFO:Cross validating with KFold(n_splits=15, random_state=None, shuffle=False), n_jobs=-1
2023-09-30 16:43:20,191:INFO:Calculating mean and std
2023-09-30 16:43:20,191:INFO:Creating metrics dataframe
2023-09-30 16:43:20,197:INFO:Uploading results into container
2023-09-30 16:43:20,197:INFO:Uploading model into container now
2023-09-30 16:43:20,197:INFO:_master_model_container: 34
2023-09-30 16:43:20,197:INFO:_display_container: 3
2023-09-30 16:43:20,197:INFO:AdaBoostRegressor(random_state=88)
2023-09-30 16:43:20,197:INFO:create_model() successfully completed......................................
2023-09-30 16:43:20,289:INFO:SubProcess create_model() end ==================================
2023-09-30 16:43:20,289:INFO:Creating metrics dataframe
2023-09-30 16:43:20,334:INFO:Initializing Gradient Boosting Regressor
2023-09-30 16:43:20,334:INFO:Total runtime is 0.18202068408330283 minutes
2023-09-30 16:43:20,340:INFO:SubProcess create_model() called ==================================
2023-09-30 16:43:20,340:INFO:Initializing create_model()
2023-09-30 16:43:20,340:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=gbr, fold=KFold(n_splits=15, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170B10A0A30>, model_only=True, return_train_score=False, kwargs={})
2023-09-30 16:43:20,340:INFO:Checking exceptions
2023-09-30 16:43:20,340:INFO:Importing libraries
2023-09-30 16:43:20,340:INFO:Copying training dataset
2023-09-30 16:43:20,348:INFO:Defining folds
2023-09-30 16:43:20,348:INFO:Declaring metric variables
2023-09-30 16:43:20,365:INFO:Importing untrained model
2023-09-30 16:43:20,365:INFO:Gradient Boosting Regressor Imported successfully
2023-09-30 16:43:20,381:INFO:Starting cross validation
2023-09-30 16:43:20,389:INFO:Cross validating with KFold(n_splits=15, random_state=None, shuffle=False), n_jobs=-1
2023-09-30 16:43:21,058:INFO:Calculating mean and std
2023-09-30 16:43:21,058:INFO:Creating metrics dataframe
2023-09-30 16:43:21,058:INFO:Uploading results into container
2023-09-30 16:43:21,058:INFO:Uploading model into container now
2023-09-30 16:43:21,058:INFO:_master_model_container: 35
2023-09-30 16:43:21,058:INFO:_display_container: 3
2023-09-30 16:43:21,058:INFO:GradientBoostingRegressor(random_state=88)
2023-09-30 16:43:21,058:INFO:create_model() successfully completed......................................
2023-09-30 16:43:21,163:INFO:SubProcess create_model() end ==================================
2023-09-30 16:43:21,163:INFO:Creating metrics dataframe
2023-09-30 16:43:21,206:INFO:Initializing Extreme Gradient Boosting
2023-09-30 16:43:21,206:INFO:Total runtime is 0.1965653936068217 minutes
2023-09-30 16:43:21,214:INFO:SubProcess create_model() called ==================================
2023-09-30 16:43:21,214:INFO:Initializing create_model()
2023-09-30 16:43:21,214:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=xgboost, fold=KFold(n_splits=15, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170B10A0A30>, model_only=True, return_train_score=False, kwargs={})
2023-09-30 16:43:21,214:INFO:Checking exceptions
2023-09-30 16:43:21,214:INFO:Importing libraries
2023-09-30 16:43:21,222:INFO:Copying training dataset
2023-09-30 16:43:21,224:INFO:Defining folds
2023-09-30 16:43:21,224:INFO:Declaring metric variables
2023-09-30 16:43:21,241:INFO:Importing untrained model
2023-09-30 16:43:21,252:INFO:Extreme Gradient Boosting Imported successfully
2023-09-30 16:43:21,264:INFO:Starting cross validation
2023-09-30 16:43:21,264:INFO:Cross validating with KFold(n_splits=15, random_state=None, shuffle=False), n_jobs=-1
2023-09-30 16:43:22,766:INFO:Calculating mean and std
2023-09-30 16:43:22,769:INFO:Creating metrics dataframe
2023-09-30 16:43:22,779:INFO:Uploading results into container
2023-09-30 16:43:22,780:INFO:Uploading model into container now
2023-09-30 16:43:22,782:INFO:_master_model_container: 36
2023-09-30 16:43:22,782:INFO:_display_container: 3
2023-09-30 16:43:22,784:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=88, ...)
2023-09-30 16:43:22,785:INFO:create_model() successfully completed......................................
2023-09-30 16:43:22,894:INFO:SubProcess create_model() end ==================================
2023-09-30 16:43:22,894:INFO:Creating metrics dataframe
2023-09-30 16:43:22,910:INFO:Initializing Light Gradient Boosting Machine
2023-09-30 16:43:22,910:INFO:Total runtime is 0.2249541997909546 minutes
2023-09-30 16:43:22,910:INFO:SubProcess create_model() called ==================================
2023-09-30 16:43:22,910:INFO:Initializing create_model()
2023-09-30 16:43:22,910:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=lightgbm, fold=KFold(n_splits=15, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170B10A0A30>, model_only=True, return_train_score=False, kwargs={})
2023-09-30 16:43:22,910:INFO:Checking exceptions
2023-09-30 16:43:22,910:INFO:Importing libraries
2023-09-30 16:43:22,910:INFO:Copying training dataset
2023-09-30 16:43:22,925:INFO:Defining folds
2023-09-30 16:43:22,925:INFO:Declaring metric variables
2023-09-30 16:43:22,925:INFO:Importing untrained model
2023-09-30 16:43:22,945:INFO:Light Gradient Boosting Machine Imported successfully
2023-09-30 16:43:22,961:INFO:Starting cross validation
2023-09-30 16:43:22,961:INFO:Cross validating with KFold(n_splits=15, random_state=None, shuffle=False), n_jobs=-1
2023-09-30 16:43:24,310:INFO:Calculating mean and std
2023-09-30 16:43:24,310:INFO:Creating metrics dataframe
2023-09-30 16:43:24,315:INFO:Uploading results into container
2023-09-30 16:43:24,315:INFO:Uploading model into container now
2023-09-30 16:43:24,323:INFO:_master_model_container: 37
2023-09-30 16:43:24,323:INFO:_display_container: 3
2023-09-30 16:43:24,323:INFO:LGBMRegressor(n_jobs=-1, random_state=88)
2023-09-30 16:43:24,323:INFO:create_model() successfully completed......................................
2023-09-30 16:43:24,426:INFO:SubProcess create_model() end ==================================
2023-09-30 16:43:24,426:INFO:Creating metrics dataframe
2023-09-30 16:43:24,442:INFO:Initializing Dummy Regressor
2023-09-30 16:43:24,442:INFO:Total runtime is 0.2505035161972046 minutes
2023-09-30 16:43:24,458:INFO:SubProcess create_model() called ==================================
2023-09-30 16:43:24,458:INFO:Initializing create_model()
2023-09-30 16:43:24,458:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=dummy, fold=KFold(n_splits=15, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170B10A0A30>, model_only=True, return_train_score=False, kwargs={})
2023-09-30 16:43:24,458:INFO:Checking exceptions
2023-09-30 16:43:24,458:INFO:Importing libraries
2023-09-30 16:43:24,458:INFO:Copying training dataset
2023-09-30 16:43:24,458:INFO:Defining folds
2023-09-30 16:43:24,458:INFO:Declaring metric variables
2023-09-30 16:43:24,475:INFO:Importing untrained model
2023-09-30 16:43:24,475:INFO:Dummy Regressor Imported successfully
2023-09-30 16:43:24,490:INFO:Starting cross validation
2023-09-30 16:43:24,497:INFO:Cross validating with KFold(n_splits=15, random_state=None, shuffle=False), n_jobs=-1
2023-09-30 16:43:24,674:INFO:Calculating mean and std
2023-09-30 16:43:24,674:INFO:Creating metrics dataframe
2023-09-30 16:43:24,674:INFO:Uploading results into container
2023-09-30 16:43:24,674:INFO:Uploading model into container now
2023-09-30 16:43:24,674:INFO:_master_model_container: 38
2023-09-30 16:43:24,674:INFO:_display_container: 3
2023-09-30 16:43:24,674:INFO:DummyRegressor()
2023-09-30 16:43:24,686:INFO:create_model() successfully completed......................................
2023-09-30 16:43:24,773:INFO:SubProcess create_model() end ==================================
2023-09-30 16:43:24,773:INFO:Creating metrics dataframe
2023-09-30 16:43:24,839:INFO:Initializing create_model()
2023-09-30 16:43:24,839:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=88, ...), fold=KFold(n_splits=15, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-30 16:43:24,839:INFO:Checking exceptions
2023-09-30 16:43:24,844:INFO:Importing libraries
2023-09-30 16:43:24,844:INFO:Copying training dataset
2023-09-30 16:43:24,844:INFO:Defining folds
2023-09-30 16:43:24,844:INFO:Declaring metric variables
2023-09-30 16:43:24,844:INFO:Importing untrained model
2023-09-30 16:43:24,844:INFO:Declaring custom model
2023-09-30 16:43:24,844:INFO:Extreme Gradient Boosting Imported successfully
2023-09-30 16:43:24,856:INFO:Cross validation set to False
2023-09-30 16:43:24,856:INFO:Fitting Model
2023-09-30 16:43:25,029:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=88, ...)
2023-09-30 16:43:25,029:INFO:create_model() successfully completed......................................
2023-09-30 16:43:25,215:INFO:_master_model_container: 38
2023-09-30 16:43:25,215:INFO:_display_container: 3
2023-09-30 16:43:25,215:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=88, ...)
2023-09-30 16:43:25,215:INFO:compare_models() successfully completed......................................
2023-09-30 16:43:29,844:INFO:Initializing predict_model()
2023-09-30 16:43:29,844:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=88, ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000170B35715A0>)
2023-09-30 16:43:29,844:INFO:Checking exceptions
2023-09-30 16:43:29,844:INFO:Preloading libraries
2023-09-30 16:44:14,763:INFO:Initializing tune_model()
2023-09-30 16:44:14,763:INFO:tune_model(estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=88, ...), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>)
2023-09-30 16:44:14,763:INFO:Checking exceptions
2023-09-30 16:44:14,795:INFO:Copying training dataset
2023-09-30 16:44:14,807:INFO:Checking base model
2023-09-30 16:44:14,807:INFO:Base model : Extreme Gradient Boosting
2023-09-30 16:44:14,815:INFO:Declaring metric variables
2023-09-30 16:44:14,831:INFO:Defining Hyperparameters
2023-09-30 16:44:14,941:INFO:Tuning with n_jobs=-1
2023-09-30 16:44:14,941:INFO:Initializing RandomizedSearchCV
2023-09-30 16:44:24,785:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__scale_pos_weight': 12.600000000000001, 'actual_estimator__reg_lambda': 0.7, 'actual_estimator__reg_alpha': 0.01, 'actual_estimator__n_estimators': 180, 'actual_estimator__min_child_weight': 1, 'actual_estimator__max_depth': 4, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__colsample_bytree': 0.5}
2023-09-30 16:44:24,785:INFO:Hyperparameter search completed
2023-09-30 16:44:24,785:INFO:SubProcess create_model() called ==================================
2023-09-30 16:44:24,785:INFO:Initializing create_model()
2023-09-30 16:44:24,793:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=88, ...), fold=KFold(n_splits=15, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170B3C42500>, model_only=True, return_train_score=False, kwargs={'subsample': 0.7, 'scale_pos_weight': 12.600000000000001, 'reg_lambda': 0.7, 'reg_alpha': 0.01, 'n_estimators': 180, 'min_child_weight': 1, 'max_depth': 4, 'learning_rate': 0.05, 'colsample_bytree': 0.5})
2023-09-30 16:44:24,793:INFO:Checking exceptions
2023-09-30 16:44:24,793:INFO:Importing libraries
2023-09-30 16:44:24,793:INFO:Copying training dataset
2023-09-30 16:44:24,802:INFO:Defining folds
2023-09-30 16:44:24,802:INFO:Declaring metric variables
2023-09-30 16:44:24,810:INFO:Importing untrained model
2023-09-30 16:44:24,810:INFO:Declaring custom model
2023-09-30 16:44:24,832:INFO:Extreme Gradient Boosting Imported successfully
2023-09-30 16:44:24,850:INFO:Starting cross validation
2023-09-30 16:44:24,855:INFO:Cross validating with KFold(n_splits=15, random_state=None, shuffle=False), n_jobs=-1
2023-09-30 16:44:26,571:INFO:Calculating mean and std
2023-09-30 16:44:26,576:INFO:Creating metrics dataframe
2023-09-30 16:44:26,591:INFO:Finalizing model
2023-09-30 16:44:26,816:INFO:Uploading results into container
2023-09-30 16:44:26,819:INFO:Uploading model into container now
2023-09-30 16:44:26,819:INFO:_master_model_container: 39
2023-09-30 16:44:26,820:INFO:_display_container: 5
2023-09-30 16:44:26,822:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.5, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=0.05, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=4, max_leaves=None,
             min_child_weight=1, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=180, n_jobs=-1,
             num_parallel_tree=None, random_state=88, ...)
2023-09-30 16:44:26,822:INFO:create_model() successfully completed......................................
2023-09-30 16:44:26,959:INFO:SubProcess create_model() end ==================================
2023-09-30 16:44:26,959:INFO:choose_better activated
2023-09-30 16:44:26,976:INFO:SubProcess create_model() called ==================================
2023-09-30 16:44:26,976:INFO:Initializing create_model()
2023-09-30 16:44:26,976:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=88, ...), fold=KFold(n_splits=15, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-30 16:44:26,976:INFO:Checking exceptions
2023-09-30 16:44:26,976:INFO:Importing libraries
2023-09-30 16:44:26,976:INFO:Copying training dataset
2023-09-30 16:44:26,976:INFO:Defining folds
2023-09-30 16:44:26,976:INFO:Declaring metric variables
2023-09-30 16:44:26,976:INFO:Importing untrained model
2023-09-30 16:44:26,976:INFO:Declaring custom model
2023-09-30 16:44:26,976:INFO:Extreme Gradient Boosting Imported successfully
2023-09-30 16:44:26,992:INFO:Starting cross validation
2023-09-30 16:44:26,992:INFO:Cross validating with KFold(n_splits=15, random_state=None, shuffle=False), n_jobs=-1
2023-09-30 16:44:28,332:INFO:Calculating mean and std
2023-09-30 16:44:28,333:INFO:Creating metrics dataframe
2023-09-30 16:44:28,336:INFO:Finalizing model
2023-09-30 16:44:28,499:INFO:Uploading results into container
2023-09-30 16:44:28,499:INFO:Uploading model into container now
2023-09-30 16:44:28,499:INFO:_master_model_container: 40
2023-09-30 16:44:28,499:INFO:_display_container: 6
2023-09-30 16:44:28,499:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=88, ...)
2023-09-30 16:44:28,499:INFO:create_model() successfully completed......................................
2023-09-30 16:44:28,630:INFO:SubProcess create_model() end ==================================
2023-09-30 16:44:28,630:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=88, ...) result for R2 is 0.9388
2023-09-30 16:44:28,630:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.5, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=0.05, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=4, max_leaves=None,
             min_child_weight=1, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=180, n_jobs=-1,
             num_parallel_tree=None, random_state=88, ...) result for R2 is 0.9383
2023-09-30 16:44:28,630:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=88, ...) is best model
2023-09-30 16:44:28,630:INFO:choose_better completed
2023-09-30 16:44:28,630:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-09-30 16:44:28,646:INFO:_master_model_container: 40
2023-09-30 16:44:28,660:INFO:_display_container: 5
2023-09-30 16:44:28,660:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=88, ...)
2023-09-30 16:44:28,660:INFO:tune_model() successfully completed......................................
2023-09-30 16:44:28,758:INFO:Initializing predict_model()
2023-09-30 16:44:28,758:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=88, ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000170B3C46F80>)
2023-09-30 16:44:28,758:INFO:Checking exceptions
2023-09-30 16:44:28,758:INFO:Preloading libraries
2023-09-30 16:47:23,682:INFO:Initializing finalize_model()
2023-09-30 16:47:23,682:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=88, ...), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-09-30 16:47:23,692:INFO:Finalizing XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=88, ...)
2023-09-30 16:47:23,701:INFO:Initializing create_model()
2023-09-30 16:47:23,701:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=88, ...), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-09-30 16:47:23,701:INFO:Checking exceptions
2023-09-30 16:47:23,701:INFO:Importing libraries
2023-09-30 16:47:23,701:INFO:Copying training dataset
2023-09-30 16:47:23,701:INFO:Defining folds
2023-09-30 16:47:23,701:INFO:Declaring metric variables
2023-09-30 16:47:23,701:INFO:Importing untrained model
2023-09-30 16:47:23,701:INFO:Declaring custom model
2023-09-30 16:47:23,712:INFO:Extreme Gradient Boosting Imported successfully
2023-09-30 16:47:23,712:INFO:Cross validation set to False
2023-09-30 16:47:23,712:INFO:Fitting Model
2023-09-30 16:47:23,999:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['clonesize', 'honeybee', 'bumbles',
                                             'andrena', 'osmia',
                                             'MaxOfUpperTRange',
                                             'MinOfUpperTRange',
                                             'AverageOfUpperTRange',
                                             'MaxOfLowerTRange',
                                             'MinOfLowerTRange',
                                             'AverageOfLowerTRange',
                                             'RainingDays',
                                             'AverageRainingDays'],
                                    transformer=SimpleImputer())),
                ('categorical_imp...
                              feature_types=None, gamma=None, grow_policy=None,
                              importance_type=None,
                              interaction_constraints=None, learning_rate=None,
                              max_bin=None, max_cat_threshold=None,
                              max_cat_to_onehot=None, max_delta_step=None,
                              max_depth=None, max_leaves=None,
                              min_child_weight=None, missing=nan,
                              monotone_constraints=None, multi_strategy=None,
                              n_estimators=None, n_jobs=-1,
                              num_parallel_tree=None, random_state=88, ...))])
2023-09-30 16:47:23,999:INFO:create_model() successfully completed......................................
2023-09-30 16:47:24,128:INFO:_master_model_container: 40
2023-09-30 16:47:24,128:INFO:_display_container: 6
2023-09-30 16:47:24,145:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['clonesize', 'honeybee', 'bumbles',
                                             'andrena', 'osmia',
                                             'MaxOfUpperTRange',
                                             'MinOfUpperTRange',
                                             'AverageOfUpperTRange',
                                             'MaxOfLowerTRange',
                                             'MinOfLowerTRange',
                                             'AverageOfLowerTRange',
                                             'RainingDays',
                                             'AverageRainingDays'],
                                    transformer=SimpleImputer())),
                ('categorical_imp...
                              feature_types=None, gamma=None, grow_policy=None,
                              importance_type=None,
                              interaction_constraints=None, learning_rate=None,
                              max_bin=None, max_cat_threshold=None,
                              max_cat_to_onehot=None, max_delta_step=None,
                              max_depth=None, max_leaves=None,
                              min_child_weight=None, missing=nan,
                              monotone_constraints=None, multi_strategy=None,
                              n_estimators=None, n_jobs=-1,
                              num_parallel_tree=None, random_state=88, ...))])
2023-09-30 16:47:24,145:INFO:finalize_model() successfully completed......................................
2023-09-30 16:47:52,281:INFO:Initializing finalize_model()
2023-09-30 16:47:52,282:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=88, ...), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-09-30 16:47:52,284:INFO:Finalizing XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=88, ...)
2023-09-30 16:47:52,295:INFO:Initializing create_model()
2023-09-30 16:47:52,295:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=88, ...), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-09-30 16:47:52,295:INFO:Checking exceptions
2023-09-30 16:47:52,304:INFO:Importing libraries
2023-09-30 16:47:52,304:INFO:Copying training dataset
2023-09-30 16:47:52,304:INFO:Defining folds
2023-09-30 16:47:52,304:INFO:Declaring metric variables
2023-09-30 16:47:52,304:INFO:Importing untrained model
2023-09-30 16:47:52,304:INFO:Declaring custom model
2023-09-30 16:47:52,304:INFO:Extreme Gradient Boosting Imported successfully
2023-09-30 16:47:52,304:INFO:Cross validation set to False
2023-09-30 16:47:52,304:INFO:Fitting Model
2023-09-30 16:47:52,699:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['clonesize', 'honeybee', 'bumbles',
                                             'andrena', 'osmia',
                                             'MaxOfUpperTRange',
                                             'MinOfUpperTRange',
                                             'AverageOfUpperTRange',
                                             'MaxOfLowerTRange',
                                             'MinOfLowerTRange',
                                             'AverageOfLowerTRange',
                                             'RainingDays',
                                             'AverageRainingDays'],
                                    transformer=SimpleImputer())),
                ('categorical_imp...
                              feature_types=None, gamma=None, grow_policy=None,
                              importance_type=None,
                              interaction_constraints=None, learning_rate=None,
                              max_bin=None, max_cat_threshold=None,
                              max_cat_to_onehot=None, max_delta_step=None,
                              max_depth=None, max_leaves=None,
                              min_child_weight=None, missing=nan,
                              monotone_constraints=None, multi_strategy=None,
                              n_estimators=None, n_jobs=-1,
                              num_parallel_tree=None, random_state=88, ...))])
2023-09-30 16:47:52,699:INFO:create_model() successfully completed......................................
2023-09-30 16:47:52,857:INFO:_master_model_container: 40
2023-09-30 16:47:52,857:INFO:_display_container: 6
2023-09-30 16:47:52,858:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['clonesize', 'honeybee', 'bumbles',
                                             'andrena', 'osmia',
                                             'MaxOfUpperTRange',
                                             'MinOfUpperTRange',
                                             'AverageOfUpperTRange',
                                             'MaxOfLowerTRange',
                                             'MinOfLowerTRange',
                                             'AverageOfLowerTRange',
                                             'RainingDays',
                                             'AverageRainingDays'],
                                    transformer=SimpleImputer())),
                ('categorical_imp...
                              feature_types=None, gamma=None, grow_policy=None,
                              importance_type=None,
                              interaction_constraints=None, learning_rate=None,
                              max_bin=None, max_cat_threshold=None,
                              max_cat_to_onehot=None, max_delta_step=None,
                              max_depth=None, max_leaves=None,
                              min_child_weight=None, missing=nan,
                              monotone_constraints=None, multi_strategy=None,
                              n_estimators=None, n_jobs=-1,
                              num_parallel_tree=None, random_state=88, ...))])
2023-09-30 16:47:52,858:INFO:finalize_model() successfully completed......................................
2023-09-30 16:50:17,786:INFO:Initializing plot_model()
2023-09-30 16:50:17,786:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=88, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000170B0EB3C40>, system=True)
2023-09-30 16:50:17,786:INFO:Checking exceptions
2023-09-30 16:50:17,798:INFO:Preloading libraries
2023-09-30 16:50:17,821:INFO:Copying training dataset
2023-09-30 16:50:17,821:INFO:Plot type: residuals
2023-09-30 16:50:18,117:INFO:Fitting Model
2023-09-30 16:50:18,260:INFO:Scoring test/hold-out set
2023-09-30 16:50:19,654:INFO:Visual Rendered Successfully
2023-09-30 16:50:19,753:INFO:plot_model() successfully completed......................................
2023-09-30 17:36:22,932:INFO:Initializing load_model()
2023-09-30 17:36:22,932:INFO:load_model(model_name=pycaret_automl_blueberry_yield_xgb12fold, platform=None, authentication=None, verbose=True)
